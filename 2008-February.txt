From mangoo at wpkg.org  Fri Feb  1 13:05:41 2008
From: mangoo at wpkg.org (Tomasz Chmielewski)
Date: Fri, 01 Feb 2008 13:05:41 +0100
Subject: [Stgt-devel] data corruption problems with stgt (aborted
 journal, remounting ro)?
In-Reply-To: <47A1B6E9.30603@wpkg.org>
References: <47A1B6E9.30603@wpkg.org>
Message-ID: <47A30B15.6000605@wpkg.org>

Tomasz Chmielewski schrieb:
> Doesn't look my posts get to this list... or is it just lagged a lot? 
> Resending.
> 
> 
> Perhaps I'm doing something wrong - but with stgt I'm facing problems I 
> didn't have with IET or SCST.
> 
> Whenever I kill tgtd daemon and start it again (i.e., target server 
> restart), the initiator detects an aborted journal and remount the 
> device ro.
> 
> Why is it so?
> 
> What is the recommended way to kill the tgtd daemon? It doesn't seem to 
> react on TERM signal.

Hello, anyone there?

Is there a way to restart tgtd daemon or a machine running tgtd, so that 
iSCSI connections don't break?


-- 
Tomasz Chmielewski
http://wpkg.org



From tomof at acm.org  Sat Feb  2 01:56:38 2008
From: tomof at acm.org (FUJITA Tomonori)
Date: Sat, 2 Feb 2008 09:56:38 +0900
Subject: [Stgt-devel] data corruption problems with stgt (aborted
 journal, remounting ro)?
In-Reply-To: <47A30B15.6000605@wpkg.org>
References: <47A1B6E9.30603@wpkg.org>
	<47A30B15.6000605@wpkg.org>
Message-ID: <20080202095637T.tomof@acm.org>

On Fri, 01 Feb 2008 13:05:41 +0100
Tomasz Chmielewski <mangoo at wpkg.org> wrote:

> Tomasz Chmielewski schrieb:
> > Doesn't look my posts get to this list... or is it just lagged a lot? 
> > Resending.
> > 
> > 
> > Perhaps I'm doing something wrong - but with stgt I'm facing problems I 
> > didn't have with IET or SCST.
> > 
> > Whenever I kill tgtd daemon and start it again (i.e., target server 
> > restart), the initiator detects an aborted journal and remount the 
> > device ro.
> > 
> > Why is it so?
> > 
> > What is the recommended way to kill the tgtd daemon? It doesn't seem to 
> > react on TERM signal.
> 
> Hello, anyone there?
> 
> Is there a way to restart tgtd daemon or a machine running tgtd, so that 
> iSCSI connections don't break?

What does your 'restart tgtd daemon' mean? For me, 'restart' involves
stopping tgtd daemon and it closes all the iSCSI connections.


From mangoo at wpkg.org  Sat Feb  2 10:39:02 2008
From: mangoo at wpkg.org (Tomasz Chmielewski)
Date: Sat, 02 Feb 2008 10:39:02 +0100
Subject: [Stgt-devel] data corruption problems with stgt (aborted
 journal, remounting ro)?
In-Reply-To: <20080202095637T.tomof@acm.org>
References: <47A1B6E9.30603@wpkg.org>	<47A30B15.6000605@wpkg.org>
	<20080202095637T.tomof@acm.org>
Message-ID: <47A43A36.9030307@wpkg.org>

FUJITA Tomonori schrieb:
> On Fri, 01 Feb 2008 13:05:41 +0100
> Tomasz Chmielewski <mangoo at wpkg.org> wrote:
> 
>> Tomasz Chmielewski schrieb:
>>> Doesn't look my posts get to this list... or is it just lagged a lot? 
>>> Resending.
>>>
>>>
>>> Perhaps I'm doing something wrong - but with stgt I'm facing problems I 
>>> didn't have with IET or SCST.
>>>
>>> Whenever I kill tgtd daemon and start it again (i.e., target server 
>>> restart), the initiator detects an aborted journal and remount the 
>>> device ro.
>>>
>>> Why is it so?
>>>
>>> What is the recommended way to kill the tgtd daemon? It doesn't seem to 
>>> react on TERM signal.
>> Hello, anyone there?
>>
>> Is there a way to restart tgtd daemon or a machine running tgtd, so that 
>> iSCSI connections don't break?
> 
> What does your 'restart tgtd daemon' mean? For me, 'restart' involves
> stopping tgtd daemon and it closes all the iSCSI connections.

Stop it, and start again?

Imagine you want to upgrade your tgtd daemon, a kernel running on that 
machine, or you have to restart the target machine for some other reason 
(i.e. your target machine died).

With IET or SCST there is no problem with that - stop the target, and 
iSCSI initiator will try to reconnect.

By default, open-iscsi tries to reconnect for 120 seconds without 
returning an error to the SCSI layer, as defined /etc/iscsi/iscsid.conf:

node.session.timeo.replacement_timeout = 120


But there is no problem to increase that value to even a couple of days 
(imagine: admin stops the target machine erroneously on Friday, comes 
back to work on Monday, starts the target, and initiators continue to 
work as if nothing happened - processes were in an uninterruptible sleep 
state, waiting for I/O operations to complete).


With tgtd, it seems impossible to me - or am I wrong?


-- 
Tomasz Chmielewski
http://wpkg.org


From tomof at acm.org  Sat Feb  2 10:48:06 2008
From: tomof at acm.org (FUJITA Tomonori)
Date: Sat, 2 Feb 2008 18:48:06 +0900
Subject: [Stgt-devel] data corruption problems with stgt (aborted
 journal, remounting ro)?
In-Reply-To: <47A43A36.9030307@wpkg.org>
References: <47A30B15.6000605@wpkg.org> <20080202095637T.tomof@acm.org>
	<47A43A36.9030307@wpkg.org>
Message-ID: <20080202184816P.tomof@acm.org>

On Sat, 02 Feb 2008 10:39:02 +0100
Tomasz Chmielewski <mangoo at wpkg.org> wrote:

> FUJITA Tomonori schrieb:
> > On Fri, 01 Feb 2008 13:05:41 +0100
> > Tomasz Chmielewski <mangoo at wpkg.org> wrote:
> > 
> >> Tomasz Chmielewski schrieb:
> >>> Doesn't look my posts get to this list... or is it just lagged a lot? 
> >>> Resending.
> >>>
> >>>
> >>> Perhaps I'm doing something wrong - but with stgt I'm facing problems I 
> >>> didn't have with IET or SCST.
> >>>
> >>> Whenever I kill tgtd daemon and start it again (i.e., target server 
> >>> restart), the initiator detects an aborted journal and remount the 
> >>> device ro.
> >>>
> >>> Why is it so?
> >>>
> >>> What is the recommended way to kill the tgtd daemon? It doesn't seem to 
> >>> react on TERM signal.
> >> Hello, anyone there?
> >>
> >> Is there a way to restart tgtd daemon or a machine running tgtd, so that 
> >> iSCSI connections don't break?
> > 
> > What does your 'restart tgtd daemon' mean? For me, 'restart' involves
> > stopping tgtd daemon and it closes all the iSCSI connections.
> 
> Stop it, and start again?
> 
> Imagine you want to upgrade your tgtd daemon, a kernel running on that 
> machine, or you have to restart the target machine for some other reason 
> (i.e. your target machine died).
> 
> With IET or SCST there is no problem with that - stop the target, and 
> iSCSI initiator will try to reconnect.

How did you restart IET?

/etc/init.d/iscsi-target restart

?


> By default, open-iscsi tries to reconnect for 120 seconds without 
> returning an error to the SCSI layer, as defined /etc/iscsi/iscsid.conf:
> 
> node.session.timeo.replacement_timeout = 120
> 
> 
> But there is no problem to increase that value to even a couple of days 
> (imagine: admin stops the target machine erroneously on Friday, comes 
> back to work on Monday, starts the target, and initiators continue to 
> work as if nothing happened - processes were in an uninterruptible sleep 
> state, waiting for I/O operations to complete).
> 
> 
> With tgtd, it seems impossible to me - or am I wrong?
> 
> 
> -- 
> Tomasz Chmielewski
> http://wpkg.org


From mangoo at wpkg.org  Sat Feb  2 11:19:11 2008
From: mangoo at wpkg.org (Tomasz Chmielewski)
Date: Sat, 02 Feb 2008 11:19:11 +0100
Subject: [Stgt-devel] data corruption problems with stgt (aborted
 journal, remounting ro)?
In-Reply-To: <20080202184816P.tomof@acm.org>
References: <47A30B15.6000605@wpkg.org>	<20080202095637T.tomof@acm.org>	<47A43A36.9030307@wpkg.org>
	<20080202184816P.tomof@acm.org>
Message-ID: <47A4439F.2040409@wpkg.org>

FUJITA Tomonori schrieb:
> On Sat, 02 Feb 2008 10:39:02 +0100
> Tomasz Chmielewski <mangoo at wpkg.org> wrote:
> 
>> FUJITA Tomonori schrieb:
>>> On Fri, 01 Feb 2008 13:05:41 +0100
>>> Tomasz Chmielewski <mangoo at wpkg.org> wrote:
>>>
>>>> Tomasz Chmielewski schrieb:
>>>>> Doesn't look my posts get to this list... or is it just lagged a lot? 
>>>>> Resending.
>>>>>
>>>>>
>>>>> Perhaps I'm doing something wrong - but with stgt I'm facing problems I 
>>>>> didn't have with IET or SCST.
>>>>>
>>>>> Whenever I kill tgtd daemon and start it again (i.e., target server 
>>>>> restart), the initiator detects an aborted journal and remount the 
>>>>> device ro.
>>>>>
>>>>> Why is it so?
>>>>>
>>>>> What is the recommended way to kill the tgtd daemon? It doesn't seem to 
>>>>> react on TERM signal.
>>>> Hello, anyone there?
>>>>
>>>> Is there a way to restart tgtd daemon or a machine running tgtd, so that 
>>>> iSCSI connections don't break?
>>> What does your 'restart tgtd daemon' mean? For me, 'restart' involves
>>> stopping tgtd daemon and it closes all the iSCSI connections.
>> Stop it, and start again?
>>
>> Imagine you want to upgrade your tgtd daemon, a kernel running on that 
>> machine, or you have to restart the target machine for some other reason 
>> (i.e. your target machine died).
>>
>> With IET or SCST there is no problem with that - stop the target, and 
>> iSCSI initiator will try to reconnect.
> 
> How did you restart IET?
> 
> /etc/init.d/iscsi-target restart

Yes. Or restarting the whole machine if I changed the kernel (which 
would use the same iscsi-target script).

IET has some problems that it breaks when a number of initiators is 
bigger than 50 or so - which needs two workarounds (iptables, and 
increasing INCOMING_MAX in ietadm.h).

I described it a bit here:

http://blog.wpkg.org/2007/09/09/solving-reliability-and-scalability-problems-with-iscsi/


Restarting SCST works well, and doesn't need any workarounds.


But I also had one machine which was just hanging/freezing with IET 
every couple of weeks - just start the machine again, everything goes 
back to normal.


-- 
Tomasz Chmielewski


From nab at linux-iscsi.org  Mon Feb  4 14:33:52 2008
From: nab at linux-iscsi.org (Nicholas A. Bellinger)
Date: Mon, 04 Feb 2008 05:33:52 -0800
Subject: [Stgt-devel] [Fwd: 2.6.24 kernel and LIO Target memory mapping]
Message-ID: <1202132032.11265.498.camel@haakon2.linux-iscsi.org>

Sorry, resend..
-------------- next part --------------
An embedded message was scrubbed...
From: "Nicholas A. Bellinger" <nab at kernel.org>
Subject: 2.6.24 kernel and LIO Target memory mapping
Date: Mon, 04 Feb 2008 05:27:23 -0800
Size: 9241
URL: <https://lists.berlios.de/pipermail/stgt-devel/attachments/20080204/a70966b9/attachment.mht>

From nab at kernel.org  Mon Feb  4 14:27:20 2008
From: nab at kernel.org (Nicholas A. Bellinger)
Date: Mon, 04 Feb 2008 05:27:20 -0800
Subject: [Stgt-devel] 2.6.24 kernel and LIO Target memory mapping
In-Reply-To: <1201958796.11265.415.camel@haakon2.linux-iscsi.org>
References: <e2e108260802010609m12af3990k58a385b8f8598ec7@mail.gmail.com>
	<1201877400.11265.311.camel@haakon2.linux-iscsi.org>
	<1201958796.11265.415.camel@haakon2.linux-iscsi.org>
Message-ID: <1202131640.11265.494.camel@haakon2.linux-iscsi.org>

On Sat, 2008-02-02 at 05:26 -0800, Nicholas A. Bellinger wrote: 
> Hi Bart,
> 
> Ok, I have 2.6.24 running on ppc64 doing iSCSI/HD on PS3-Linux.  The
> changes for struct scatterlist->page moving to struct
> scatterlist->page_link where pretty straightforward, considering the LIO
> storage engine does not depend on struct scatterlist.  I am going to
> take another look at the diffs later today and make sure everything
> looks corerct, and will make the commits then.
> 
> If you could test these on your setup with 2.6.24 in the non IPoIB case
> (that from my previous emails I am guessing will be fine on your setup)
> I would really appreciate it.  I will put 2.6.24 in VM on the
> Linux-iSCSI.org fabric in the upcoming days, and do some additional
> testing.  Getting the CentOS v5u1 x86_64 builds release are a bit higher
> priority than 2.6.24, but I think that the 2.6.24 changes are reasonable
> and do not cause concern with the LIO v2.9 codebase.
> 
> Have you made any futher progress on debugging the issue LIO Target with
> IPoIB..?
> 
> Many thanks for your most valuable of time,
> 
> --nab
> 
> On Fri, 2008-02-01 at 06:50 -0800, Nicholas A. Bellinger wrote:
> > Hi There,
> > 
> > I will doing a 2.6.24 build for LIO on PS3-Linux this weekend now that
> > ps3rom.c is reporting the proper struct scsi_host_template->max_sectors.
> > Also in the queue are releasing updated builds for CentOS v5.1 x86_64.
> > I have recently upgraded one pair of core nodes on the Linux-iSCSI.org
> > fabric to the newest CentOS release, and minus a few minor issues with
> > the upgrade process, everything is looking very stable.  The few issues
> > that I had (an lvremove issue on v4.5, and qemu-dm performance with HVM
> > on v5.0) have been resolved and the fabric is running much smoother for
> > the VMs that are providing OCFS2 cluster storage to the LIO debian and
> > ubuntu repositories.  
> > 
> > I will let you know when I get 2.6.24 building.  Until then, feel free
> > to post the build failure log here.
> > 
> > Many thanks for your most valuable of time,
> > 
> > --nab
> > 
> > On Fri, 2008-02-01 at 15:09 +0100, Bart Van Assche wrote:
> > > Hello,
> > > 
> > > The Linux-iSCSI target (kernel module) does not compile on the 2.6.24
> > > kernel because of changes in the scatterlist API. Has a target date
> > > for a version that compiles with the 2.6.24 kernel headers already
> > > been set ?
> > > 
> > > Bart Van Assche.
> > > 
> 

Here are the changes to transport_memcpy_[write,read]_[contig,sg]()
respectively.  This functions are legacy within v2.9 LIO SE, and are
currently unused in kernel mode because the SE core does not rely on
struct scatterlist.

Index: target/iscsi_target_transport.c
===================================================================
--- target/iscsi_target_transport.c	(revision 205)
+++ target/iscsi_target_transport.c	(revision 206)
@@ -4181,7 +4181,7 @@
 		if (length > total_length)
 			length = total_length;
 
-		src = GET_ADDR_SG(sg_s, i);
+		src = GET_ADDR_SG(&sg_s[i]);
 
 		memcpy(dst, src, length);
 
@@ -4211,12 +4211,12 @@
 			if (length > total_length)
 				length = total_length;
 
-			dst = GET_ADDR_SG(sg_d, i) + dst_offset;
+			dst = GET_ADDR_SG(&sg_d[i]) + dst_offset;
 			if (!dst)
 				BUG();
 			i++;
 			
-			src = GET_ADDR_SG(sg_s, j) + src_offset;
+			src = GET_ADDR_SG(&sg_s[j]) + src_offset;
 			if (!src)
 				BUG();
 
@@ -4228,7 +4228,7 @@
 			if (length > total_length)
 				length = total_length;
 
-			dst = GET_ADDR_SG(sg_d, i) + dst_offset;
+			dst = GET_ADDR_SG(&sg_d[i]) + dst_offset;
 			if (!dst)
 				BUG();
 
@@ -4238,7 +4238,7 @@
 			} else
 				dst_offset = length;
 
-			src = GET_ADDR_SG(sg_s, j) + src_offset;
+			src = GET_ADDR_SG(&sg_s[j]) + src_offset;
 			if (!src)
 				BUG();
 			j++;
@@ -4269,7 +4269,7 @@
 		if (length > total_length)
 			length = total_length;
 
-		dst = GET_ADDR_SG(sg_d, i);
+		dst = GET_ADDR_SG(&sg_d[i]);
 
 		memcpy(dst, src, length);


These changes are followed up by transport_map_sg_to_mem()
and transport_map_mem_to_sg()..  The latter is the default path for
LIO SE v2.9 to v2.6 Linux storage subsystems along with the other completely
virtual subsystem drivers.  Note the former does reverse contigious
scatterlist array mapping to SE linked list memory which is then handed to
the SCSI transport, in the LIO case, traditional iSCSI.  This is currently
unused, but may be useful in some future cases.
 
@@ -4299,12 +4299,12 @@
 			if (length > total_length)
 				length = total_length;
 
-			src = GET_ADDR_SG(sg_s, i) + src_offset;
+			src = GET_ADDR_SG(&sg_s[i]) + src_offset;
 			if (!src)
 				BUG();
 			i++;
 
-			dst = GET_ADDR_SG(sg_d, j) + dst_offset;
+			dst = GET_ADDR_SG(&sg_d[j]) + dst_offset;
 			if (!dst)
 				BUG();
 
@@ -4316,7 +4316,7 @@
 			if (length > total_length)
 				length = total_length;
 
-			src = GET_ADDR_SG(sg_s, i) + src_offset;
+			src = GET_ADDR_SG(&sg_s[i]) + src_offset;
 			if (!src)
 				BUG();
 
@@ -4326,7 +4326,7 @@
 			} else
 				src_offset = length;
 
-			dst = GET_ADDR_SG(sg_d, j) + dst_offset;
+			dst = GET_ADDR_SG(&sg_d[j]) + dst_offset;
 			if (!dst)
 				BUG();
 			j++;
@@ -5191,7 +5191,7 @@
 		INIT_LIST_HEAD(&se_mem->se_list);
 
 		if (*task_offset == 0) {
-			se_mem->se_page = sg_s[j].page;
+			se_mem->se_page = GET_PAGE_SG(&sg_s[j]);
 			se_mem->se_off = sg_s[j].offset;
 
 			if (task_size >= sg_s[j].length)
@@ -5208,7 +5208,7 @@
 			if (saved_task_offset)
 				*task_offset = saved_task_offset;
 		} else {
-			se_mem->se_page = sg_s[j].page;
+			se_mem->se_page = GET_PAGE_SG(&sg_s[j]);
 			se_mem->se_off = (*task_offset + sg_s[j].offset);
 
 			if ((sg_s[j].length - *task_offset) > task_size) {
@@ -5348,7 +5348,7 @@
 
 	while (task_size) {
 		if (*task_offset == 0) {
-			sg[sg_no].page = se_mem->se_page;
+			SET_PAGE_SG(&sg[sg_no], se_mem->se_page);
 			sg[sg_no].offset = se_mem->se_off;
 
 			if (task_size >= se_mem->se_len) {
@@ -5375,7 +5375,7 @@
 			if (saved_task_offset)
 				*task_offset = saved_task_offset;
 		} else {
-			sg[sg_no].page = se_mem->se_page;
+			SET_PAGE_SG(&sg[sg_no], se_mem->se_page);
 			sg[sg_no].offset = (*task_offset + se_mem->se_off);
 
 			if ((se_mem->se_len - *task_offset) > task_size) {


The SE algoritims can also potentially accept preallocated memory for
RDMA operations and then map said memory to contiguous struct
scatterlist buffers that are then mapped to the SCSI, BIO, and
[read,write]v() for struct file.

Here are the macro changes for new and legacy operation:

Index: include/iscsi_linux_defs.h
===================================================================
--- include/iscsi_linux_defs.h (revision 207)
+++ include/iscsi_linux_defs.h (revision 208)
@@ -44,15 +44,29 @@
#define inline
#endif

-/* added to address 64bit addressing issues. */
+/*
+ * 2.6.24 provides an updated struct scatterlist API.  Use macros for
the new
+ * code, and use inline functions for legacy operation. 
+ */
#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,24)
# define GET_ADDR_SG(sg) sg_virt(sg)
# define GET_PAGE_SG(sg) sg_page(sg)
# define SET_PAGE_SG(sg, page) sg_assign_page(sg, page)
#else
-# define GET_ADDR_SG(sg) page_address(sg->page) + sg->offset
-# define GET_PAGE_SG(sg) sg->page
-# define SET_PAGE_SG(sg, page) sg->page = page
+#include <linux/scatterlist.h>
+static inline void *GET_ADDR_SG(struct scatterlist *sg)
+{
+ return(page_address(sg->page) + sg->offset);
+}
+static inline struct page *GET_PAGE_SG(struct scatterlist *sg)
+{
+ return(sg->page);
+}
+static inline void SET_PAGE_SG(struct scatterlist *sg, struct page
*page)
+{
+ sg->page = page;
+ return;
+}
#endif

/*

--nab

> 
> --~--~---------~--~----~------------~-------~--~----~
> You received this message because you are subscribed to the Google Groups "Linux-iSCSI.org Target Development" group.
> To post to this group, send email to linux-iscsi-target-dev at googlegroups.com
> To unsubscribe from this group, send email to linux-iscsi-target-dev-unsubscribe at googlegroups.com
> For more options, visit this group at http://groups.google.com/group/linux-iscsi-target-dev?hl=en
> -~----------~----~----~----~------~----~------~--~---
> 



From erezz at Voltaire.COM  Tue Feb  5 15:41:10 2008
From: erezz at Voltaire.COM (Erez Zilber)
Date: Tue, 05 Feb 2008 16:41:10 +0200
Subject: [Stgt-devel] [ANNOUNCE] open iSCSI over iSER target RPM is available
Message-ID: <47A87586.6010904@Voltaire.COM>

stgt (SCSI target) is an open-source framework for storage target
drivers. It supports iSCSI over iSER among other storage target drivers.

Voltaire added a git tree for stgt that will be added to OFED 1.4:
http://www2.openfabrics.org/git/?p=~dorons/tgt.git;a=summary

Until OFED 1.4 gets released, it is possible to install the stgt RPM on
top of OFED 1.3. For more details about how to install and use stgt,
please refer to https://wiki.openfabrics.org/tiki-index.php?page=ISER-target

Some performance numbers that were measured by OSC (using SDR cards):

    * READ: 920 MB/sec
    * WRITE: 850 MB/sec

We hope to have DDR measurements numbers soon.

-- 

____________________________________________________________

Erez Zilber | 972-9-971-7689

Software Engineer, Storage Solutions

Voltaire ? _The Grid Backbone_

www.voltaire.com <http://www.voltaire.com/>


From bart.vanassche at gmail.com  Tue Feb  5 16:48:22 2008
From: bart.vanassche at gmail.com (Bart Van Assche)
Date: Tue, 5 Feb 2008 16:48:22 +0100
Subject: [Stgt-devel] [ANNOUNCE] open iSCSI over iSER target RPM is
	available
In-Reply-To: <47A87586.6010904@Voltaire.COM>
References: <47A87586.6010904@Voltaire.COM>
Message-ID: <e2e108260802050748u7bc9bd2fx24dadcaa06b355d3@mail.gmail.com>

On Feb 5, 2008 3:41 PM, Erez Zilber <erezz at voltaire.com> wrote:
> stgt (SCSI target) is an open-source framework for storage target
> drivers. It supports iSCSI over iSER among other storage target drivers.
>
> Voltaire added a git tree for stgt that will be added to OFED 1.4:
> http://www2.openfabrics.org/git/?p=~dorons/tgt.git;a=summary
>
> Until OFED 1.4 gets released, it is possible to install the stgt RPM on
> top of OFED 1.3. For more details about how to install and use stgt,
> please refer to https://wiki.openfabrics.org/tiki-index.php?page=ISER-target
>
> Some performance numbers that were measured by OSC (using SDR cards):
>
>     * READ: 920 MB/sec
>     * WRITE: 850 MB/sec
>
> We hope to have DDR measurements numbers soon.

Hello Erez,

Can you please post more information about how these numbers were
obtained (test program and configuration parameters) ?

Bart Van Assche.


From mangoo at wpkg.org  Tue Feb  5 18:04:52 2008
From: mangoo at wpkg.org (Tomasz Chmielewski)
Date: Tue, 05 Feb 2008 18:04:52 +0100
Subject: [Stgt-devel] [Scst-devel] Integration of SCST in the mainstream
	Linux kernel
In-Reply-To: <20080206014340X.tomof@acm.org>
References: <47A80CB9.9000805@wpkg.org>	<20080205223740L.tomof@acm.org>	<47A889AB.9090301@wpkg.org>
	<20080206014340X.tomof@acm.org>
Message-ID: <47A89734.7000009@wpkg.org>

FUJITA Tomonori schrieb:

(...)

>> The problem with tgtd is that you can't start it (configured) in an
>> "atomic" way.
>> Usually, one will start tgtd and it's configuration in a script (I 
>> replaced some parameters with "..." to make it shorter and more readable):
> 
> Thanks for the details. So the way to stop the daemon is not related
> with your problem.
> 
> It's easily fixable. Can you start a new thread about this on
> stgt-devel mailing list? When we agree on the interface to start the
> daemon, I'll implement it.

Sure.

1. tgtd should not immediately background, but only when it's fully started?

2. tgtd should only start to listen if told so? tgtdadm --listen/--nolisten?

Actually, I only found this iptables workaround a few hours ago, after 
sending the first mail to lkml.
At first, I didn't realize my setup screws between tgtd and tgtdadm 
commands (where I put "sleep 1" command).

Anyway - if tgtd can be only killed with KILL signal - isn't it risky to 
do so? For example, something may be still cached, not full transferred? 
Will SCSI stack take care of it properly?


> You want to reboot a server running target devices while initiators
> connect to it. Rebooting the target server behind the initiators
> seldom works. System adminstorators in my workplace reboot storage
> devices once a year and tell us to shut down the initiator machines
> that use them before that.

Technically, it should always work (assuming the timeout on the 
initiators is bigger than time the target server reboot takes).
By default, for open-iscsi, timeout is 120 seconds, but in practice 
there is no problem in increasing it to even many days.



-- 
Tomasz Chmielewski
http://wpkg.org



From pw at osc.edu  Tue Feb  5 18:58:53 2008
From: pw at osc.edu (Pete Wyckoff)
Date: Tue, 5 Feb 2008 12:58:53 -0500
Subject: [Stgt-devel] [Scst-devel] Integration of SCST in the	mainstream
	Linux kernel
In-Reply-To: <47A89734.7000009@wpkg.org>
References: <47A80CB9.9000805@wpkg.org> <20080205223740L.tomof@acm.org>
	<47A889AB.9090301@wpkg.org> <20080206014340X.tomof@acm.org>
	<47A89734.7000009@wpkg.org>
Message-ID: <20080205175853.GA2082@osc.edu>

mangoo at wpkg.org wrote on Tue, 05 Feb 2008 18:04 +0100:
> Anyway - if tgtd can be only killed with KILL signal - isn't it risky to 
> do so? For example, something may be still cached, not full transferred? 
> Will SCSI stack take care of it properly?

I too would like a clean shutdown mechanism.  For testing and system
scripts.  Target should go away cleanly:  drop incoming tasks, wait
for pending ops to finish and send responses, drop existing
connections, close 3260, flush logs, exit.  It may be somewhat
complex to get right.  Recently iscsid grew a SIGTERM handler too.
See abd1595d358b1cfe6c059aeea74f6ecdc748f461.

		-- Pete


From mangoo at wpkg.org  Tue Feb  5 17:07:07 2008
From: mangoo at wpkg.org (Tomasz Chmielewski)
Date: Tue, 05 Feb 2008 17:07:07 +0100
Subject: [Stgt-devel] [Scst-devel] Integration of SCST in the mainstream
	Linux kernel
In-Reply-To: <20080205223740L.tomof@acm.org>
References: <e2e108260801300029r1a949353k73b30f1f28db0bc9@mail.gmail.com>	<1201710175.3292.16.camel@localhost.localdomain>	<47A80CB9.9000805@wpkg.org>
	<20080205223740L.tomof@acm.org>
Message-ID: <47A889AB.9090301@wpkg.org>

FUJITA Tomonori schrieb:
> On Tue, 05 Feb 2008 08:14:01 +0100
> Tomasz Chmielewski <mangoo at wpkg.org> wrote:
> 
>> James Bottomley schrieb:
>>
>>> These are both features being independently worked on, are they not?
>>> Even if they weren't, the combination of the size of SCST in kernel plus
>>> the problem of having to find a migration path for the current STGT
>>> users still looks to me to involve the greater amount of work.
>> I don't want to be mean, but does anyone actually use STGT in
>> production? Seriously?
>>
>> In the latest development version of STGT, it's only possible to stop
>> the tgtd target daemon using KILL / 9 signal - which also means all
>> iSCSI initiator connections are corrupted when tgtd target daemon is
>> started again (kernel upgrade, target daemon upgrade, server reboot etc.).
> 
> I don't know what "iSCSI initiator connections are corrupted"
> mean. But if you reboot a server, how can an iSCSI target
> implementation keep iSCSI tcp connections?

The problem with tgtd is that you can't start it (configured) in an
"atomic" way.
Usually, one will start tgtd and it's configuration in a script (I 
replaced some parameters with "..." to make it shorter and more readable):


tgtd
tgtadm --op new ...
tgtadm --lld iscsi --op new ...


However, this won't work - tgtd goes immediately in the background as it 
is still starting, and the first tgtadm commands will fail:

# bash -x tgtd-start
+ tgtd
+ tgtadm --op new --mode target ...
tgtadm: can't connect to the tgt daemon, Connection refused
tgtadm: can't send the request to the tgt daemon, Transport endpoint is 
not connected
+ tgtadm --lld iscsi --op new --mode account ...
tgtadm: can't connect to the tgt daemon, Connection refused
tgtadm: can't send the request to the tgt daemon, Transport endpoint is 
not connected
+ tgtadm --lld iscsi --op bind --mode account --tid 1 ...
tgtadm: can't find the target
+ tgtadm --op new --mode logicalunit --tid 1 --lun 1 ...
tgtadm: can't find the target
+ tgtadm --op bind --mode target --tid 1 -I ALL
tgtadm: can't find the target
+ tgtadm --op new --mode target --tid 2 ...
+ tgtadm --op new --mode logicalunit --tid 2 --lun 1 ...
+ tgtadm --op bind --mode target --tid 2 -I ALL


OK, if tgtd takes longer to start, perhaps it's a good idea to sleep a 
second right after tgtd?

tgtd
sleep 1
tgtadm --op new ...
tgtadm --lld iscsi --op new ...


No, it is not a good idea - if tgtd listens on port 3260 *and* is 
unconfigured yet,  any reconnecting initiator will fail, like below:

end_request: I/O error, dev sdb, sector 7045192
Buffer I/O error on device sdb, logical block 880649
lost page write due to I/O error on sdb
Aborting journal on device sdb.
ext3_abort called.
EXT3-fs error (device sdb): ext3_journal_start_sb: Detected aborted journal
Remounting filesystem read-only
end_request: I/O error, dev sdb, sector 7045880
Buffer I/O error on device sdb, logical block 880735
lost page write due to I/O error on sdb
end_request: I/O error, dev sdb, sector 6728
Buffer I/O error on device sdb, logical block 841
lost page write due to I/O error on sdb
end_request: I/O error, dev sdb, sector 7045192
Buffer I/O error on device sdb, logical block 880649
lost page write due to I/O error on sdb
end_request: I/O error, dev sdb, sector 7045880
Buffer I/O error on device sdb, logical block 880735
lost page write due to I/O error on sdb
__journal_remove_journal_head: freeing b_frozen_data
__journal_remove_journal_head: freeing b_frozen_data


Ouch.

So the only way to start/restart tgtd reliably is to do hacks which are 
needed with yet another iSCSI kernel implementation (IET): use iptables.

iptables <block iSCSI traffic>
tgtd
sleep 1
tgtadm --op new ...
tgtadm --lld iscsi --op new ...
iptables <unblock iSCSI traffic>


A bit ugly, isn't it?
Having to tinker with a firewall in order to start a daemon is by no 
means a sign of a well-tested and mature project.

That's why I asked how many people use stgt in a production environment 
- James was worried about a potential migration path for current users.



-- 
Tomasz Chmielewski
http://wpkg.org



From blackmagic02881 at gmail.com  Tue Feb  5 17:21:47 2008
From: blackmagic02881 at gmail.com (Ming Zhang)
Date: Tue, 05 Feb 2008 11:21:47 -0500
Subject: [Stgt-devel] [Scst-devel] Integration of SCST in the mainstream
	Linux kernel
In-Reply-To: <47A889AB.9090301@wpkg.org>
References: <e2e108260801300029r1a949353k73b30f1f28db0bc9@mail.gmail.com>
	<1201710175.3292.16.camel@localhost.localdomain>
	<47A80CB9.9000805@wpkg.org> <20080205223740L.tomof@acm.org>
	<47A889AB.9090301@wpkg.org>
Message-ID: <1202228507.4096.11.camel@dhcp-117.ibrix.com>

On Tue, 2008-02-05 at 17:07 +0100, Tomasz Chmielewski wrote:
> FUJITA Tomonori schrieb:
> > On Tue, 05 Feb 2008 08:14:01 +0100
> > Tomasz Chmielewski <mangoo at wpkg.org> wrote:
> > 
> >> James Bottomley schrieb:
> >>
> >>> These are both features being independently worked on, are they not?
> >>> Even if they weren't, the combination of the size of SCST in kernel plus
> >>> the problem of having to find a migration path for the current STGT
> >>> users still looks to me to involve the greater amount of work.
> >> I don't want to be mean, but does anyone actually use STGT in
> >> production? Seriously?
> >>
> >> In the latest development version of STGT, it's only possible to stop
> >> the tgtd target daemon using KILL / 9 signal - which also means all
> >> iSCSI initiator connections are corrupted when tgtd target daemon is
> >> started again (kernel upgrade, target daemon upgrade, server reboot etc.).
> > 
> > I don't know what "iSCSI initiator connections are corrupted"
> > mean. But if you reboot a server, how can an iSCSI target
> > implementation keep iSCSI tcp connections?
> 
> The problem with tgtd is that you can't start it (configured) in an
> "atomic" way.
> Usually, one will start tgtd and it's configuration in a script (I 
> replaced some parameters with "..." to make it shorter and more readable):
> 
> 
> tgtd
> tgtadm --op new ...
> tgtadm --lld iscsi --op new ...
> 
> 
> However, this won't work - tgtd goes immediately in the background as it 
> is still starting, and the first tgtadm commands will fail:

this should be a easy fix. start tgtd, get port setup ready in forked
process, then signal its parent that ready to quit. or set port ready in
parent, fork and pass to daemon.


> 
> # bash -x tgtd-start
> + tgtd
> + tgtadm --op new --mode target ...
> tgtadm: can't connect to the tgt daemon, Connection refused
> tgtadm: can't send the request to the tgt daemon, Transport endpoint is 
> not connected
> + tgtadm --lld iscsi --op new --mode account ...
> tgtadm: can't connect to the tgt daemon, Connection refused
> tgtadm: can't send the request to the tgt daemon, Transport endpoint is 
> not connected
> + tgtadm --lld iscsi --op bind --mode account --tid 1 ...
> tgtadm: can't find the target
> + tgtadm --op new --mode logicalunit --tid 1 --lun 1 ...
> tgtadm: can't find the target
> + tgtadm --op bind --mode target --tid 1 -I ALL
> tgtadm: can't find the target
> + tgtadm --op new --mode target --tid 2 ...
> + tgtadm --op new --mode logicalunit --tid 2 --lun 1 ...
> + tgtadm --op bind --mode target --tid 2 -I ALL
> 
> 
> OK, if tgtd takes longer to start, perhaps it's a good idea to sleep a 
> second right after tgtd?
> 
> tgtd
> sleep 1
> tgtadm --op new ...
> tgtadm --lld iscsi --op new ...
> 
> 
> No, it is not a good idea - if tgtd listens on port 3260 *and* is 
> unconfigured yet,  any reconnecting initiator will fail, like below:

this is another easy fix. tgtd started with unconfigured status and then
a tgtadm can configure it and turn it into ready status.


those are really minor usability issue. ( i know it is painful for user,
i agree)


the major problem here is to discuss in architectural wise, which one is
better... linux kernel should have one implementation that is good from
foundation...





> 
> end_request: I/O error, dev sdb, sector 7045192
> Buffer I/O error on device sdb, logical block 880649
> lost page write due to I/O error on sdb
> Aborting journal on device sdb.
> ext3_abort called.
> EXT3-fs error (device sdb): ext3_journal_start_sb: Detected aborted journal
> Remounting filesystem read-only
> end_request: I/O error, dev sdb, sector 7045880
> Buffer I/O error on device sdb, logical block 880735
> lost page write due to I/O error on sdb
> end_request: I/O error, dev sdb, sector 6728
> Buffer I/O error on device sdb, logical block 841
> lost page write due to I/O error on sdb
> end_request: I/O error, dev sdb, sector 7045192
> Buffer I/O error on device sdb, logical block 880649
> lost page write due to I/O error on sdb
> end_request: I/O error, dev sdb, sector 7045880
> Buffer I/O error on device sdb, logical block 880735
> lost page write due to I/O error on sdb
> __journal_remove_journal_head: freeing b_frozen_data
> __journal_remove_journal_head: freeing b_frozen_data
> 
> 
> Ouch.
> 
> So the only way to start/restart tgtd reliably is to do hacks which are 
> needed with yet another iSCSI kernel implementation (IET): use iptables.
> 
> iptables <block iSCSI traffic>
> tgtd
> sleep 1
> tgtadm --op new ...
> tgtadm --lld iscsi --op new ...
> iptables <unblock iSCSI traffic>
> 
> 
> A bit ugly, isn't it?
> Having to tinker with a firewall in order to start a daemon is by no 
> means a sign of a well-tested and mature project.
> 
> That's why I asked how many people use stgt in a production environment 
> - James was worried about a potential migration path for current users.
> 
> 
> 
> -- 
> Tomasz Chmielewski
> http://wpkg.org
> 
> 
> -------------------------------------------------------------------------
> This SF.net email is sponsored by: Microsoft
> Defy all challenges. Microsoft(R) Visual Studio 2008.
> http://clk.atdmt.com/MRT/go/vse0120000070mrt/direct/01/
> _______________________________________________
> Scst-devel mailing list
> Scst-devel at lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/scst-devel
-- 
Ming Zhang


@#$%^ purging memory... (*!%
http://blackmagic02881.wordpress.com/
http://www.linkedin.com/in/blackmagic02881
--------------------------------------------



From tomof at acm.org  Tue Feb  5 17:43:37 2008
From: tomof at acm.org (FUJITA Tomonori)
Date: Wed, 6 Feb 2008 01:43:37 +0900
Subject: [Stgt-devel] [Scst-devel] Integration of SCST in the mainstream
	Linux kernel
In-Reply-To: <47A889AB.9090301@wpkg.org>
References: <47A80CB9.9000805@wpkg.org> <20080205223740L.tomof@acm.org>
	<47A889AB.9090301@wpkg.org>
Message-ID: <20080206014340X.tomof@acm.org>

On Tue, 05 Feb 2008 17:07:07 +0100
Tomasz Chmielewski <mangoo at wpkg.org> wrote:

> FUJITA Tomonori schrieb:
> > On Tue, 05 Feb 2008 08:14:01 +0100
> > Tomasz Chmielewski <mangoo at wpkg.org> wrote:
> > 
> >> James Bottomley schrieb:
> >>
> >>> These are both features being independently worked on, are they not?
> >>> Even if they weren't, the combination of the size of SCST in kernel plus
> >>> the problem of having to find a migration path for the current STGT
> >>> users still looks to me to involve the greater amount of work.
> >> I don't want to be mean, but does anyone actually use STGT in
> >> production? Seriously?
> >>
> >> In the latest development version of STGT, it's only possible to stop
> >> the tgtd target daemon using KILL / 9 signal - which also means all
> >> iSCSI initiator connections are corrupted when tgtd target daemon is
> >> started again (kernel upgrade, target daemon upgrade, server reboot etc.).
> > 
> > I don't know what "iSCSI initiator connections are corrupted"
> > mean. But if you reboot a server, how can an iSCSI target
> > implementation keep iSCSI tcp connections?
> 
> The problem with tgtd is that you can't start it (configured) in an
> "atomic" way.
> Usually, one will start tgtd and it's configuration in a script (I 
> replaced some parameters with "..." to make it shorter and more readable):

Thanks for the details. So the way to stop the daemon is not related
with your problem.

It's easily fixable. Can you start a new thread about this on
stgt-devel mailing list? When we agree on the interface to start the
daemon, I'll implement it.


> tgtd
> tgtadm --op new ...
> tgtadm --lld iscsi --op new ...

(snip)

> So the only way to start/restart tgtd reliably is to do hacks which are 
> needed with yet another iSCSI kernel implementation (IET): use iptables.
> 
> iptables <block iSCSI traffic>
> tgtd
> sleep 1
> tgtadm --op new ...
> tgtadm --lld iscsi --op new ...
> iptables <unblock iSCSI traffic>
> 
> 
> A bit ugly, isn't it?
> Having to tinker with a firewall in order to start a daemon is by no 
> means a sign of a well-tested and mature project.
> 
> That's why I asked how many people use stgt in a production environment 
> - James was worried about a potential migration path for current users.

I don't know how many people use stgt in a production environment but
I'm not sure that this problem prevents many people from using it in a
production environment.

You want to reboot a server running target devices while initiators
connect to it. Rebooting the target server behind the initiators
seldom works. System adminstorators in my workplace reboot storage
devices once a year and tell us to shut down the initiator machines
that use them before that.


From fujita.tomonori at lab.ntt.co.jp  Wed Feb  6 01:12:47 2008
From: fujita.tomonori at lab.ntt.co.jp (FUJITA Tomonori)
Date: Wed, 06 Feb 2008 09:12:47 +0900
Subject: [Stgt-devel] [Scst-devel] Integration of SCST in the
 mainstream	Linux kernel
In-Reply-To: <47A89734.7000009@wpkg.org>
References: <47A889AB.9090301@wpkg.org> <20080206014340X.tomof@acm.org>
	<47A89734.7000009@wpkg.org>
Message-ID: <20080206091247E.fujita.tomonori@lab.ntt.co.jp>

On Tue, 05 Feb 2008 18:04:52 +0100
Tomasz Chmielewski <mangoo at wpkg.org> wrote:

> FUJITA Tomonori schrieb:
> 
> (...)
> 
> >> The problem with tgtd is that you can't start it (configured) in an
> >> "atomic" way.
> >> Usually, one will start tgtd and it's configuration in a script (I 
> >> replaced some parameters with "..." to make it shorter and more readable):
> > 
> > Thanks for the details. So the way to stop the daemon is not related
> > with your problem.
> > 
> > It's easily fixable. Can you start a new thread about this on
> > stgt-devel mailing list? When we agree on the interface to start the
> > daemon, I'll implement it.
> 
> Sure.
> 
> 1. tgtd should not immediately background, but only when it's fully started?
> 
> 2. tgtd should only start to listen if told so? tgtdadm --listen/--nolisten?

I was thinking about something like:

tgtadm --op update --mode sys --name state -v running


> Actually, I only found this iptables workaround a few hours ago, after 
> sending the first mail to lkml.
> At first, I didn't realize my setup screws between tgtd and tgtdadm 
> commands (where I put "sleep 1" command).
> 
> Anyway - if tgtd can be only killed with KILL signal - isn't it risky to 
> do so? For example, something may be still cached, not full transferred? 
> Will SCSI stack take care of it properly?

No risk. It's just like power failure. The file system on the
initiator machine just sees the I/O failure. It will not break your
file system. With ext3, if power failure happens during a transaction,
it just aborts the transaction.


> > You want to reboot a server running target devices while initiators
> > connect to it. Rebooting the target server behind the initiators
> > seldom works. System adminstorators in my workplace reboot storage
> > devices once a year and tell us to shut down the initiator machines
> > that use them before that.
> 
> Technically, it should always work (assuming the timeout on the 
> initiators is bigger than time the target server reboot takes).
> By default, for open-iscsi, timeout is 120 seconds, but in practice 
> there is no problem in increasing it to even many days.

Well, what happens if people try to shut down the initiator box while
the target server is down?

It might work only in an environment which you control everything.


From fujita.tomonori at lab.ntt.co.jp  Wed Feb  6 01:22:52 2008
From: fujita.tomonori at lab.ntt.co.jp (FUJITA Tomonori)
Date: Wed, 06 Feb 2008 09:22:52 +0900
Subject: [Stgt-devel] [Scst-devel] Integration of SCST in
	the	mainstream	Linux kernel
In-Reply-To: <20080205175853.GA2082@osc.edu>
References: <20080206014340X.tomof@acm.org> <47A89734.7000009@wpkg.org>
	<20080205175853.GA2082@osc.edu>
Message-ID: <20080206092252S.fujita.tomonori@lab.ntt.co.jp>

On Tue, 5 Feb 2008 12:58:53 -0500
Pete Wyckoff <pw at osc.edu> wrote:

> mangoo at wpkg.org wrote on Tue, 05 Feb 2008 18:04 +0100:
> > Anyway - if tgtd can be only killed with KILL signal - isn't it risky to 
> > do so? For example, something may be still cached, not full transferred? 
> > Will SCSI stack take care of it properly?
> 
> I too would like a clean shutdown mechanism.  For testing and system
> scripts.  Target should go away cleanly:  drop incoming tasks, wait
> for pending ops to finish and send responses, drop existing
> connections, close 3260, flush logs, exit.  It may be somewhat

I have no problem about having a better shutdown mechanism though
there are tons of high-priority items in my TODO list.


> complex to get right.  Recently iscsid grew a SIGTERM handler too.
> See abd1595d358b1cfe6c059aeea74f6ecdc748f461.

In what git tree is this commit?


From fujita.tomonori at lab.ntt.co.jp  Wed Feb  6 02:31:29 2008
From: fujita.tomonori at lab.ntt.co.jp (FUJITA Tomonori)
Date: Wed, 06 Feb 2008 10:31:29 +0900
Subject: [Stgt-devel] data corruption problems with stgt (aborted
 journal, remounting ro)?
In-Reply-To: <47A4439F.2040409@wpkg.org>
References: <47A43A36.9030307@wpkg.org> <20080202184816P.tomof@acm.org>
	<47A4439F.2040409@wpkg.org>
Message-ID: <20080206103129I.fujita.tomonori@lab.ntt.co.jp>

On Sat, 02 Feb 2008 11:19:11 +0100
Tomasz Chmielewski <mangoo at wpkg.org> wrote:

> FUJITA Tomonori schrieb:
> > On Sat, 02 Feb 2008 10:39:02 +0100
> > Tomasz Chmielewski <mangoo at wpkg.org> wrote:
> > 
> >> FUJITA Tomonori schrieb:
> >>> On Fri, 01 Feb 2008 13:05:41 +0100
> >>> Tomasz Chmielewski <mangoo at wpkg.org> wrote:
> >>>
> >>>> Tomasz Chmielewski schrieb:
> >>>>> Doesn't look my posts get to this list... or is it just lagged a lot? 
> >>>>> Resending.
> >>>>>
> >>>>>
> >>>>> Perhaps I'm doing something wrong - but with stgt I'm facing problems I 
> >>>>> didn't have with IET or SCST.
> >>>>>
> >>>>> Whenever I kill tgtd daemon and start it again (i.e., target server 
> >>>>> restart), the initiator detects an aborted journal and remount the 
> >>>>> device ro.
> >>>>>
> >>>>> Why is it so?
> >>>>>
> >>>>> What is the recommended way to kill the tgtd daemon? It doesn't seem to 
> >>>>> react on TERM signal.
> >>>> Hello, anyone there?
> >>>>
> >>>> Is there a way to restart tgtd daemon or a machine running tgtd, so that 
> >>>> iSCSI connections don't break?
> >>> What does your 'restart tgtd daemon' mean? For me, 'restart' involves
> >>> stopping tgtd daemon and it closes all the iSCSI connections.
> >> Stop it, and start again?
> >>
> >> Imagine you want to upgrade your tgtd daemon, a kernel running on that 
> >> machine, or you have to restart the target machine for some other reason 
> >> (i.e. your target machine died).
> >>
> >> With IET or SCST there is no problem with that - stop the target, and 
> >> iSCSI initiator will try to reconnect.
> > 
> > How did you restart IET?
> > 
> > /etc/init.d/iscsi-target restart
> 
> Yes. Or restarting the whole machine if I changed the kernel (which 
> would use the same iscsi-target script).
> 
> IET has some problems that it breaks when a number of initiators is 
> bigger than 50 or so - which needs two workarounds (iptables, and 
> increasing INCOMING_MAX in ietadm.h).
> 
> I described it a bit here:
> 
> http://blog.wpkg.org/2007/09/09/solving-reliability-and-scalability-problems-with-iscsi/

BTW, this problem should not exist in stgt. There is no limits about
it.


From mangoo at wpkg.org  Wed Feb  6 07:58:57 2008
From: mangoo at wpkg.org (Tomasz Chmielewski)
Date: Wed, 06 Feb 2008 07:58:57 +0100
Subject: [Stgt-devel] [Scst-devel] Integration of SCST in the mainstream
 Linux kernel
In-Reply-To: <20080206091247E.fujita.tomonori@lab.ntt.co.jp>
References: <47A889AB.9090301@wpkg.org>	<20080206014340X.tomof@acm.org>	<47A89734.7000009@wpkg.org>
	<20080206091247E.fujita.tomonori@lab.ntt.co.jp>
Message-ID: <47A95AB1.8090404@wpkg.org>

FUJITA Tomonori schrieb:

(...)

>> Anyway - if tgtd can be only killed with KILL signal - isn't it risky to 
>> do so? For example, something may be still cached, not full transferred? 
>> Will SCSI stack take care of it properly?
> 
> No risk. It's just like power failure. The file system on the
> initiator machine just sees the I/O failure. It will not break your
> file system. With ext3, if power failure happens during a transaction,
> it just aborts the transaction.

Well, if the initiator sees any failure, it is a risk.
I have a target machine which used to freeze about once a week when I 
used IET. No kernel logs, no oops, no panic - just a freeze.

Whenever that happened, I used to just restart that frozen target 
machine, and initiators resumed their work without any failure (and 
filesystems didn't even know SCSI layer had problems with reading and 
writing for the whole night). With write cache enabled this could be 
different of course.

Curiously, this machine doesn't freeze when I use SCST or STGT.

So it's good to know a clean tgtd shutdown is somewhere on a TO DO list.


>>> You want to reboot a server running target devices while initiators
>>> connect to it. Rebooting the target server behind the initiators
>>> seldom works. System adminstorators in my workplace reboot storage
>>> devices once a year and tell us to shut down the initiator machines
>>> that use them before that.
>> Technically, it should always work (assuming the timeout on the 
>> initiators is bigger than time the target server reboot takes).
>> By default, for open-iscsi, timeout is 120 seconds, but in practice 
>> there is no problem in increasing it to even many days.
> 
> Well, what happens if people try to shut down the initiator box while
> the target server is down?

The same should happen as if the initiator is running normally - tasks 
which want to read or write to disk will be in a uninterruptible sleep 
until the initiator can connect again (and continue the shutdown process).


> It might work only in an environment which you control everything.

True, but I guess that's the most of usage scenarios for iSCSI?
iSCSI target is not a web server in anonymous internet, where anyone can 
connect.


-- 
Tomasz Chmielewski
http://wpkg.org



From mangoo at wpkg.org  Wed Feb  6 10:45:54 2008
From: mangoo at wpkg.org (Tomasz Chmielewski)
Date: Wed, 06 Feb 2008 10:45:54 +0100
Subject: [Stgt-devel] yet another tgtd iSCSI misbehaviour (aborted journal,
 remounting ro)
Message-ID: <47A981D2.1050806@wpkg.org>

It seems there is yet another problem (?) in tgtd.

It can be easily reproduced when the initiator crashes and then starts 
again. I tested it only with diskless machines booted off iSCSI.

To reproduce:

1. Start tgtd, apply settings with tgtadm
2. Start a diskless initiator:
  a) a diskless initiator fetches the kernel and the initrd via PXE/tftp
  b) kernel executes initrd; initrd brings the interface up
  c) initrd starts the iSCSI connection with "iscsistart" command from 
open-iscsi
  d) we switch to a new root, system boots fine
  e) IMPORTANT - system starts iscsid now (/etc/init.d/open-iscsi start)

So far, everything was fine and unproblematic.

3. Now, crash your initiator machine (i.e. press reboot button)[1].

4. Initiator starts just fine again - the connection was established 
with "iscsistart".

5. IMPORTANT - start iscsid now (/etc/init.d/open-iscsi start). The 
initiator will report "connection1:0: iscsi: detected conn error (1011)" 
and eventually, will break the connection, remount fs readonly etc. 
scary things will happen.

  a) there is a workaround to that: when initiator reports 
"connection1:0: iscsi: detected conn error..." - kill tgtd, and start it 
again. Initiator will reconnect flawlessly
  b) if you don't kill/start tgtd again, connection will break and fs 
will be remounted ro.


The issue does not happen with IET or SCST.

It looks like:
- tgtd has an established connection with an initiator
- initiator is killed, but tgtd still thinks initiator is connected to it
- initiator connects from the same IP address
- when we start iscsid on the initiator, it confuses tgtd, tgtd breaks 
and has to be restarted


Let me know if you need such tcpdumps (if so, please give me all tcpdump 
command line options you would use):

- point 2e) - clean start of iscsid on the initiator
- point 5) - iscsid start on the initiator when connection breaks
- iscsid start on the initiator, target is SCST


[1] I use kexec here to reboot the machine because it has a buggy BIOS 
(an old Supermicro P4SBR/P4SBE server). Randomly, it doesn't reboot when 
a normal reboot command is used; the system shuts down, but never 
reboots. kexec is a nice workaround for that, but it doesn't close 
network sockets, so the target thinks we're still connected.


-- 
Tomasz Chmielewski
http://wpkg.org


From pw at osc.edu  Wed Feb  6 15:18:17 2008
From: pw at osc.edu (Pete Wyckoff)
Date: Wed, 6 Feb 2008 09:18:17 -0500
Subject: [Stgt-devel] [Scst-devel] Integration of SCST in the	mainstream
	Linux kernel
In-Reply-To: <20080206092252S.fujita.tomonori@lab.ntt.co.jp>
References: <20080206014340X.tomof@acm.org> <47A89734.7000009@wpkg.org>
	<20080205175853.GA2082@osc.edu>
	<20080206092252S.fujita.tomonori@lab.ntt.co.jp>
Message-ID: <20080206141817.GC3415@osc.edu>

fujita.tomonori at lab.ntt.co.jp wrote on Wed, 06 Feb 2008 09:22 +0900:
> On Tue, 5 Feb 2008 12:58:53 -0500
> Pete Wyckoff <pw at osc.edu> wrote:
> 
> > complex to get right.  Recently iscsid grew a SIGTERM handler too.
> > See abd1595d358b1cfe6c059aeea74f6ecdc748f461.
> 
> In what git tree is this commit?

Mike's open-iscsi

git://git.kernel.org/pub/scm/linux/kernel/git/mnc/open-iscsi.git



From landman at scalableinformatics.com  Wed Feb  6 22:38:11 2008
From: landman at scalableinformatics.com (Joe Landman)
Date: Wed, 06 Feb 2008 16:38:11 -0500
Subject: [Stgt-devel] [ofa-general] [ANNOUNCE] open iSCSI over iSER
	target RPM is	available
In-Reply-To: <47A87586.6010904@Voltaire.COM>
References: <47A87586.6010904@Voltaire.COM>
Message-ID: <47AA28C3.7090003@scalableinformatics.com>

Hi Erez

Erez Zilber wrote:
> stgt (SCSI target) is an open-source framework for storage target
> drivers. It supports iSCSI over iSER among other storage target drivers.
> 
> Voltaire added a git tree for stgt that will be added to OFED 1.4:
> http://www2.openfabrics.org/git/?p=~dorons/tgt.git;a=summary
> 
> Until OFED 1.4 gets released, it is possible to install the stgt RPM on
> top of OFED 1.3. For more details about how to install and use stgt,
> please refer to https://wiki.openfabrics.org/tiki-index.php?page=ISER-target
> 
> Some performance numbers that were measured by OSC (using SDR cards):

Is there a 2TB limit on this target? It turns our 6TB partition into a 
2TB lun.

>     * READ: 920 MB/sec
>     * WRITE: 850 MB/sec

Not getting anything even remotely close to this.  Are there more 
details on configuration somewhere?  I followed the web page as indicated.

Joe

> 
> We hope to have DDR measurements numbers soon.
> 


-- 
Joseph Landman, Ph.D
Founder and CEO
Scalable Informatics LLC,
email: landman at scalableinformatics.com
web  : http://www.scalableinformatics.com
        http://jackrabbit.scalableinformatics.com
phone: +1 734 786 8423
fax  : +1 866 888 3112
cell : +1 734 612 4615


From fujita.tomonori at lab.ntt.co.jp  Thu Feb  7 01:20:30 2008
From: fujita.tomonori at lab.ntt.co.jp (FUJITA Tomonori)
Date: Thu, 07 Feb 2008 09:20:30 +0900
Subject: [Stgt-devel] [Scst-devel] Integration of SCST in the mainstream
 Linux kernel
In-Reply-To: <47A95AB1.8090404@wpkg.org>
References: <47A89734.7000009@wpkg.org>
	<20080206091247E.fujita.tomonori@lab.ntt.co.jp>
	<47A95AB1.8090404@wpkg.org>
Message-ID: <20080207092030O.fujita.tomonori@lab.ntt.co.jp>

On Wed, 06 Feb 2008 07:58:57 +0100
Tomasz Chmielewski <mangoo at wpkg.org> wrote:

> FUJITA Tomonori schrieb:
> 
> (...)
> 
> >> Anyway - if tgtd can be only killed with KILL signal - isn't it risky to 
> >> do so? For example, something may be still cached, not full transferred? 
> >> Will SCSI stack take care of it properly?
> > 
> > No risk. It's just like power failure. The file system on the
> > initiator machine just sees the I/O failure. It will not break your
> > file system. With ext3, if power failure happens during a transaction,
> > it just aborts the transaction.
> 
> Well, if the initiator sees any failure, it is a risk.

Then your definition of 'a risk' is different from mine.

For me, I/O failure (due to an unexpected crash of a target) is not a
risk since it doesn't corrupt my file system (of course, I prefer not
see I/O failure). I think, in general, in a storage world, corruption
refers to data corruption stored in a file system (or something like
database).


> I have a target machine which used to freeze about once a week when I 
> used IET. No kernel logs, no oops, no panic - just a freeze.
> 
> Whenever that happened, I used to just restart that frozen target 
> machine, and initiators resumed their work without any failure (and 
> filesystems didn't even know SCSI layer had problems with reading and 
> writing for the whole night). With write cache enabled this could be 
> different of course.

Again, from the perspective of file systems, write cache doesn't
matter. Even with write cache, I/O failure doesn't corrupt file
systems.


> Curiously, this machine doesn't freeze when I use SCST or STGT.
> 
> So it's good to know a clean tgtd shutdown is somewhere on a TO DO list.
> 
> 
> >>> You want to reboot a server running target devices while initiators
> >>> connect to it. Rebooting the target server behind the initiators
> >>> seldom works. System adminstorators in my workplace reboot storage
> >>> devices once a year and tell us to shut down the initiator machines
> >>> that use them before that.
> >> Technically, it should always work (assuming the timeout on the 
> >> initiators is bigger than time the target server reboot takes).
> >> By default, for open-iscsi, timeout is 120 seconds, but in practice 
> >> there is no problem in increasing it to even many days.
> > 
> > Well, what happens if people try to shut down the initiator box while
> > the target server is down?
> 
> The same should happen as if the initiator is running normally - tasks 
> which want to read or write to disk will be in a uninterruptible sleep 
> until the initiator can connect again (and continue the shutdown process).

For me, uninterruptible sleep is really bad. I prefer to have I/O
failure ealier.


> > It might work only in an environment which you control everything.
> 
> True, but I guess that's the most of usage scenarios for iSCSI?
> iSCSI target is not a web server in anonymous internet, where anyone can 
> connect.

For me, no. Commonly, the initiators provides some service to users
(that is, they are web, mail servers, or something eles). So if you
shut down the target server behind the initiators, for example, the
http daemon stops uninterruptibly and gives no response to the
users. As a user, I prefer to see an error after expected timeout than
waiting for an unexpected time and guessing what's wrong.

Anyway, how you manage your systems doesn't matter for me. So it's the
time for me to fix the stuff instead of discussion, I guess.


From fujita.tomonori at lab.ntt.co.jp  Thu Feb  7 02:06:18 2008
From: fujita.tomonori at lab.ntt.co.jp (FUJITA Tomonori)
Date: Thu, 07 Feb 2008 10:06:18 +0900
Subject: [Stgt-devel] [ofa-general] [ANNOUNCE] open iSCSI over
	iSER	target RPM is	available
In-Reply-To: <47AA28C3.7090003@scalableinformatics.com>
References: <47A87586.6010904@Voltaire.COM>
	<47AA28C3.7090003@scalableinformatics.com>
Message-ID: <20080207100618G.fujita.tomonori@lab.ntt.co.jp>

On Wed, 06 Feb 2008 16:38:11 -0500
Joe Landman <landman at scalableinformatics.com> wrote:

> Hi Erez
> 
> Erez Zilber wrote:
> > stgt (SCSI target) is an open-source framework for storage target
> > drivers. It supports iSCSI over iSER among other storage target drivers.
> > 
> > Voltaire added a git tree for stgt that will be added to OFED 1.4:
> > http://www2.openfabrics.org/git/?p=~dorons/tgt.git;a=summary
> > 
> > Until OFED 1.4 gets released, it is possible to install the stgt RPM on
> > top of OFED 1.3. For more details about how to install and use stgt,
> > please refer to https://wiki.openfabrics.org/tiki-index.php?page=ISER-target
> > 
> > Some performance numbers that were measured by OSC (using SDR cards):
> 
> Is there a 2TB limit on this target? It turns our 6TB partition into a 
> 2TB lun.

No, there isn't.


From erezz at Voltaire.COM  Thu Feb  7 09:24:39 2008
From: erezz at Voltaire.COM (Erez Zilber)
Date: Thu, 07 Feb 2008 10:24:39 +0200
Subject: [Stgt-devel] [ewg] Re: [ofa-general] [ANNOUNCE] open iSCSI over
 iSER target RPMis	available
In-Reply-To: <47AA28C3.7090003@scalableinformatics.com>
References: <47A87586.6010904@Voltaire.COM>
	<47AA28C3.7090003@scalableinformatics.com>
Message-ID: <47AAC047.4000306@Voltaire.COM>


> >     * READ: 920 MB/sec
> >     * WRITE: 850 MB/sec
>
> Not getting anything even remotely close to this.  Are there more
> details on configuration somewhere?  I followed the web page as indicated.
>

Are you running iSCSI over TCP or iSCSI over iSER (over InfiniBand)? Our
results are with iSER.

Erez


From landman at scalableinformatics.com  Thu Feb  7 14:50:33 2008
From: landman at scalableinformatics.com (Joe Landman)
Date: Thu, 07 Feb 2008 08:50:33 -0500
Subject: [Stgt-devel] [ewg] Re: [ofa-general] [ANNOUNCE] open iSCSI over
 iSER target RPMis	available
In-Reply-To: <47AAC047.4000306@Voltaire.COM>
References: <47A87586.6010904@Voltaire.COM>
	<47AA28C3.7090003@scalableinformatics.com>
	<47AAC047.4000306@Voltaire.COM>
Message-ID: <47AB0CA9.4020904@scalableinformatics.com>

Erez Zilber wrote:
>>>     * READ: 920 MB/sec
>>>     * WRITE: 850 MB/sec
>> Not getting anything even remotely close to this.  Are there more
>> details on configuration somewhere?  I followed the web page as indicated.
>>
> 
> Are you running iSCSI over TCP or iSCSI over iSER (over InfiniBand)? Our
> results are with iSER.

I followed the instructions on the web pages that were pointed to for 
iSER.  Are there updated pages?  Is there a way to tell whether or not 
the RDMA path is being used?

Thanks.

Joe



-- 
Joseph Landman, Ph.D
Founder and CEO
Scalable Informatics LLC,
email: landman at scalableinformatics.com
web  : http://www.scalableinformatics.com
        http://jackrabbit.scalableinformatics.com
phone: +1 734 786 8423
fax  : +1 866 888 3112
cell : +1 734 612 4615


From bart.vanassche at gmail.com  Thu Feb  7 17:04:38 2008
From: bart.vanassche at gmail.com (Bart Van Assche)
Date: Thu, 7 Feb 2008 17:04:38 +0100
Subject: [Stgt-devel] Strange throughput results with tgtd and iSCSI
Message-ID: <e2e108260802070804qd9903f1yd0156a293d662f43@mail.gmail.com>

Hello,

While running performance tests to compare various iSCSI target
implementations I noticed that tgtd processes data writes slower via
iSCSI for a block transfer size of 1 MB than for 512 KB. Although such
large block transfer sizes are irrelevant when a filesystem is mounted
on top of an iSCSI target, I decided to report this anyway.

Kernel version: 2.6.23.14
STGT version (target): 20071227. The target was set up such that a RAM
disk of 2GB in size was exported via iSCSI.
open-iscsi version (initiator): 2.0.865-1
Performance related settings on the iSCSI initiator:
node.session.iscsi.FirstBurstLength = 262144,
node.session.iscsi.MaxBurstLength = 16776192,
node.conn[0].iscsi.MaxRecvDataSegmentLength = 131072 and
node.conn[0].tcp.window_size = 524288.
Test commands that were run on the initiator:
dd if=/dev/zero of=/dev/sde bs=512K oflag=direct
dd if=/dev/zero of=/dev/sde bs=1M oflag=direct

Results on Ethernet:
For a block size of 512 KB: write throughput of 43 MB/s.
For a block size of 1 MB: write throughput of 15 MB/s.

Results on with IPoIB:
For a block size of 512 KB: write throughput of 95 MB/s.
For a block size of 1 MB: write throughput of 26 MB/s.

Bart Van Assche.


From landman at scalableinformatics.com  Thu Feb  7 17:05:03 2008
From: landman at scalableinformatics.com (Joe Landman)
Date: Thu, 07 Feb 2008 11:05:03 -0500
Subject: [Stgt-devel] Update (Re: open iSCSI over iSER target RPM ...)
In-Reply-To: <47AA28C3.7090003@scalableinformatics.com>
References: <47A87586.6010904@Voltaire.COM>
	<47AA28C3.7090003@scalableinformatics.com>
Message-ID: <47AB2C2F.2090707@scalableinformatics.com>

Update:

[root at woody etc]# dd if=/dev/zero of=/big/local.file bs=256k count=100000
100000+0 records in
100000+0 records out
26214400000 bytes (26 GB) copied, 58.7484 seconds, 446 MB/s

Better. I rebuilt OFED 1.2.5.5.  Are there specific recommended tuning 
guides for iSER?  Backing store in this case are real disks, and we can 
sink/source >750 MB/s on them, so I am not worried about disk IO 
bottlenecks, more worried about bad config of iSCSI/iSER.

BTW:  the 2TB LUN limit I asked about is still here in this code.  Same 
machines (initiator and target) used for SRP reported correct LUN sizes. 
  Here we are using the -868 open-iscsi initiator, and the tgt RPM 
announced.  I would like to dig into this.

This is what I am getting in dmesg for this iSER target:

iscsi: registered transport (tcp)
iscsi: registered transport (iser)
iser: iser_connect:connecting to: 10.2.1.2, port 0xbc0c
iser: iser_cma_handler:event 0 conn ffff81024b9f69c0 id ffff810209748c00
iser: iser_cma_handler:event 2 conn ffff81024b9f69c0 id ffff810209748c00
iser: iser_create_ib_conn_res:setting conn ffff81024b9f69c0 cma_id 
ffff810209748c00: fmr_pool ffff81024bfb32c0 qp ffff8101cb16d600
iser: iser_cma_handler:event 9 conn ffff81024b9f69c0 id ffff810209748c00
iser: iscsi_iser_ep_poll:ib conn ffff81024b9f69c0 rc = 1
scsi13 : iSCSI Initiator over iSER, v.0.1
iser: iscsi_iser_conn_bind:binding iscsi conn ffff81021b65fa90 to 
iser_conn ffff81024b9f69c0
   Vendor: IET       Model: Controller        Rev: 0001
   Type:   RAID                               ANSI SCSI revision: 05
scsi 13:0:0:0: Attached scsi generic sg2 type 12
   Vendor: IET       Model: VIRTUAL-DISK      Rev: 0001
   Type:   Direct-Access                      ANSI SCSI revision: 05
sdc : very big device. try to use READ CAPACITY(16).
sdc : READ CAPACITY(16) failed.
sdc : status=1, message=00, host=0, driver=08
sdc : use 0xffffffff as device size
SCSI device sdc: 4294967296 512-byte hdwr sectors (2199023 MB)
sdc: Write Protect is off
sdc: Mode Sense: 79 00 00 08
SCSI device sdc: drive cache: write back
sdc : very big device. try to use READ CAPACITY(16).
sdc : READ CAPACITY(16) failed.
sdc : status=1, message=00, host=0, driver=08
sdc : use 0xffffffff as device size
SCSI device sdc: 4294967296 512-byte hdwr sectors (2199023 MB)
sdc: Write Protect is off
sdc: Mode Sense: 79 00 00 08
SCSI device sdc: drive cache: write back
  sdc: unknown partition table
sd 13:0:0:1: Attached scsi disk sdc
sd 13:0:0:1: Attached scsi generic sg3 type 0


and this is what we get in SRP

scsi6 : SRP.T10:0008F104039862A4
   Vendor: SCST_BIO  Model: vdisk0            Rev:  096
   Type:   Direct-Access                      ANSI SCSI revision: 04
sdc : very big device. try to use READ CAPACITY(16).
SCSI device sdc: 12693355130 512-byte hdwr sectors (6498998 MB)
sdc: Write Protect is off
sdc: Mode Sense: 6b 00 10 08
SCSI device sdc: drive cache: write back w/ FUA


This looks suspiciously like a 2^32 limit somewhere.


Our exported device is

[root at jr1 ~]# parted /dev/sdb print

Model: Areca jrvs1 (scsi)
Disk /dev/sdb: 6500GB
Sector size (logical/physical): 512B/512B
Partition Table: loop

Number  Start   End     Size    File system  Flags
  1      0.00kB  6500GB  6500GB  xfs


and this is what tgtadm reports

[root at jr1 ~]# tgtadm --lld iscsi --op show --mode target
Target 1: iqn.2001-04.com.jr1-jackrabbit.small
     System information:
         Driver: iscsi
         Status: running
     I_T nexus information:
         I_T nexus: 4
             Initiator: iqn.1996-04.voltaire.com:01:dfa8888a3fd
             Connection: 0
                 RDMA IP Address: 10.2.1.1
     LUN information:
         LUN: 0
             Type: controller
             SCSI ID: deadbeaf1:0
             SCSI SN: beaf10
             Size: 0
             Online: No
             Poweron/Reset: Yes
             Removable media: No
             Backing store: No backing store
         LUN: 1
             Type: disk
             SCSI ID: deadbeaf1:1
             SCSI SN: beaf11
             Size: 5T
             Online: Yes
             Poweron/Reset: No
             Removable media: No
             Backing store: /dev/sdb
     Account information:
     ACL information:
         10.2.1.1

So it looks like the LUN 1 is approximately correct (5T ???) on the 
target, and incorrect when the initiator asks for it.

Please note that I have successfully used the full 6+TB as an iSCSI 
target using the SCST-iscsi code, so I do know that the initiator works 
correctly.

Is there a source RPM/tree for this target?

Joe Landman wrote:
> Hi Erez
> 
> Erez Zilber wrote:
>> stgt (SCSI target) is an open-source framework for storage target
>> drivers. It supports iSCSI over iSER among other storage target drivers.
>>
>> Voltaire added a git tree for stgt that will be added to OFED 1.4:
>> http://www2.openfabrics.org/git/?p=~dorons/tgt.git;a=summary
>>
>> Until OFED 1.4 gets released, it is possible to install the stgt RPM on
>> top of OFED 1.3. For more details about how to install and use stgt,
>> please refer to 
>> https://wiki.openfabrics.org/tiki-index.php?page=ISER-target
>>
>> Some performance numbers that were measured by OSC (using SDR cards):
> 
> Is there a 2TB limit on this target? It turns our 6TB partition into a 
> 2TB lun.
> 
>>     * READ: 920 MB/sec
>>     * WRITE: 850 MB/sec
> 
> Not getting anything even remotely close to this.  Are there more 
> details on configuration somewhere?  I followed the web page as indicated.
> 
> Joe
> 
>>
>> We hope to have DDR measurements numbers soon.
>>
> 
> 


-- 
Joseph Landman, Ph.D
Founder and CEO
Scalable Informatics LLC,
email: landman at scalableinformatics.com
web  : http://www.scalableinformatics.com
        http://jackrabbit.scalableinformatics.com
phone: +1 734 786 8423
fax  : +1 866 888 3112
cell : +1 734 612 4615


From pw at osc.edu  Thu Feb  7 17:57:03 2008
From: pw at osc.edu (Pete Wyckoff)
Date: Thu, 7 Feb 2008 11:57:03 -0500
Subject: [Stgt-devel] Strange throughput results with tgtd and iSCSI
In-Reply-To: <e2e108260802070804qd9903f1yd0156a293d662f43@mail.gmail.com>
References: <e2e108260802070804qd9903f1yd0156a293d662f43@mail.gmail.com>
Message-ID: <20080207165703.GA8048@osc.edu>

bart.vanassche at gmail.com wrote on Thu, 07 Feb 2008 17:04 +0100:
> While running performance tests to compare various iSCSI target
> implementations I noticed that tgtd processes data writes slower via
> iSCSI for a block transfer size of 1 MB than for 512 KB. Although such
> large block transfer sizes are irrelevant when a filesystem is mounted
> on top of an iSCSI target, I decided to report this anyway.
> 
> Kernel version: 2.6.23.14
> STGT version (target): 20071227. The target was set up such that a RAM
> disk of 2GB in size was exported via iSCSI.
> open-iscsi version (initiator): 2.0.865-1
> Performance related settings on the iSCSI initiator:
> node.session.iscsi.FirstBurstLength = 262144,
> node.session.iscsi.MaxBurstLength = 16776192,
> node.conn[0].iscsi.MaxRecvDataSegmentLength = 131072 and
> node.conn[0].tcp.window_size = 524288.
> Test commands that were run on the initiator:
> dd if=/dev/zero of=/dev/sde bs=512K oflag=direct
> dd if=/dev/zero of=/dev/sde bs=1M oflag=direct
> 
> Results on Ethernet:
> For a block size of 512 KB: write throughput of 43 MB/s.
> For a block size of 1 MB: write throughput of 15 MB/s.
> 
> Results on with IPoIB:
> For a block size of 512 KB: write throughput of 95 MB/s.
> For a block size of 1 MB: write throughput of 26 MB/s.

Nice report.  I'll try to take a look at the ethernet numbers first.

Please show me the output of "iscsiadm -m session -P 3".  It has the
actual negotiated connection params, which will differ from what you
quote from the iscsid.conf above.  You may find it handy to do "rm
-rf /var/lib/iscsi/*/*" to destroy all iscsi state if you find the
negotiated values are not what you expect.

My nodes only have 2G.  When I build a tmpfs, put in a 2G file,
export that, these tests essentially measure swap performance of the
system.  I get 12 MB/s for writes at both block sizes.  Running
"vmstat 2" on the target shows it is busy swapping.

Redoing the tests at 1G keeps it all in RAM for me.  Then I get 95
MB/s at 512 kB and 88 MB/s at 1MB, so confirming your performance
disparity, but not finding numbers nearly so bad.

Here's the good bits from iscsiadm -m session -P 3 here:

    Negotiated iSCSI params:
    ************************
    HeaderDigest: None
    DataDigest: None
    MaxRecvDataSegmentLength: 131072
    MaxXmitDataSegmentLength: 131072
    FirstBurstLength: 131072
    MaxBurstLength: 16776192
    ImmediateData: Yes
    InitialR2T: Yes
    MaxOutstandingR2T: 1

and the script I use to try to replicate your seutp:

    #!/bin/bash
    ./tgtadm --lld iscsi --mode target --op new --tid 1 --targetname $(hostname)
    ./tgtadm --lld iscsi --mode target --op bind --tid 1 --initiator-address ALL
    ./tgtadm --lld iscsi --mode logicalunit --op new --tid 1 --lun 1 --backing-store /tmp/ram/tgt-ram-1g-pw
    ./tgtadm --lld iscsi --mode logicalunit --op update --tid 1 --lun 1 --name=scsi_sn --value=$(hostname)
    ./tgtadm --lld iscsi --mode target --op update --tid 1 --name MaxRecvDataSegmentLength --value 131072
    ./tgtadm --lld iscsi --mode target --op update --tid 1 --name MaxXmitDataSegmentLength --value 131072
    ./tgtadm --lld iscsi --mode target --op update --tid 1 --name FirstBurstLength --value 131072
    ./tgtadm --lld iscsi --mode target --op update --tid 1 --name MaxBurstLength --value 16776192

Show me what you have and I'll try to replicate.  The 88 vs 95 is
enough in itself to cause alarm, which we can try to understand, but
I'd also like to make sure that you can get numbers in this
neighborhood at least.

		-- Pete


From pw at osc.edu  Thu Feb  7 19:17:13 2008
From: pw at osc.edu (Pete Wyckoff)
Date: Thu, 7 Feb 2008 13:17:13 -0500
Subject: [Stgt-devel] [PATCH 1/1] iscsi tcp nodelay
Message-ID: <20080207181951.0573F8B7AE@titan.sf.osc.edu>

Set TCP_NODELAY to avoid big latency between sending data-in and sending
command response on reads, and to make sure the response goes out
promptly for completed writes.

Signed-off-by: Pete Wyckoff <pw at osc.edu>
---
 usr/iscsi/iscsi_tcp.c |   13 +++++++++++++
 1 files changed, 13 insertions(+), 0 deletions(-)

diff --git a/usr/iscsi/iscsi_tcp.c b/usr/iscsi/iscsi_tcp.c
index c4d08a1..09ed0e5 100644
--- a/usr/iscsi/iscsi_tcp.c
+++ b/usr/iscsi/iscsi_tcp.c
@@ -78,6 +78,15 @@ static int set_keepalive(int fd)
 	return 0;
 }
 
+static int set_nodelay(int fd)
+{
+	int ret, opt;
+
+	opt = 1;
+	ret = setsockopt(fd, IPPROTO_TCP, TCP_NODELAY, &opt, sizeof(opt));
+	return ret;
+}
+
 static void accept_connection(int afd, int events, void *data)
 {
 	struct sockaddr_storage from;
@@ -99,6 +108,10 @@ static void accept_connection(int afd, int events, void *data)
 	if (ret)
 		goto out;
 
+	ret = set_nodelay(fd);
+	if (ret)
+		goto out;
+
 	tcp_conn = zalloc(sizeof(*tcp_conn));
 	if (!tcp_conn)
 		goto out;
-- 
1.5.3.8



From pw at osc.edu  Thu Feb  7 19:20:16 2008
From: pw at osc.edu (Pete Wyckoff)
Date: Thu, 7 Feb 2008 13:20:16 -0500
Subject: [Stgt-devel] Strange throughput results with tgtd and iSCSI
In-Reply-To: <20080207165703.GA8048@osc.edu>
References: <e2e108260802070804qd9903f1yd0156a293d662f43@mail.gmail.com>
	<20080207165703.GA8048@osc.edu>
Message-ID: <20080207182016.GA8115@osc.edu>

pw at osc.edu wrote on Thu, 07 Feb 2008 11:57 -0500:
> bart.vanassche at gmail.com wrote on Thu, 07 Feb 2008 17:04 +0100:
> > Results on Ethernet:
> > For a block size of 512 KB: write throughput of 43 MB/s.
> > For a block size of 1 MB: write throughput of 15 MB/s.
> 
> Redoing the tests at 1G keeps it all in RAM for me.  Then I get 95
> MB/s at 512 kB and 88 MB/s at 1MB, so confirming your performance
> disparity, but not finding numbers nearly so bad.

I looked at logs on tgtd.  These are writes.  With my kernel, the 1M
case just sends two 512k requests back-to-back due to initiator
block limits.  So there are an identical series of requests in both
cases.

The time between reception of a new command request and sending the
status response is constant for both 512k and 1M cases.  The time
when the target is idle varies, though.  Initially the idle time
between commands is identical in both 512k and 1M, until about
request number 2000 out of 2048.  Then a delay of 40 ms shows up
between commands.  What is the initiator doing here?

Turns out it is a TCP artifact.  I've been carrying around a patch
to tgtd to turn on O_NDELAY.  The numbers I reported above are for
stock tgtd.  With the O_NDELAY patch, these change to 95 MB/s at 512
kB (same) and 102 MB/s at 1M (better).  Presumably Bart runs for
longer (2 GB total), and sees more of these 40 ms delays.  I did not
analyze why the Nagle algorithm decides to hold packets when it
does, just was happy to turn it off.

I'll submit the patch to Tomo now.

		-- Pete


From robin.humble+stgt at anu.edu.au  Fri Feb  8 03:36:20 2008
From: robin.humble+stgt at anu.edu.au (Robin Humble)
Date: Thu, 7 Feb 2008 21:36:20 -0500
Subject: [Stgt-devel] [PATCH 1/2] iSER throttling
Message-ID: <20080208023619.GA23845@porcupine.cita.utoronto.ca>

with a few iSER writers it's easy to run out of RDMA areas in the tgtd
mempool. currently tgtd gives up in this case, leading to a mess.
these 2 patches throttle iSER requests so that there are always enough
RDMA areas left in the mempool left to do i/o.

it's been tested with 1 to 16 initiators and it seems to work.

funtionality of the iSER code is unchanged when there's 1 initiator and
1 target.
functionality of the tcp transport code is unchanged, although these
patches add enough framework that the tcp code could have throttling
enabled sometime in the future.

possible extensions to this work are
 - to tell the user when they are frequently running low on RDMA areas
   and suggest that they recompile with a higher number
 - to make the RDMA mempool size a runtime configurable so that it can
   be increased without a recompile
 - to add tcp accounting and throttling

cheers,
robin

  patch 01 - add reference counting to iser code

Signed-off-by: Robin Humble <robin.humble+stgt at anu.edu.au>
--
diff -ruN ../tgt/usr/iscsi/iscsi_rdma.c ./usr/iscsi/iscsi_rdma.c
--- ../tgt/usr/iscsi/iscsi_rdma.c	2008-01-23 12:50:27.000000000 +1100
+++ ./usr/iscsi/iscsi_rdma.c	2008-01-24 18:22:32.000000000 +1100
@@ -196,6 +196,9 @@
 
 	/* free and allocated mempool entries */
 	struct list_head mempool_free, mempool_alloc;
+
+        /* rdma mempool accounting */
+        int mempool_used;
 };
 
 static struct iscsi_transport iscsi_iser;
@@ -213,6 +216,7 @@
 
 /* all iser connections */
 static struct list_head iser_conn_list;
+static int iser_conn_cnt;
 
 /* if any task needs an rdma read or write slot to proceed */
 static int waiting_rdma_slot;
@@ -555,6 +559,7 @@
 	dev->mempool_listbuf = listbuf;
 	INIT_LIST_HEAD(&dev->mempool_free);
 	INIT_LIST_HEAD(&dev->mempool_alloc);
+	dev->mempool_used = 0;
 
 	for (i = 0; i < mempool_num; i++) {
 		mp = (void *) listbuf;
@@ -793,6 +798,7 @@
 	dprintf("established conn %p\n", ci);
 	list_del(&ci->iser_conn_list);
 	list_add(&ci->iser_conn_list, &iser_conn_list);
+	iser_conn_cnt++;
 }
 
 static void iser_disconnect(struct rdma_cm_event *ev)
@@ -1167,6 +1173,7 @@
 	INIT_LIST_HEAD(&temp_conn);
 	num_tx_ready = 0;
 	num_rx_ready = 0;
+	iser_conn_cnt = 0;
 	ret = tgt_counter_event_add(&num_tx_ready, iser_tx_progress, NULL);
 	ret = tgt_counter_event_add(&num_rx_ready, iser_rx_progress, NULL);
 	return ret;
@@ -1565,6 +1572,7 @@
 	dprintf("did rdma_disconnect\n");
 	list_del(&ci->conn_tx_ready);
 	list_del(&ci->iser_conn_list);
+	iser_conn_cnt--;
 	ci->draining = 1;
 	return 0;
 }
@@ -1656,7 +1680,9 @@
 	mem = list_entry(dev->mempool_free.next, typeof(*mem), list);
 	list_del(&mem->list);
 	list_add(&mem->list, &dev->mempool_alloc);
-	dprintf("malloc %p sz %zu\n", mem->buf, sz);
+	dev->mempool_used++;
+	dprintf("malloc %p sz %zu used %d\n", mem->buf, sz, dev->mempool_used);
+
 	return mem->buf;
 }
 
@@ -1682,6 +1708,7 @@
 	}
 	list_del(&mem->list);
 	list_add(&mem->list, &dev->mempool_free);
+	dev->mempool_used--;
 }
 
 static int iscsi_rdma_getsockname(struct iscsi_connection *conn,


From robin.humble+stgt at anu.edu.au  Fri Feb  8 03:38:51 2008
From: robin.humble+stgt at anu.edu.au (Robin Humble)
Date: Thu, 7 Feb 2008 21:38:51 -0500
Subject: [Stgt-devel] [PATCH 2/2] iSER throttling
Message-ID: <20080208023851.GA25361@porcupine.cita.utoronto.ca>

  patch 02 - limit iSER requests so there are always RDMA mempools
             available

Signed-off-by: Robin Humble <robin.humble+stgt at anu.edu.au>
--
diff -ruN ../tgt/usr/iscsi/iscsid.c ./usr/iscsi/iscsid.c
--- ../tgt/usr/iscsi/iscsid.c	2008-01-24 18:45:27.000000000 +1100
+++ ./usr/iscsi/iscsid.c	2008-01-24 18:43:34.000000000 +1100
@@ -893,6 +893,21 @@
 	}
 }
 
+static int max_queue_cmds_available(struct iscsi_connection *conn)
+{
+	int max_queue_cmd;
+	int max_safe_cmds;
+
+	max_safe_cmds = conn->tp->queue_cmds_available(conn);
+	if (max_safe_cmds < 0) {
+		eprintf("iSER max_safe_cmds %d < 0\n", max_safe_cmds );
+		return 0;
+	}
+	max_queue_cmd = min( MAX_QUEUE_CMD, max_safe_cmds );
+
+	return max_queue_cmd;
+}
+
 static int iscsi_cmd_rsp_build(struct iscsi_task *task)
 {
 	struct iscsi_connection *conn = task->conn;
@@ -908,7 +923,8 @@
 	rsp->cmd_status = scsi_get_result(&task->scmd);
 	rsp->statsn = cpu_to_be32(conn->stat_sn++);
 	rsp->exp_cmdsn = cpu_to_be32(conn->session->exp_cmd_sn);
-	rsp->max_cmdsn = cpu_to_be32(conn->session->exp_cmd_sn + MAX_QUEUE_CMD);
+	rsp->max_cmdsn = cpu_to_be32(conn->session->exp_cmd_sn +
+				     max_queue_cmds_available(conn));
 
 	calc_residual(rsp, task);
 
@@ -935,7 +951,8 @@
 	rsp->cmd_status = SAM_STAT_CHECK_CONDITION;
 	rsp->statsn = cpu_to_be32(conn->stat_sn++);
 	rsp->exp_cmdsn = cpu_to_be32(conn->session->exp_cmd_sn);
-	rsp->max_cmdsn = cpu_to_be32(conn->session->exp_cmd_sn + MAX_QUEUE_CMD);
+	rsp->max_cmdsn = cpu_to_be32(conn->session->exp_cmd_sn +
+				     max_queue_cmds_available(conn));
 
 	calc_residual(rsp, task);
 
@@ -989,7 +1006,8 @@
 		datalen = conn->data_inout_max_length;
 
 	rsp->exp_cmdsn = cpu_to_be32(conn->session->exp_cmd_sn);
-	rsp->max_cmdsn = cpu_to_be32(conn->session->exp_cmd_sn + MAX_QUEUE_CMD);
+	rsp->max_cmdsn = cpu_to_be32(conn->session->exp_cmd_sn +
+				     max_queue_cmds_available(conn));
 
 	conn->rsp.datasize = datalen;
 	hton24(rsp->dlength, datalen);
@@ -1523,6 +1541,7 @@
 	conn->exp_stat_sn = be32_to_cpu(req->exp_statsn);
 
 	len = ntoh24(req->dlength);
+
 	task = iscsi_alloc_task(conn, 0, len);
 	if (task)
 		conn->rx_task = task;
@@ -1639,7 +1658,8 @@
 	rsp->itt = task->req.itt;
 	rsp->statsn = cpu_to_be32(conn->stat_sn++);
 	rsp->exp_cmdsn = cpu_to_be32(conn->session->exp_cmd_sn);
-	rsp->max_cmdsn = cpu_to_be32(conn->session->exp_cmd_sn + MAX_QUEUE_CMD);
+	rsp->max_cmdsn = cpu_to_be32(conn->session->exp_cmd_sn +
+				     max_queue_cmds_available(conn));
 
 	return 0;
 }
@@ -1662,7 +1682,8 @@
 		rsp->ttt = cpu_to_be32(ISCSI_RESERVED_TAG);
 		rsp->statsn = cpu_to_be32(conn->stat_sn++);
 		rsp->exp_cmdsn = cpu_to_be32(conn->session->exp_cmd_sn);
-		rsp->max_cmdsn = cpu_to_be32(conn->session->exp_cmd_sn + MAX_QUEUE_CMD);
+		rsp->max_cmdsn = cpu_to_be32(conn->session->exp_cmd_sn +
+					     max_queue_cmds_available(conn));
 
 		/* TODO: honor max_burst */
 		conn->rsp.datasize = task->len;
@@ -1686,7 +1707,8 @@
 
 	rsp->statsn = cpu_to_be32(conn->stat_sn++);
 	rsp->exp_cmdsn = cpu_to_be32(conn->session->exp_cmd_sn);
-	rsp->max_cmdsn = cpu_to_be32(conn->session->exp_cmd_sn + MAX_QUEUE_CMD);
+	rsp->max_cmdsn = cpu_to_be32(conn->session->exp_cmd_sn +
+				     max_queue_cmds_available(conn));
 
 	return 0;
 }
diff -ruN ../tgt/usr/iscsi/iscsi_rdma.c ./usr/iscsi/iscsi_rdma.c
--- ../tgt/usr/iscsi/iscsi_rdma.c	2008-01-24 18:45:44.000000000 +1100
+++ ./usr/iscsi/iscsi_rdma.c	2008-01-24 18:43:34.000000000 +1100
@@ -1643,6 +1643,22 @@
 	}
 }
 
+/*
+ * we know how many iSER connections we have, and also how many areas are
+ * allocated from our mempool, so we can trivially calculate how many
+ * more cmds we can handle without running out of rdma areas.
+ */
+static int iscsi_rdma_queue_cmds_available(struct iscsi_connection *conn)
+{
+	struct conn_info *ci = RDMA_CONN(conn);
+	struct iser_device *dev = ci->dev;
+	int cmds;
+
+	cmds = (mempool_num - dev->mempool_used)/iser_conn_cnt;
+
+	return cmds;
+}
+
 static void *iscsi_rdma_alloc_data_buf(struct iscsi_connection *conn,
 				       size_t sz)
 {
@@ -1735,6 +1751,7 @@
 	.ep_show		= iscsi_rdma_show,
 	.ep_event_modify	= iscsi_rdma_event_modify,
 	.alloc_data_buf		= iscsi_rdma_alloc_data_buf,
+	.queue_cmds_available	= iscsi_rdma_queue_cmds_available,
 	.free_data_buf		= iscsi_rdma_free_data_buf,
 	.ep_getsockname		= iscsi_rdma_getsockname,
 	.ep_getpeername		= iscsi_rdma_getpeername,
diff -ruN ../tgt/usr/iscsi/iscsi_tcp.c ./usr/iscsi/iscsi_tcp.c
--- ../tgt/usr/iscsi/iscsi_tcp.c	2008-01-24 18:45:27.000000000 +1100
+++ ./usr/iscsi/iscsi_tcp.c	2008-01-24 18:43:34.000000000 +1100
@@ -36,6 +36,8 @@
 #include "tgtd.h"
 #include "util.h"
 
+#define MAX_TCP_QUEUE_CMD	128
+
 static void iscsi_tcp_event_handler(int fd, int events, void *data);
 
 static struct iscsi_transport iscsi_tcp;
@@ -322,6 +324,10 @@
 	free(task);
 }
 
+static int iscsi_tcp_queue_cmds_available(struct iscsi_connection *conn) {
+	return MAX_TCP_QUEUE_CMD;
+}
+
 static void *iscsi_tcp_alloc_data_buf(struct iscsi_connection *conn, size_t sz)
 {
 	return valloc(sz);
@@ -365,6 +371,7 @@
 	.ep_show		= iscsi_tcp_show,
 	.ep_event_modify	= iscsi_event_modify,
 	.alloc_data_buf		= iscsi_tcp_alloc_data_buf,
+	.queue_cmds_available	= iscsi_tcp_queue_cmds_available,
 	.free_data_buf		= iscsi_tcp_free_data_buf,
 	.ep_getsockname		= iscsi_tcp_getsockname,
 	.ep_getpeername		= iscsi_tcp_getpeername,
diff -ruN ../tgt/usr/iscsi/transport.h ./usr/iscsi/transport.h
--- ../tgt/usr/iscsi/transport.h	2008-01-24 18:45:27.000000000 +1100
+++ ./usr/iscsi/transport.h	2008-01-24 18:43:34.000000000 +1100
@@ -32,6 +32,7 @@
 	int (*ep_show)(struct iscsi_connection *conn, char *buf, int rest);
 	void (*ep_event_modify)(struct iscsi_connection *conn, int events);
 	void *(*alloc_data_buf)(struct iscsi_connection *conn, size_t sz);
+	int (*queue_cmds_available)(struct iscsi_connection *conn);
 	void (*free_data_buf)(struct iscsi_connection *conn, void *buf);
 	int (*ep_getsockname)(struct iscsi_connection *conn,
 			      struct sockaddr *sa, socklen_t *len);


From robin.humble+stgt at anu.edu.au  Fri Feb  8 03:07:22 2008
From: robin.humble+stgt at anu.edu.au (Robin Humble)
Date: Thu, 7 Feb 2008 21:07:22 -0500
Subject: [Stgt-devel] iSER multiple readers
Message-ID: <20080208020722.GA5146@porcupine.cita.utoronto.ca>

Hi,

I think I'm seeing iSER read corruption problems.
a) in stock centos5.1 when not using kernel 2.6.22.6 I get read
   corruption with just a single reader
b) every kernel/OS/ofed combination that I've tried when there are
   multiple simultaneous readers

the multiple reader problem happens whether the data is read from
multiple luns or clients or... well, just multiple reads to a single
tgtd doing iSER seems to be enough to cause it.

I'm hoping these problems are just something that I've broken in my
setup... previously 2.6.18-52.el5 + centos5 worked (in the single
reader case) but I can't make it work now.

is anyone else seeing easy read corruption?

the easiest way I can reproduce it is:
 initiator side - write data:
   lmdd if=internal of=/dev/sdc opat=1 bs=1M count=1000
 target side - check that the file is ok (it is):
   lmdd of=internal if=/mnt/ramdisk/file ipat=1 bs=1M count=1000 mismatch=1
 initiator side - read and check data (is sometimes ok):
   lmdd of=internal if=/dev/sdc ipat=1 bs=1M count=1000 mismatch=1
 initiator side - read data with 2 processes at once (always fails):
   lmdd of=internal if=/dev/sdc ipat=1 bs=1M count=1000 mismatch=1 &
   lmdd of=internal if=/dev/sdc ipat=1 bs=1M count=1000 mismatch=1 &

I'm using the kernel git tree of stgt.
I don't see any problems when using TCP IPoIB.

cheers,
robin


From fujita.tomonori at lab.ntt.co.jp  Fri Feb  8 03:05:06 2008
From: fujita.tomonori at lab.ntt.co.jp (FUJITA Tomonori)
Date: Fri, 08 Feb 2008 11:05:06 +0900
Subject: [Stgt-devel] [PATCH 1/1] iscsi tcp nodelay
In-Reply-To: <20080207181951.0573F8B7AE@titan.sf.osc.edu>
References: <20080207181951.0573F8B7AE@titan.sf.osc.edu>
Message-ID: <20080208110506Y.fujita.tomonori@lab.ntt.co.jp>

On Thu, 7 Feb 2008 13:17:13 -0500
Pete Wyckoff <pw at osc.edu> wrote:

> Set TCP_NODELAY to avoid big latency between sending data-in and sending
> command response on reads, and to make sure the response goes out
> promptly for completed writes.
> 
> Signed-off-by: Pete Wyckoff <pw at osc.edu>
> ---
>  usr/iscsi/iscsi_tcp.c |   13 +++++++++++++
>  1 files changed, 13 insertions(+), 0 deletions(-)

Thanks a lot!

Yeah, this is a must-have trick for low latency. IET has the same
trick but somehow I forgot to add this to tgt.


From fujita.tomonori at lab.ntt.co.jp  Fri Feb  8 03:12:37 2008
From: fujita.tomonori at lab.ntt.co.jp (FUJITA Tomonori)
Date: Fri, 08 Feb 2008 11:12:37 +0900
Subject: [Stgt-devel] Strange throughput results with tgtd and iSCSI
In-Reply-To: <20080207182016.GA8115@osc.edu>
References: <e2e108260802070804qd9903f1yd0156a293d662f43@mail.gmail.com>
	<20080207165703.GA8048@osc.edu> <20080207182016.GA8115@osc.edu>
Message-ID: <20080208111237G.fujita.tomonori@lab.ntt.co.jp>

On Thu, 7 Feb 2008 13:20:16 -0500
Pete Wyckoff <pw at osc.edu> wrote:

> pw at osc.edu wrote on Thu, 07 Feb 2008 11:57 -0500:
> > bart.vanassche at gmail.com wrote on Thu, 07 Feb 2008 17:04 +0100:
> > > Results on Ethernet:
> > > For a block size of 512 KB: write throughput of 43 MB/s.
> > > For a block size of 1 MB: write throughput of 15 MB/s.
> > 
> > Redoing the tests at 1G keeps it all in RAM for me.  Then I get 95
> > MB/s at 512 kB and 88 MB/s at 1MB, so confirming your performance
> > disparity, but not finding numbers nearly so bad.
> 
> I looked at logs on tgtd.  These are writes.  With my kernel, the 1M
> case just sends two 512k requests back-to-back due to initiator
> block limits.  So there are an identical series of requests in both
> cases.

With the current git tree, it's possible to send a 1MB SCSI request, I
think.


From fujita.tomonori at lab.ntt.co.jp  Fri Feb  8 03:09:44 2008
From: fujita.tomonori at lab.ntt.co.jp (FUJITA Tomonori)
Date: Fri, 08 Feb 2008 11:09:44 +0900
Subject: [Stgt-devel] Update (Re: open iSCSI over iSER target RPM ...)
In-Reply-To: <47AB2C2F.2090707@scalableinformatics.com>
References: <47A87586.6010904@Voltaire.COM>
	<47AA28C3.7090003@scalableinformatics.com>
	<47AB2C2F.2090707@scalableinformatics.com>
Message-ID: <20080208110944W.fujita.tomonori@lab.ntt.co.jp>

On Thu, 07 Feb 2008 11:05:03 -0500
Joe Landman <landman at scalableinformatics.com> wrote:

> Update:
> 
> [root at woody etc]# dd if=/dev/zero of=/big/local.file bs=256k count=100000
> 100000+0 records in
> 100000+0 records out
> 26214400000 bytes (26 GB) copied, 58.7484 seconds, 446 MB/s
> 
> Better. I rebuilt OFED 1.2.5.5.  Are there specific recommended tuning 
> guides for iSER?  Backing store in this case are real disks, and we can 
> sink/source >750 MB/s on them, so I am not worried about disk IO 
> bottlenecks, more worried about bad config of iSCSI/iSER.
> 
> BTW:  the 2TB LUN limit I asked about is still here in this code.  Same 
> machines (initiator and target) used for SRP reported correct LUN sizes. 
>   Here we are using the -868 open-iscsi initiator, and the tgt RPM 
> announced.  I would like to dig into this.

Thanks a lot,

I thought that I tested tgt with >2TB devices but seems that I
didn't. I'll try to fix the problem shortly.


From bart.vanassche at gmail.com  Fri Feb  8 14:52:12 2008
From: bart.vanassche at gmail.com (Bart Van Assche)
Date: Fri, 8 Feb 2008 14:52:12 +0100
Subject: [Stgt-devel] [PATCH 1/1] iscsi tcp nodelay
In-Reply-To: <20080208110506Y.fujita.tomonori@lab.ntt.co.jp>
References: <20080207181951.0573F8B7AE@titan.sf.osc.edu>
	<20080208110506Y.fujita.tomonori@lab.ntt.co.jp>
Message-ID: <e2e108260802080552q7868ae72of00e3d7822e6667b@mail.gmail.com>

On Feb 8, 2008 3:05 AM, FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp> wrote:
> Yeah, this is a must-have trick for low latency. IET has the same
> trick but somehow I forgot to add this to tgt.

I have retested tgt-20071227 with the TCP_NODELAY patch on an 1GB/s IB
network with a RAM disk target. For realistic block transfer sizes (<=
64 KB) latency is unchanged and throughput improved slightly (5% for
reads and 9% for writes).

Bart Van Assche.


From pw at osc.edu  Fri Feb  8 20:11:33 2008
From: pw at osc.edu (Pete Wyckoff)
Date: Fri, 8 Feb 2008 14:11:33 -0500
Subject: [Stgt-devel] iSER multiple readers
In-Reply-To: <20080208020722.GA5146@porcupine.cita.utoronto.ca>
References: <20080208020722.GA5146@porcupine.cita.utoronto.ca>
Message-ID: <20080208191133.GA14485@osc.edu>

robin.humble+stgt at anu.edu.au wrote on Thu, 07 Feb 2008 21:07 -0500:
> I think I'm seeing iSER read corruption problems.
> a) in stock centos5.1 when not using kernel 2.6.22.6 I get read
>    corruption with just a single reader
> b) every kernel/OS/ofed combination that I've tried when there are
>    multiple simultaneous readers
> 
> the multiple reader problem happens whether the data is read from
> multiple luns or clients or... well, just multiple reads to a single
> tgtd doing iSER seems to be enough to cause it.
> 
> I'm hoping these problems are just something that I've broken in my
> setup... previously 2.6.18-52.el5 + centos5 worked (in the single
> reader case) but I can't make it work now.
> 
> is anyone else seeing easy read corruption?
> 
> the easiest way I can reproduce it is:
>  initiator side - write data:
>    lmdd if=internal of=/dev/sdc opat=1 bs=1M count=1000
>  target side - check that the file is ok (it is):
>    lmdd of=internal if=/mnt/ramdisk/file ipat=1 bs=1M count=1000 mismatch=1
>  initiator side - read and check data (is sometimes ok):
>    lmdd of=internal if=/dev/sdc ipat=1 bs=1M count=1000 mismatch=1
>  initiator side - read data with 2 processes at once (always fails):
>    lmdd of=internal if=/dev/sdc ipat=1 bs=1M count=1000 mismatch=1 &
>    lmdd of=internal if=/dev/sdc ipat=1 bs=1M count=1000 mismatch=1 &
> 
> I'm using the kernel git tree of stgt.
> I don't see any problems when using TCP IPoIB.

I've tried this and a few variations but can't find any problems.
That's unfortunate.  To debug it, perhaps you can investigate the
mismatched data that comes back and see if you can discern a
pattern.  Like if it is always at 4k boundaries, or always at 512k
boundaries, that could help us to narrow it down.

You had another corruption issue a long time ago that I thought was
related to the response message getting in front of the RDMA.  But
IB guys insist that this is not possible.  I had a patch that I very
much did not like that delayed the final response message until the
target saw the local completions for its RDMAs.  This never went in.
It is dated 16 oct 2007.  In case your notes or mail archives lead
you to believe this current read corruption is similar.

		-- Pete


From pw at osc.edu  Fri Feb  8 20:24:48 2008
From: pw at osc.edu (Pete Wyckoff)
Date: Fri, 8 Feb 2008 14:24:48 -0500
Subject: [Stgt-devel] [PATCH 1/2] iSER throttling
In-Reply-To: <20080208023619.GA23845@porcupine.cita.utoronto.ca>
References: <20080208023619.GA23845@porcupine.cita.utoronto.ca>
Message-ID: <20080208192448.GB14485@osc.edu>

robin.humble+stgt at anu.edu.au wrote on Thu, 07 Feb 2008 21:36 -0500:
> with a few iSER writers it's easy to run out of RDMA areas in the tgtd
> mempool. currently tgtd gives up in this case, leading to a mess.
> these 2 patches throttle iSER requests so that there are always enough
> RDMA areas left in the mempool left to do i/o.
> 
> it's been tested with 1 to 16 initiators and it seems to work.
> 
> funtionality of the iSER code is unchanged when there's 1 initiator and
> 1 target.
> functionality of the tcp transport code is unchanged, although these
> patches add enough framework that the tcp code could have throttling
> enabled sometime in the future.
> 
> possible extensions to this work are
>  - to tell the user when they are frequently running low on RDMA areas
>    and suggest that they recompile with a higher number
>  - to make the RDMA mempool size a runtime configurable so that it can
>    be increased without a recompile
>  - to add tcp accounting and throttling

Brilliant stuff.  This is definitely a worthwhile improvement.  Some
comments.

> diff -ruN ../tgt/usr/iscsi/iscsi_rdma.c ./usr/iscsi/iscsi_rdma.c
> --- ../tgt/usr/iscsi/iscsi_rdma.c	2008-01-23 12:50:27.000000000 +1100
> +++ ./usr/iscsi/iscsi_rdma.c	2008-01-24 18:22:32.000000000 +1100
> @@ -196,6 +196,9 @@
>  
>  	/* free and allocated mempool entries */
>  	struct list_head mempool_free, mempool_alloc;
> +
> +        /* rdma mempool accounting */
> +        int mempool_used;
>  };

Tomo will yell at you for not running checkpatch.  Those spaces
should be tabs.

> @@ -213,6 +216,7 @@
>  
>  /* all iser connections */
>  static struct list_head iser_conn_list;
> +static int iser_conn_cnt;
>  
>  /* if any task needs an rdma read or write slot to proceed */
>  static int waiting_rdma_slot;
> @@ -555,6 +559,7 @@
>  	dev->mempool_listbuf = listbuf;
>  	INIT_LIST_HEAD(&dev->mempool_free);
>  	INIT_LIST_HEAD(&dev->mempool_alloc);
> +	dev->mempool_used = 0;
>  
>  	for (i = 0; i < mempool_num; i++) {
>  		mp = (void *) listbuf;
> @@ -793,6 +798,7 @@
>  	dprintf("established conn %p\n", ci);
>  	list_del(&ci->iser_conn_list);
>  	list_add(&ci->iser_conn_list, &iser_conn_list);
> +	iser_conn_cnt++;
>  }

I think iser_conn_cnt should be a property on the dev, not global.
Since we allocate mempools per device.

Also might as well fold these two patches into one, since it is hard
to understand the role of iser_conn_cnt without the uses of it in
patch 2.

		-- Pete


From pw at osc.edu  Fri Feb  8 20:49:33 2008
From: pw at osc.edu (Pete Wyckoff)
Date: Fri, 8 Feb 2008 14:49:33 -0500
Subject: [Stgt-devel] [PATCH 2/2] iSER throttling
In-Reply-To: <20080208023851.GA25361@porcupine.cita.utoronto.ca>
References: <20080208023851.GA25361@porcupine.cita.utoronto.ca>
Message-ID: <20080208194933.GC14485@osc.edu>

robin.humble+stgt at anu.edu.au wrote on Thu, 07 Feb 2008 21:38 -0500:
> +static int max_queue_cmds_available(struct iscsi_connection *conn)
> +{
> +	int max_queue_cmd;
> +	int max_safe_cmds;
> +
> +	max_safe_cmds = conn->tp->queue_cmds_available(conn);
> +	if (max_safe_cmds < 0) {
> +		eprintf("iSER max_safe_cmds %d < 0\n", max_safe_cmds );
> +		return 0;
> +	}
> +	max_queue_cmd = min( MAX_QUEUE_CMD, max_safe_cmds );
> +
> +	return max_queue_cmd;
> +}

Can we just get rid of MAX_QUEUE_CMD?  You don't need this min(), I
think.  The max_queue_cmd is a property of the transport now, not
iscsi.

> +/*
> + * we know how many iSER connections we have, and also how many areas are
> + * allocated from our mempool, so we can trivially calculate how many
> + * more cmds we can handle without running out of rdma areas.
> + */
> +static int iscsi_rdma_queue_cmds_available(struct iscsi_connection *conn)
> +{
> +	struct conn_info *ci = RDMA_CONN(conn);
> +	struct iser_device *dev = ci->dev;
> +	int cmds;
> +
> +	cmds = (mempool_num - dev->mempool_used)/iser_conn_cnt;
> +
> +	return cmds;
> +}

The divide here is used to spread the remaining available mempool
items on the device across current connections using that device.
This is why I said that iser_conn_cnt should be on dev->.

This is approximate.  For commands that ship no data, we don't need
a mempool buf.  For bidi commands, we need two.  But I think this
approach definitely meets the most common usage model.

Did you think about just doing static allocation?  Since
dev->mempool_used is fairly volatile, you could just give
mempool_num / iser_conn_cnt to each connection.

Probably should make sure you hand out at least 1 command.
I don't know what the spec says about handing out 0.

And yeah, to your future work, may want to add a comment saying how
we could grow the mempool as more clients connect, since there is no
a priori way to know if tgtd will be used for 1 client or lots.

> +static int iscsi_tcp_queue_cmds_available(struct iscsi_connection *conn) {
> +	return MAX_TCP_QUEUE_CMD;
> +}
> +

Sytle, or lack thereof.

		-- Pete


From robin.humble+stgt at anu.edu.au  Sat Feb  9 17:39:04 2008
From: robin.humble+stgt at anu.edu.au (Robin Humble)
Date: Sat, 9 Feb 2008 11:39:04 -0500
Subject: [Stgt-devel] iSER multiple readers
In-Reply-To: <20080208191133.GA14485@osc.edu>
References: <20080208020722.GA5146@porcupine.cita.utoronto.ca>
	<20080208191133.GA14485@osc.edu>
Message-ID: <20080209163904.GA16930@porcupine.cita.utoronto.ca>

On Fri, Feb 08, 2008 at 02:11:33PM -0500, Pete Wyckoff wrote:
>robin.humble+stgt at anu.edu.au wrote on Thu, 07 Feb 2008 21:07 -0500:
>> I think I'm seeing iSER read corruption problems.
>> a) in stock centos5.1 when not using kernel 2.6.22.6 I get read
>>    corruption with just a single reader
>> b) every kernel/OS/ofed combination that I've tried when there are
>>    multiple simultaneous readers
...
>> the easiest way I can reproduce it is:
>>  initiator side - write data:
>>    lmdd if=internal of=/dev/sdc opat=1 bs=1M count=1000
>>  target side - check that the file is ok (it is):
>>    lmdd of=internal if=/mnt/ramdisk/file ipat=1 bs=1M count=1000 mismatch=1
>>  initiator side - read and check data (is sometimes ok):
>>    lmdd of=internal if=/dev/sdc ipat=1 bs=1M count=1000 mismatch=1
>>  initiator side - read data with 2 processes at once (always fails):
>>    lmdd of=internal if=/dev/sdc ipat=1 bs=1M count=1000 mismatch=1 &
>>    lmdd of=internal if=/dev/sdc ipat=1 bs=1M count=1000 mismatch=1 &
>> 
>> I'm using the kernel git tree of stgt.
>> I don't see any problems when using TCP IPoIB.
>
>I've tried this and a few variations but can't find any problems.
>That's unfortunate.  To debug it, perhaps you can investigate the
>mismatched data that comes back and see if you can discern a
>pattern.  Like if it is always at 4k boundaries, or always at 512k
>boundaries, that could help us to narrow it down.

a few of these
  lmdd of=internal if=/dev/sdc bs=1M count=7000 ipat=1 mismatch=1
gives:
 off=116000000 want=6f80000 got=6fa1000
 off=518000000 want=1eec0000 got=1eee1000
 off=12000000 want=c40000 got=c5d000
 off=627000000 want=256e0000 got=256ee000
 off=344000000 want=148b6000 got=148c0000
 off=163000000 want=9c40000 got=9c5b000
 off=11000000 want=b40000 got=b47000
 off=514000000 want=1eb20000 got=1eb21000
 off=28000000 want=1b80000 got=1b93000
 off=78000000 want=4b3d000 got=4b41000
 off=70000000 want=4360000 got=4381000
 off=0 want=e0000 got=fb000
 off=20000000 want=13e0000 got=13fa000
so always on MB boundaries?

a few tests show that it's pretty hard to get mismatches with ~ bs=384
and below.

with bs=512
  lmdd of=internal if=/dev/sdc bs=512 count=7000000 ipat=1 mismatch=1
I get
 off=1010024448 want=3c33c000 got=3c350000
 off=1693302784 want=64edc000 got=64eea000
 off=45203456 want=2b1c000 got=2b27000
 off=289783808 want=1145c000 got=11460000
 off=507494400 want=1e3fc000 got=1e40f000
 off=282181632 want=10d1c000 got=10d30000
 off=334217216 want=13ebc000 got=13ebe000

>You had another corruption issue a long time ago that I thought was
>related to the response message getting in front of the RDMA.  But
>IB guys insist that this is not possible.  I had a patch that I very
>much did not like that delayed the final response message until the
>target saw the local completions for its RDMAs.  This never went in.
>It is dated 16 oct 2007.  In case your notes or mail archives lead
>you to believe this current read corruption is similar.

as always, thanks for looking into this so quickly!

so with ye olde
  [PATCH 20/20] iser wait for rdma completion
applied, now single and multiple readers with stock centos5.1 kernels
and userland work ok. odd.

is there any way to check more definitively whether the ordering is
getting messed up with my hardware/OS/OFED combo? perhaps some sort of
a micro-verbs/rdma benchmark that would convice the IB guys one way or
the other?

I've attached an updated version of the patch that applies to the
current tree.

cheers,
robin
-------------- next part --------------
--- tgt/usr/iscsi/iscsi_rdma.c	2008-01-23 12:50:27.000000000 +1100
+++ tgt+iserCompletePatch/usr/iscsi/iscsi_rdma.c	2008-02-10 02:17:06.000000000 +1100
@@ -94,6 +94,7 @@
 	struct ibv_send_wr wr;
 	struct list_head list;
 	struct iscsi_task *task;  /* to get iser_task for remote stag and va */
+	int final_rdma;
 };
 
 /*
@@ -938,6 +939,14 @@
 
 		iscsi_rdma_event_modify(conn, EPOLLIN | EPOLLOUT);
 		list_add(&rdmal->list, &ci->rdmal);
+
+		/* now let it transmit the final response, as we know
+		 * the RDMAs have completed */
+		if (rdmal->final_rdma) {
+			struct iscsi_task *task = rdmal->task;
+			list_add_tail(&task->c_list, &task->conn->tx_clist);
+		}
+
 		if (waiting_rdma_slot) {
 			waiting_rdma_slot = 0;
 			num_tx_ready = 1;
@@ -1408,7 +1417,8 @@
  */
 static int iser_post_rdma_wr(struct conn_info *ci, struct iscsi_task *task,
 			     void *buf, ssize_t size, int op,
-			     uint64_t remote_va, uint32_t remote_rkey)
+			     uint64_t remote_va, uint32_t remote_rkey,
+			     int final_rdma)
 {
 	int ret;
 	struct rdmalist *rdmal;
@@ -1429,6 +1439,8 @@
 	rdmal->wr.wr.rdma.remote_addr = remote_va;
 	rdmal->wr.wr.rdma.rkey = remote_rkey;
 
+	rdmal->final_rdma = final_rdma;
+
 	ret = ibv_post_send(ci->qp_hndl, &rdmal->wr, &bad_wr);
 	if (ret)
 		eprintf("ibv_post_send ret %d\n", ret);
@@ -1457,7 +1469,7 @@
 		(unsigned long long) itask->rem_write_va);
 
 	ret = iser_post_rdma_wr(ci, task, buf, len, IBV_WR_RDMA_READ,
-				itask->rem_write_va, itask->rem_write_stag);
+				itask->rem_write_va, itask->rem_write_stag, 0);
 	if (ret < 0)
 		return ret;
 
@@ -1482,6 +1494,7 @@
 	struct iser_task *itask = ISER_TASK(task);
 	struct iscsi_pdu *rsp = &conn->rsp;
 	struct iscsi_data_rsp *datain = (struct iscsi_data_rsp *) &rsp->bhs;
+	int final_rdma = (task->offset == task->len);
 	uint32_t offset;
 	int ret;
 
@@ -1492,7 +1505,7 @@
 
 	ret = iser_post_rdma_wr(ci, task, rsp->data, rsp->datasize,
 				IBV_WR_RDMA_WRITE, itask->rem_read_va + offset,
-				itask->rem_read_stag);
+				itask->rem_read_stag, final_rdma);
 	if (ret < 0)
 		return ret;
 
@@ -1501,7 +1514,7 @@
 	 * rdma to finish before sending the completion.  Then we'll stick
 	 * ourselves back on the list.
 	 */
-	if (task->offset == task->len) {
+	if (final_rdma) {
 		iscsi_rdma_event_modify(conn, EPOLLIN);
 	} else {
 		/* poke ourselves to do the next rdma */
--- tgt/usr/iscsi/iscsid.c	2008-01-23 12:50:27.000000000 +1100
+++ tgt+iserCompletePatch/usr/iscsi/iscsid.c	2008-02-10 02:47:18.000000000 +1100
@@ -1700,14 +1700,20 @@
 	case ISCSI_OP_R2T:
 		break;
 	case ISCSI_OP_SCSI_DATA_IN:
-		if (task->offset < task->len ||
-		    scsi_get_result(&task->scmd) != SAM_STAT_GOOD ||
-		    scsi_get_data_dir(&task->scmd) == DATA_BIDIRECTIONAL ||
-		    conn->tp->rdma) {
-			dprintf("more data or sense or bidir %x\n", hdr->itt);
-			list_add_tail(&task->c_list, &task->conn->tx_clist);
-			return 0;
-		}
+ 		if (conn->tp->rdma) {
+ 			/* keep sending RDMA writes, but wait until they
+ 			 * are done before sending final response */
+ 			if (task->offset < task->len)
+ 			    list_add_tail(&task->c_list, &task->conn->tx_clist);
+ 		} else {
+			if (task->offset < task->len ||
+			    scsi_get_result(&task->scmd) != SAM_STAT_GOOD ||
+			    scsi_get_data_dir(&task->scmd) == DATA_BIDIRECTIONAL ) {
+				dprintf("more data or sense or bidir %x\n", hdr->itt);
+				list_add_tail(&task->c_list, &task->conn->tx_clist);
+			}
+  		}
+ 		break;
 	case ISCSI_OP_SCSI_CMD_RSP:
 		iscsi_free_cmd_task(task);
 		break;

From tomof at acm.org  Sat Feb  9 17:41:36 2008
From: tomof at acm.org (FUJITA Tomonori)
Date: Sun, 10 Feb 2008 01:41:36 +0900
Subject: [Stgt-devel] Update (Re: open iSCSI over iSER target RPM ...)
In-Reply-To: <47AB2C2F.2090707@scalableinformatics.com>
References: <47A87586.6010904@Voltaire.COM>
	<47AA28C3.7090003@scalableinformatics.com>
	<47AB2C2F.2090707@scalableinformatics.com>
Message-ID: <200802091641.m19GffI5008280@mbox.iij4u.or.jp>

From: Joe Landman <landman at scalableinformatics.com>
Subject: [Stgt-devel] Update (Re: open iSCSI over iSER target RPM ...)
Date: Thu, 07 Feb 2008 11:05:03 -0500

> Update:
> 
> [root at woody etc]# dd if=/dev/zero of=/big/local.file bs=256k count=100000
> 100000+0 records in
> 100000+0 records out
> 26214400000 bytes (26 GB) copied, 58.7484 seconds, 446 MB/s
> 
> Better. I rebuilt OFED 1.2.5.5.  Are there specific recommended tuning 
> guides for iSER?  Backing store in this case are real disks, and we can 
> sink/source >750 MB/s on them, so I am not worried about disk IO 
> bottlenecks, more worried about bad config of iSCSI/iSER.
> 
> BTW:  the 2TB LUN limit I asked about is still here in this code.  Same 
> machines (initiator and target) used for SRP reported correct LUN sizes. 
>   Here we are using the -868 open-iscsi initiator, and the tgt RPM 
> announced.  I would like to dig into this.
> 
> This is what I am getting in dmesg for this iSER target:
> 
> iscsi: registered transport (tcp)
> iscsi: registered transport (iser)
> iser: iser_connect:connecting to: 10.2.1.2, port 0xbc0c
> iser: iser_cma_handler:event 0 conn ffff81024b9f69c0 id ffff810209748c00
> iser: iser_cma_handler:event 2 conn ffff81024b9f69c0 id ffff810209748c00
> iser: iser_create_ib_conn_res:setting conn ffff81024b9f69c0 cma_id 
> ffff810209748c00: fmr_pool ffff81024bfb32c0 qp ffff8101cb16d600
> iser: iser_cma_handler:event 9 conn ffff81024b9f69c0 id ffff810209748c00
> iser: iscsi_iser_ep_poll:ib conn ffff81024b9f69c0 rc = 1
> scsi13 : iSCSI Initiator over iSER, v.0.1
> iser: iscsi_iser_conn_bind:binding iscsi conn ffff81021b65fa90 to 
> iser_conn ffff81024b9f69c0
>    Vendor: IET       Model: Controller        Rev: 0001
>    Type:   RAID                               ANSI SCSI revision: 05
> scsi 13:0:0:0: Attached scsi generic sg2 type 12
>    Vendor: IET       Model: VIRTUAL-DISK      Rev: 0001
>    Type:   Direct-Access                      ANSI SCSI revision: 05
> sdc : very big device. try to use READ CAPACITY(16).
> sdc : READ CAPACITY(16) failed.
> sdc : status=1, message=00, host=0, driver=08
> sdc : use 0xffffffff as device size
> SCSI device sdc: 4294967296 512-byte hdwr sectors (2199023 MB)
> sdc: Write Protect is off
> sdc: Mode Sense: 79 00 00 08
> SCSI device sdc: drive cache: write back
> sdc : very big device. try to use READ CAPACITY(16).
> sdc : READ CAPACITY(16) failed.
> sdc : status=1, message=00, host=0, driver=08
> sdc : use 0xffffffff as device size
> SCSI device sdc: 4294967296 512-byte hdwr sectors (2199023 MB)
> sdc: Write Protect is off
> sdc: Mode Sense: 79 00 00 08
> SCSI device sdc: drive cache: write back
>   sdc: unknown partition table
> sd 13:0:0:1: Attached scsi disk sdc
> sd 13:0:0:1: Attached scsi generic sg3 type 0
> 
> 
> and this is what we get in SRP
> 
> scsi6 : SRP.T10:0008F104039862A4
>    Vendor: SCST_BIO  Model: vdisk0            Rev:  096
>    Type:   Direct-Access                      ANSI SCSI revision: 04
> sdc : very big device. try to use READ CAPACITY(16).
> SCSI device sdc: 12693355130 512-byte hdwr sectors (6498998 MB)
> sdc: Write Protect is off
> sdc: Mode Sense: 6b 00 10 08
> SCSI device sdc: drive cache: write back w/ FUA
> 
> 
> This looks suspiciously like a 2^32 limit somewhere.

Can you try the latest git tree
(65a3f8b0c14305aaee5bcaade569b40882e8dd88)? It works for me:

scsi3 : iSCSI Initiator over TCP/IP
scsi 3:0:0:0: RAID              IET      Controller       0001 PQ: 0 ANSI: 5
scsi 3:0:0:1: Direct-Access     IET      VIRTUAL-DISK     0001 PQ: 0 ANSI: 5
sd 3:0:0:1: [sdb] Very big device. Trying to use READ CAPACITY(16).
sd 3:0:0:1: [sdb] 12884901888 512-byte hardware sectors (6597070 MB)
sd 3:0:0:1: [sdb] Write Protect is off
sd 3:0:0:1: [sdb] Mode Sense: 79 00 00 08
sd 3:0:0:1: [sdb] Write cache: enabled, read cache: enabled, doesn't support DPO or FUA


Somehow I forgot to add READ_CAPACITY_16 support. I would appreciate
it if you could read and write on over 2TB position properly.


> Our exported device is
> 
> [root at jr1 ~]# parted /dev/sdb print
> 
> Model: Areca jrvs1 (scsi)
> Disk /dev/sdb: 6500GB
> Sector size (logical/physical): 512B/512B
> Partition Table: loop
> 
> Number  Start   End     Size    File system  Flags
>   1      0.00kB  6500GB  6500GB  xfs
> 
> 
> and this is what tgtadm reports
> 
> [root at jr1 ~]# tgtadm --lld iscsi --op show --mode target
> Target 1: iqn.2001-04.com.jr1-jackrabbit.small
>      System information:
>          Driver: iscsi
>          Status: running
>      I_T nexus information:
>          I_T nexus: 4
>              Initiator: iqn.1996-04.voltaire.com:01:dfa8888a3fd
>              Connection: 0
>                  RDMA IP Address: 10.2.1.1
>      LUN information:
>          LUN: 0
>              Type: controller
>              SCSI ID: deadbeaf1:0
>              SCSI SN: beaf10
>              Size: 0
>              Online: No
>              Poweron/Reset: Yes
>              Removable media: No
>              Backing store: No backing store
>          LUN: 1
>              Type: disk
>              SCSI ID: deadbeaf1:1
>              SCSI SN: beaf11
>              Size: 5T
>              Online: Yes
>              Poweron/Reset: No
>              Removable media: No
>              Backing store: /dev/sdb
>      Account information:
>      ACL information:
>          10.2.1.1
> 
> So it looks like the LUN 1 is approximately correct (5T ???) on the 
> target, and incorrect when the initiator asks for it.

I changed tgt to show the capacity like Linux does:


Target 1: iqn.2007-03:marks-vtl-tgt:tulip
    System information:
        Driver: iscsi
        Status: running
    I_T nexus information:
        I_T nexus: 1
            Initiator: iqn.2005-03.org.open-iscsi:d38a581f3318
            Connection: 0
                IP Address: 192.168.11.15
    LUN information:
        LUN: 0
            Type: controller
            SCSI ID: deadbeaf1:0
            SCSI SN: beaf10
            Size: 0 MB
            Online: Yes
            Poweron/Reset: Yes
            Removable media: No
            Backing store: No backing store
        LUN: 1
            Type: disk
            SCSI ID: deadbeaf1:1
            SCSI SN: beaf11
            Size: 6597070 MB
            Online: Yes
            Poweron/Reset: No
            Removable media: No
            Backing store: /dev/sde
    Account information:
    ACL information:
        ALL


> Please note that I have successfully used the full 6+TB as an iSCSI 
> target using the SCST-iscsi code, so I do know that the initiator works 
> correctly.
> 
> Is there a source RPM/tree for this target?

I guess that RedHat, SUSE, and OFED have tgt RPMs now so I think that
you can find something.


From tomof at acm.org  Sat Feb  9 18:01:48 2008
From: tomof at acm.org (FUJITA Tomonori)
Date: Sun, 10 Feb 2008 02:01:48 +0900
Subject: [Stgt-devel] [PATCH 1/1] iscsi tcp nodelay
In-Reply-To: <e2e108260802080552q7868ae72of00e3d7822e6667b@mail.gmail.com>
References: <20080207181951.0573F8B7AE@titan.sf.osc.edu>
	<20080208110506Y.fujita.tomonori@lab.ntt.co.jp>
	<e2e108260802080552q7868ae72of00e3d7822e6667b@mail.gmail.com>
Message-ID: <20080210020243J.tomof@acm.org>

On Fri, 8 Feb 2008 14:52:12 +0100
"Bart Van Assche" <bart.vanassche at gmail.com> wrote:

> On Feb 8, 2008 3:05 AM, FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp> wrote:
> > Yeah, this is a must-have trick for low latency. IET has the same
> > trick but somehow I forgot to add this to tgt.
> 
> I have retested tgt-20071227 with the TCP_NODELAY patch on an 1GB/s IB
> network with a RAM disk target. For realistic block transfer sizes (<=
> 64 KB) latency is unchanged and throughput improved slightly (5% for
> reads and 9% for writes).

Sounds nice improvement.

Thanks for testing,




From landman at scalableinformatics.com  Sat Feb  9 17:43:41 2008
From: landman at scalableinformatics.com (Joe Landman)
Date: Sat, 09 Feb 2008 11:43:41 -0500
Subject: [Stgt-devel] Update (Re: open iSCSI over iSER target RPM ...)
In-Reply-To: <200802091641.m19GffI5008280@mbox.iij4u.or.jp>
References: <47A87586.6010904@Voltaire.COM>	<47AA28C3.7090003@scalableinformatics.com>	<47AB2C2F.2090707@scalableinformatics.com>
	<200802091641.m19GffI5008280@mbox.iij4u.or.jp>
Message-ID: <47ADD83D.9080109@scalableinformatics.com>

FUJITA Tomonori wrote:

> Can you try the latest git tree
> (65a3f8b0c14305aaee5bcaade569b40882e8dd88)? It works for me:
> 
> scsi3 : iSCSI Initiator over TCP/IP
> scsi 3:0:0:0: RAID              IET      Controller       0001 PQ: 0 ANSI: 5
> scsi 3:0:0:1: Direct-Access     IET      VIRTUAL-DISK     0001 PQ: 0 ANSI: 5
> sd 3:0:0:1: [sdb] Very big device. Trying to use READ CAPACITY(16).
> sd 3:0:0:1: [sdb] 12884901888 512-byte hardware sectors (6597070 MB)
> sd 3:0:0:1: [sdb] Write Protect is off
> sd 3:0:0:1: [sdb] Mode Sense: 79 00 00 08
> sd 3:0:0:1: [sdb] Write cache: enabled, read cache: enabled, doesn't support DPO or FUA
> 
> 
> Somehow I forgot to add READ_CAPACITY_16 support. I would appreciate
> it if you could read and write on over 2TB position properly.

Ok, I will pull it a little later today, build and let you know.


-- 
Joseph Landman, Ph.D
Founder and CEO
Scalable Informatics LLC,
email: landman at scalableinformatics.com
web  : http://www.scalableinformatics.com
        http://jackrabbit.scalableinformatics.com
phone: +1 734 786 8423
fax  : +1 866 888 3112
cell : +1 734 612 4615


From pw at osc.edu  Sat Feb  9 19:18:58 2008
From: pw at osc.edu (Pete Wyckoff)
Date: Sat, 9 Feb 2008 13:18:58 -0500
Subject: [Stgt-devel] iSER multiple readers
In-Reply-To: <20080209163904.GA16930@porcupine.cita.utoronto.ca>
References: <20080208020722.GA5146@porcupine.cita.utoronto.ca>
	<20080208191133.GA14485@osc.edu>
	<20080209163904.GA16930@porcupine.cita.utoronto.ca>
Message-ID: <20080209181858.GA8702@osc.edu>

robin.humble+stgt at anu.edu.au wrote on Sat, 09 Feb 2008 11:39 -0500:
> a few of these
>   lmdd of=internal if=/dev/sdc bs=1M count=7000 ipat=1 mismatch=1
> gives:
>  off=116000000 want=6f80000 got=6fa1000
>  off=518000000 want=1eec0000 got=1eee1000
>  off=12000000 want=c40000 got=c5d000
>  off=627000000 want=256e0000 got=256ee000
>  off=344000000 want=148b6000 got=148c0000
>  off=163000000 want=9c40000 got=9c5b000
>  off=11000000 want=b40000 got=b47000
>  off=514000000 want=1eb20000 got=1eb21000
>  off=28000000 want=1b80000 got=1b93000
>  off=78000000 want=4b3d000 got=4b41000
>  off=70000000 want=4360000 got=4381000
>  off=0 want=e0000 got=fb000
>  off=20000000 want=13e0000 got=13fa000
> so always on MB boundaries?

Note that 1M means 1.0e6 here.  Not on MB boundaries.

We know lmdd produces the pattern in ints:  0,4,8,...
It reports the offset of the beginning of the block, with len 1M in
this case.  So the first complaint says the word at byte offset 0x6f80000
in the stream, read as part of the block 0x6ea0500 to 0x6f94740,
actually contained the data at 0x6fa1000, a spot 132 kB further up
in the data file (or 33 pages).

I was going to complain about the non-power-of-2 reads, but in this
case, I think it confirms what we suspected, that the problem is in
page mapping somewhere, either initiator or target, and not in say
bs_rdwr.  That code just does pread, which is pretty unlikely to be
broken, and it does it to non-page boundaries in the mempool buffer
provided by iser.

Here's the list of (decimal) page offsets for the above:

    33 33 29 14 10 27 7 1 19 4 33 27 26

Doesn't tell me much.

Did you modify your lmdd only to show the first error on a transfer?
The code here looks like it would print a want/got line for each
word that differed.  I would be surprised if only the first word of
the page was wrong.

> a few tests show that it's pretty hard to get mismatches with ~ bs=384
> and below.
> 
> with bs=512
>   lmdd of=internal if=/dev/sdc bs=512 count=7000000 ipat=1 mismatch=1
> I get
>  off=1010024448 want=3c33c000 got=3c350000
>  off=1693302784 want=64edc000 got=64eea000
>  off=45203456 want=2b1c000 got=2b27000
>  off=289783808 want=1145c000 got=11460000
>  off=507494400 want=1e3fc000 got=1e40f000
>  off=282181632 want=10d1c000 got=10d30000
>  off=334217216 want=13ebc000 got=13ebe000

Again, page offsets:  20 14 11 4 19 20 2

The offsets are always positive, which fits in with the theory that
future RDMAs are overwriting earlier ones.  This goes against the
theory in your (my) patch, which guesses that the SCSI response
message is sneaking ahead of RDMA operations.

lmdd is just doing reads of 1.0e6 byte size, into a valloc-ed (so
page aligned) buffer.  It just memcpys from the page cache into this
buf.  We don't see non-4k-aligned errors there, so the problem has
to be in the page cache or below.  Just like it can't be in the
mempool handling, or we'd see non-4k-aligned issues.

> so with ye olde
>   [PATCH 20/20] iser wait for rdma completion
> applied, now single and multiple readers with stock centos5.1 kernels
> and userland work ok. odd.

Ugh.  I hate that patch.  All it does is to slow things down,
effectively.

> is there any way to check more definitively whether the ordering is
> getting messed up with my hardware/OS/OFED combo? perhaps some sort of
> a micro-verbs/rdma benchmark that would convice the IB guys one way or
> the other?

I'm pretty sold on the idea that ye olde 20/20 is not the problem.
I'm leaning towards something with FMR in the iser initiator.  It's
the only place we get page size operations.  The target-side mapping
is one contiguous 192 * 512 kB chunk with a single MR.

We could write a verbs benchmark that just sends data, but I fear
the interaction is with memory registration handling either on the
initiator or the target, so we may miss the problem.

You're using oldish 2.6.18 and 2.6.22, both of which now show this
issue.  I don't suppose you'd be willing to test a more recent
kernel initiatior?  In the mean time, I'll go take a look at the
iser fmr code, comparing it to srp's fmr code.

Another possibility.  Change /sys/block/.../max_sectors_kb to 8 or
less so that each initiator request will fit in a page, disabling
FMR.  Not sure exactly how this works.  May need some debugging to
verify.  Could be too slow to provoke the problem.

		-- Pete


From tomof at acm.org  Sun Feb 10 05:37:47 2008
From: tomof at acm.org (FUJITA Tomonori)
Date: Sun, 10 Feb 2008 13:37:47 +0900
Subject: [Stgt-devel] [Scst-devel] Integration of SCST in the
 mainstream	Linux kernel
In-Reply-To: <20080206091247E.fujita.tomonori@lab.ntt.co.jp>
References: <20080206014340X.tomof@acm.org> <47A89734.7000009@wpkg.org>
	<20080206091247E.fujita.tomonori@lab.ntt.co.jp>
Message-ID: <200802100437.m1A4blER029141@mbox.iij4u.or.jp>

From: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
Subject: Re: [Stgt-devel] [Scst-devel] Integration of SCST in the mainstream	Linux kernel
Date: Wed, 06 Feb 2008 09:12:47 +0900

> On Tue, 05 Feb 2008 18:04:52 +0100
> Tomasz Chmielewski <mangoo at wpkg.org> wrote:
> 
> > FUJITA Tomonori schrieb:
> > 
> > (...)
> > 
> > >> The problem with tgtd is that you can't start it (configured) in an
> > >> "atomic" way.
> > >> Usually, one will start tgtd and it's configuration in a script (I 
> > >> replaced some parameters with "..." to make it shorter and more readable):
> > > 
> > > Thanks for the details. So the way to stop the daemon is not related
> > > with your problem.
> > > 
> > > It's easily fixable. Can you start a new thread about this on
> > > stgt-devel mailing list? When we agree on the interface to start the
> > > daemon, I'll implement it.
> > 
> > Sure.
> > 
> > 1. tgtd should not immediately background, but only when it's fully started?
> > 
> > 2. tgtd should only start to listen if told so? tgtdadm --listen/--nolisten?
> 
> I was thinking about something like:
> 
> tgtadm --op update --mode sys --name state -v running

I've just realized that tgt already has something like that, which
might work for you.

tgt has the state of a target device. See 'Status: offline':

root at iris:~/git# ./tgt/usr/tgtadm --op show --mode target
Target 1: iqn.2001-04.com.example:storage.disk2.iris.sys1.xyz
    System information:
        Driver: iscsi
        Status: offline
    I_T nexus information:
    LUN information:
        LUN: 0
            Type: controller
            SCSI ID: deadbeaf1:0
            SCSI SN: beaf10
            Size: 0 MB
            Online: Yes
            Poweron/Reset: Yes
            Removable media: No
            Backing store: No backing store
        LUN: 1
            Type: disk
            SCSI ID: deadbeaf1:1
            SCSI SN: beaf11
            Size: 2147 MB
            Online: Yes
            Poweron/Reset: Yes
            Removable media: No
            Backing store: /var/tmp/image0
    Account information:
    ACL information:
        ALL


If the state is 'offline', the daemon tells the initiator that there
is an error on the target side. Then open-iscsi tries to reconnect to
the target, I think.

By default, the sate of a target device 'running'. So there is a race
between the first and second operations (that is, you need to peform
the second right after the first, before the initiator tries to
connect). I'm fine with changing the default state to 'offline'.

tgtadm --op new --mode target --tid 1 -T iqn.2001-04.com.example:storage.disk2.iris.sys1.xyz
tgtadm --op update --mode target --tid 1 -n state -v offline
tgtadm --op new --mode logicalunit --tid 1 --lun 1 -b /var/tmp/image0
tgtadm --op bind --mode target --tid 1 -I ALL
tgtadm --op update --mode target --tid 1 -n state -v running


From robin.humble+stgt at anu.edu.au  Sun Feb 10 13:53:35 2008
From: robin.humble+stgt at anu.edu.au (Robin Humble)
Date: Sun, 10 Feb 2008 07:53:35 -0500
Subject: [Stgt-devel] iSER multiple readers
In-Reply-To: <20080209181858.GA8702@osc.edu>
References: <20080208020722.GA5146@porcupine.cita.utoronto.ca>
	<20080208191133.GA14485@osc.edu>
	<20080209163904.GA16930@porcupine.cita.utoronto.ca>
	<20080209181858.GA8702@osc.edu>
Message-ID: <20080210125335.GA6966@porcupine.cita.utoronto.ca>

On Sat, Feb 09, 2008 at 01:18:58PM -0500, Pete Wyckoff wrote:
>robin.humble+stgt at anu.edu.au wrote on Sat, 09 Feb 2008 11:39 -0500:
>> a few of these
>>   lmdd of=internal if=/dev/sdc bs=1M count=7000 ipat=1 mismatch=1
>> gives:
>>  off=116000000 want=6f80000 got=6fa1000
>>  off=518000000 want=1eec0000 got=1eee1000
>>  off=12000000 want=c40000 got=c5d000
>>  off=627000000 want=256e0000 got=256ee000
>>  off=344000000 want=148b6000 got=148c0000
>>  off=163000000 want=9c40000 got=9c5b000
>>  off=11000000 want=b40000 got=b47000
>>  off=514000000 want=1eb20000 got=1eb21000
>>  off=28000000 want=1b80000 got=1b93000
>>  off=78000000 want=4b3d000 got=4b41000
>>  off=70000000 want=4360000 got=4381000
>>  off=0 want=e0000 got=fb000
>>  off=20000000 want=13e0000 got=13fa000
>> so always on MB boundaries?
>....
>
>I was going to complain about the non-power-of-2 reads, but in this
>case, I think it confirms what we suspected, that the problem is in
>page mapping somewhere, either initiator or target, and not in say
>bs_rdwr.  That code just does pread, which is pretty unlikely to be
>broken, and it does it to non-page boundaries in the mempool buffer
>provided by iser.
>
>Here's the list of (decimal) page offsets for the above:
>
>    33 33 29 14 10 27 7 1 19 4 33 27 26
>
>Doesn't tell me much.
>
>Did you modify your lmdd only to show the first error on a transfer?

'mismatch=1' tells lmdd to just print the first error.

>> a few tests show that it's pretty hard to get mismatches with ~ bs=384
>> and below.
>> 
>> with bs=512
>>   lmdd of=internal if=/dev/sdc bs=512 count=7000000 ipat=1 mismatch=1
>> I get
>>  off=1010024448 want=3c33c000 got=3c350000
>>  off=1693302784 want=64edc000 got=64eea000
>>  off=45203456 want=2b1c000 got=2b27000
>>  off=289783808 want=1145c000 got=11460000
>>  off=507494400 want=1e3fc000 got=1e40f000
>>  off=282181632 want=10d1c000 got=10d30000
>>  off=334217216 want=13ebc000 got=13ebe000
>
>Again, page offsets:  20 14 11 4 19 20 2
>
>The offsets are always positive, which fits in with the theory that
>future RDMAs are overwriting earlier ones.  This goes against the
>theory in your (my) patch, which guesses that the SCSI response
>message is sneaking ahead of RDMA operations.

ok.

>lmdd is just doing reads of 1.0e6 byte size, into a valloc-ed (so
>page aligned) buffer.  It just memcpys from the page cache into this
>buf.  We don't see non-4k-aligned errors there, so the problem has
>to be in the page cache or below.  Just like it can't be in the
>mempool handling, or we'd see non-4k-aligned issues.

ok.

>> so with ye olde
>>   [PATCH 20/20] iser wait for rdma completion
>> applied, now single and multiple readers with stock centos5.1 kernels
>> and userland work ok. odd.
>Ugh.  I hate that patch.  All it does is to slow things down,
>effectively.

:-/

>> is there any way to check more definitively whether the ordering is
>> getting messed up with my hardware/OS/OFED combo? perhaps some sort of
>> a micro-verbs/rdma benchmark that would convice the IB guys one way or
>> the other?
>I'm pretty sold on the idea that ye olde 20/20 is not the problem.
>I'm leaning towards something with FMR in the iser initiator.  It's
>the only place we get page size operations.  The target-side mapping
>is one contiguous 192 * 512 kB chunk with a single MR.
>
>We could write a verbs benchmark that just sends data, but I fear
>the interaction is with memory registration handling either on the
>initiator or the target, so we may miss the problem.
>
>You're using oldish 2.6.18 and 2.6.22, both of which now show this
>issue.  I don't suppose you'd be willing to test a more recent
>kernel initiatior?  In the mean time, I'll go take a look at the
>iser fmr code, comparing it to srp's fmr code.

how about 2.6.24 at both ends? below are several runs of:
  lmdd of=internal if=/dev/sdc bs=1M count=7000 ipat=1 mismatch=10

off=608000000 want=2445ca00 got=2447ca00
off=608000000 want=2445ca04 got=2447ca04
off=608000000 want=2445ca08 got=2447ca08
off=608000000 want=2445ca0c got=2447ca0c
off=608000000 want=2445ca10 got=2447ca10
off=608000000 want=2445ca14 got=2447ca14
off=608000000 want=2445ca18 got=2447ca18
off=608000000 want=2445ca1c got=2447ca1c
off=608000000 want=2445ca20 got=2447ca20
off=608000000 want=2445ca24 got=2447ca24
608.0000 MB in 1.5089 secs, 402.9511 MB/sec

off=9000000 want=89d000 got=8a1000
off=9000000 want=89d004 got=8a1004
off=9000000 want=89d008 got=8a1008
off=9000000 want=89d00c got=8a100c
off=9000000 want=89d010 got=8a1010
off=9000000 want=89d014 got=8a1014
off=9000000 want=89d018 got=8a1018
off=9000000 want=89d01c got=8a101c
off=9000000 want=89d020 got=8a1020
off=9000000 want=89d024 got=8a1024
9.0000 MB in 0.0272 secs, 331.2477 MB/sec

off=355000000 want=15296200 got=152b6200
off=355000000 want=15296204 got=152b6204
off=355000000 want=15296208 got=152b6208
off=355000000 want=1529620c got=152b620c
off=355000000 want=15296210 got=152b6210
off=355000000 want=15296214 got=152b6214
off=355000000 want=15296218 got=152b6218
off=355000000 want=1529621c got=152b621c
off=355000000 want=15296220 got=152b6220
off=355000000 want=15296224 got=152b6224
355.0000 MB in 0.8903 secs, 398.7272 MB/sec

>Another possibility.  Change /sys/block/.../max_sectors_kb to 8 or
>less so that each initiator request will fit in a page, disabling
>FMR.  Not sure exactly how this works.  May need some debugging to
>verify.  Could be too slow to provoke the problem.

ok - I changed max_sectors_kb to 8 on the initiator side (was 512) and
it seemed to work slightly better, but repeated runs still fail eg.

off=264032704 want=fbe0000 got=fbe8000
off=264032704 want=fbe0004 got=fbe8004
off=264032704 want=fbe0008 got=fbe8008
off=264032704 want=fbe000c got=fbe800c
off=264032704 want=fbe0010 got=fbe8010
off=264032704 want=fbe0014 got=fbe8014
off=264032704 want=fbe0018 got=fbe8018
off=264032704 want=fbe001c got=fbe801c
off=264032704 want=fbe0020 got=fbe8020
off=264032704 want=fbe0024 got=fbe8024
4559.0000 MB in 16.8547 secs, 270.4877 MB/sec

changing max_sectors_kb to 4:

off=4113000000 want=f5284c00 got=f5288c00
off=4113000000 want=f5284c04 got=f5288c04
off=4113000000 want=f5284c08 got=f5288c08
off=4113000000 want=f5284c0c got=f5288c0c
off=4113000000 want=f5284c10 got=f5288c10
off=4113000000 want=f5284c14 got=f5288c14
off=4113000000 want=f5284c18 got=f5288c18
off=4113000000 want=f5284c1c got=f5288c1c
off=4113000000 want=f5284c20 got=f5288c20
off=4113000000 want=f5284c24 got=f5288c24
4113.0000 MB in 27.6913 secs, 148.5305 MB/sec

I'll be travelling the next few days so will be in contact only
intermittently, so apologies in advance for any slow replies.
an account for you on the cluster would be possible if that would
help.

cheers,
robin


From erezz at Voltaire.COM  Sun Feb 10 15:06:31 2008
From: erezz at Voltaire.COM (Erez Zilber)
Date: Sun, 10 Feb 2008 16:06:31 +0200
Subject: [Stgt-devel] [ewg] Re: [ofa-general] [ANNOUNCE] open iSCSI over
 iSER target RPMis	available
In-Reply-To: <47AB0CA9.4020904@scalableinformatics.com>
References: <47A87586.6010904@Voltaire.COM><47AA28C3.7090003@scalableinformatics.com><47AAC047.4000306@Voltaire.COM>
	<47AB0CA9.4020904@scalableinformatics.com>
Message-ID: <47AF04E7.6060808@Voltaire.COM>

Joe Landman wrote:
>
> Erez Zilber wrote:
> >>>     * READ: 920 MB/sec
> >>>     * WRITE: 850 MB/sec
> >> Not getting anything even remotely close to this.  Are there more
> >> details on configuration somewhere?  I followed the web page as
> indicated.
> >>
> >
> > Are you running iSCSI over TCP or iSCSI over iSER (over InfiniBand)? Our
> > results are with iSER.
>
> I followed the instructions on the web pages that were pointed to for
> iSER.  Are there updated pages?
>

For the initiator side, you can see the documentation that comes with
OFED. For the target side, use the wiki page (updated it only last week):

https://wiki.openfabrics.org/tiki-index.php?page=ISER-target

I saw that you were asking about a RPM. There are RPMs for SuSE & RedHat
on the wiki page. These RPMs will be included in OFED 1.4.

Erez

>   Is there a way to tell whether or not
> the RDMA path is being used?
>

Yes - on the initiator side, do the following:

seed1:~ # iscsiadm -m session
iser: [1] 192.168.10.63:3260,1 iqn.2001-04.com.noni-seed1

You can see that iSER is used.

On the target side, do the following:

noni:~ # tgtadm --lld iscsi --op show --mode target
Target 1: iqn.2001-04.com.noni-seed1
    System information:
        Driver: iscsi
        Status: running
    I_T nexus information:
        I_T nexus: 1
            Initiator: iqn.seed1
            Connection: 0
                RDMA IP Address: 192.168.10.81 <-- "RDMA IP Address"
means that iSER is used
    LUN information:
        LUN: 0
            Type: controller
            SCSI ID: deadbeaf1:0
            SCSI SN: beaf10
            Size: 0
            Online: Yes
            Poweron/Reset: Yes
            Removable media: No
            Backing store: No backing store
        LUN: 1
            Type: disk
            SCSI ID: deadbeaf1:1
            SCSI SN: beaf11
            Size: 82G
            Online: Yes
            Poweron/Reset: No
            Removable media: No
            Backing store: /dev/sds
    Account information:
    ACL information:
        ALL

Erez


From erezz at Voltaire.COM  Sun Feb 10 15:12:43 2008
From: erezz at Voltaire.COM (Erez Zilber)
Date: Sun, 10 Feb 2008 16:12:43 +0200
Subject: [Stgt-devel] [ANNOUNCE] open iSCSI over iSER target RPM is
	available
In-Reply-To: <e2e108260802050748u7bc9bd2fx24dadcaa06b355d3@mail.gmail.com>
References: <47A87586.6010904@Voltaire.COM>
	<e2e108260802050748u7bc9bd2fx24dadcaa06b355d3@mail.gmail.com>
Message-ID: <47AF065B.8080007@Voltaire.COM>

Bart Van Assche wrote:
> On Feb 5, 2008 3:41 PM, Erez Zilber <erezz at voltaire.com> wrote:
>   
>> stgt (SCSI target) is an open-source framework for storage target
>> drivers. It supports iSCSI over iSER among other storage target drivers.
>>
>> Voltaire added a git tree for stgt that will be added to OFED 1.4:
>> http://www2.openfabrics.org/git/?p=~dorons/tgt.git;a=summary
>>
>> Until OFED 1.4 gets released, it is possible to install the stgt RPM on
>> top of OFED 1.3. For more details about how to install and use stgt,
>> please refer to https://wiki.openfabrics.org/tiki-index.php?page=ISER-target
>>
>> Some performance numbers that were measured by OSC (using SDR cards):
>>
>>     * READ: 920 MB/sec
>>     * WRITE: 850 MB/sec
>>
>> We hope to have DDR measurements numbers soon.
>>     
>
> Hello Erez,
>
> Can you please post more information about how these numbers were
> obtained (test program and configuration parameters) ?
>
> Bart Van Assche.
>   

I will post more info. As mentioned above, I still didn't have a chance
to run performance tests myself. The numbers are taken from measurements
done in OSC by Pete Wyckoff.

Anyway, after I run the performance tests (also on DDR cards), I will
post instructions in the wiki page.

Erez


From erezz at Voltaire.COM  Mon Feb 11 06:59:41 2008
From: erezz at Voltaire.COM (Erez Zilber)
Date: Mon, 11 Feb 2008 07:59:41 +0200
Subject: [Stgt-devel] Tuning iSER for performance
In-Reply-To: <20080210204226.GA22320@porcupine.cita.utoronto.ca>
References: <47AEF406.6020908@Voltaire.COM> <20080210144229.GA16556@osc.edu>
	<47AF15E7.2000503@Voltaire.COM>
	<20080210204226.GA22320@porcupine.cita.utoronto.ca>
Message-ID: <47AFE44D.1010103@Voltaire.COM>

Robin Humble wrote:
> On Sun, Feb 10, 2008 at 05:19:03PM +0200, Erez Zilber wrote:
>   
>> Robin - did you try to use a real device? If yes, did you see any
>> difference between running something like sgp_dd directly from the
>> target machine and running the same sgp_dd command from the initiator
>> machine?
>>     
>
> I've used real devices for some tests in the past, but haven't ever
> tried initiator on the same machine. sorry.
> the tests that I can do easily are with backing store files on lustre,
> which also uses IB, so that halves the available IB bandwidth for iSER.
>
> I can try initiator on the same machine with lustre in a few days time.
> direct attached storage will prob have to wait a month 'til I get back
> from Canada :-/
>
> cheers,
> robin
>   

Robin,

I'm adding stgt list to this thread.

I'm not talking about running the initiator & the target from the same
machine. What I said is that if you're running the initiator on machine
'A' and the target on machine 'B', I see the following behavior:

    * running sgp_dd directly from the target machine - 400 MB/sec
      (which is the throughput of the LUN)
    * running sgp_dd from the initiator on the same LUN - 240 MB/sec

If you get better numbers, I'm interested to know if you're using the
default config or anything else.

Erez


From bart.vanassche at gmail.com  Mon Feb 11 08:33:59 2008
From: bart.vanassche at gmail.com (Bart Van Assche)
Date: Mon, 11 Feb 2008 08:33:59 +0100
Subject: [Stgt-devel] Tuning iSER for performance
In-Reply-To: <47AFE44D.1010103@Voltaire.COM>
References: <47AEF406.6020908@Voltaire.COM> <20080210144229.GA16556@osc.edu>
	<47AF15E7.2000503@Voltaire.COM>
	<20080210204226.GA22320@porcupine.cita.utoronto.ca>
	<47AFE44D.1010103@Voltaire.COM>
Message-ID: <e2e108260802102333i2892f509qcb298f357370d7a3@mail.gmail.com>

On Feb 11, 2008 6:59 AM, Erez Zilber <erezz at voltaire.com> wrote:
> I'm not talking about running the initiator & the target from the same
> machine. What I said is that if you're running the initiator on machine
> 'A' and the target on machine 'B', I see the following behavior:
>
>     * running sgp_dd directly from the target machine - 400 MB/sec
>       (which is the throughput of the LUN)
>     * running sgp_dd from the initiator on the same LUN - 240 MB/sec
>
> If you get better numbers, I'm interested to know if you're using the
> default config or anything else.

The results I obtained with STGT over iSER on an SDR network are as
follows (direct I/O with  xdd):
* 7.4 MB/s for reading data in blocks of 512 bytes and 8.9 MB/s for writing.
* 363 MB/s for reading data in blocks of 65536 bytes and 346 MB/s for writing.
* 890 MB/s for reading data in blocks of 10 MB and 900 MB/s for writing.

Please keep in mind that when running a filesystem on top of iSCSI
that all transfers happen in units of 64 KB or less.

Bart Van Assche.


From tomof at acm.org  Mon Feb 11 13:52:01 2008
From: tomof at acm.org (FUJITA Tomonori)
Date: Mon, 11 Feb 2008 21:52:01 +0900
Subject: [Stgt-devel] [Scst-devel] Integration of SCST in the mainstream
	Linux kernel
In-Reply-To: <C3CE56CB.57D4%matteo@rmnet.it>
References: <20080205223740L.tomof@acm.org>
	<C3CE56CB.57D4%matteo@rmnet.it>
Message-ID: <20080211215153W.tomof@acm.org>

On Tue, 05 Feb 2008 18:09:15 +0100
Matteo Tescione <matteo at rmnet.it> wrote:

> On 5-02-2008 14:38, "FUJITA Tomonori" <tomof at acm.org> wrote:
> 
> > On Tue, 05 Feb 2008 08:14:01 +0100
> > Tomasz Chmielewski <mangoo at wpkg.org> wrote:
> > 
> >> James Bottomley schrieb:
> >> 
> >>> These are both features being independently worked on, are they not?
> >>> Even if they weren't, the combination of the size of SCST in kernel plus
> >>> the problem of having to find a migration path for the current STGT
> >>> users still looks to me to involve the greater amount of work.
> >> 
> >> I don't want to be mean, but does anyone actually use STGT in
> >> production? Seriously?
> >> 
> >> In the latest development version of STGT, it's only possible to stop
> >> the tgtd target daemon using KILL / 9 signal - which also means all
> >> iSCSI initiator connections are corrupted when tgtd target daemon is
> >> started again (kernel upgrade, target daemon upgrade, server reboot etc.).
> > 
> > I don't know what "iSCSI initiator connections are corrupted"
> > mean. But if you reboot a server, how can an iSCSI target
> > implementation keep iSCSI tcp connections?
> > 
> > 
> >> Imagine you have to reboot all your NFS clients when you reboot your NFS
> >> server. Not only that - your data is probably corrupted, or at least the
> >> filesystem deserves checking...
> 
> Don't know if matters, but in my setup (iscsi on top of drbd+heartbeat)
> rebooting the primary server doesn't affect my iscsi traffic, SCST correctly
> manages stop/crash, by sending unit attention to clients on reconnect.
> Drbd+heartbeat correctly manages those things too.
> Still from an end-user POV, i was able to reboot/survive a crash only with
> SCST, IETD still has reconnect problems and STGT are even worst.

Can you tell us the details of your tgt configuration?

The git head of tgt can handle Unit Attention condition though it's
not tested much.


From tomof at acm.org  Mon Feb 11 13:58:19 2008
From: tomof at acm.org (FUJITA Tomonori)
Date: Mon, 11 Feb 2008 21:58:19 +0900
Subject: [Stgt-devel] yet another tgtd iSCSI misbehaviour (aborted
 journal, remounting ro)
In-Reply-To: <47A981D2.1050806@wpkg.org>
References: <47A981D2.1050806@wpkg.org>
Message-ID: <20080211215817B.tomof@acm.org>

On Wed, 06 Feb 2008 10:45:54 +0100
Tomasz Chmielewski <mangoo at wpkg.org> wrote:

> It seems there is yet another problem (?) in tgtd.
> 
> It can be easily reproduced when the initiator crashes and then starts 
> again. I tested it only with diskless machines booted off iSCSI.
> 
> To reproduce:
> 
> 1. Start tgtd, apply settings with tgtadm
> 2. Start a diskless initiator:
>   a) a diskless initiator fetches the kernel and the initrd via PXE/tftp
>   b) kernel executes initrd; initrd brings the interface up
>   c) initrd starts the iSCSI connection with "iscsistart" command from 
> open-iscsi
>   d) we switch to a new root, system boots fine
>   e) IMPORTANT - system starts iscsid now (/etc/init.d/open-iscsi start)
> 
> So far, everything was fine and unproblematic.
> 
> 3. Now, crash your initiator machine (i.e. press reboot button)[1].
> 
> 4. Initiator starts just fine again - the connection was established 
> with "iscsistart".
> 
> 5. IMPORTANT - start iscsid now (/etc/init.d/open-iscsi start). The 
> initiator will report "connection1:0: iscsi: detected conn error (1011)" 
> and eventually, will break the connection, remount fs readonly etc. 
> scary things will happen.
> 
>   a) there is a workaround to that: when initiator reports 
> "connection1:0: iscsi: detected conn error..." - kill tgtd, and start it 
> again. Initiator will reconnect flawlessly
>   b) if you don't kill/start tgtd again, connection will break and fs 
> will be remounted ro.
> 
> 
> The issue does not happen with IET or SCST.
> 
> It looks like:
> - tgtd has an established connection with an initiator
> - initiator is killed, but tgtd still thinks initiator is connected
> to it

Did you confirm this? 'tgtadm --op show --mode target' shows you the
active initiators (and its connections).


> - initiator connects from the same IP address
> - when we start iscsid on the initiator, it confuses tgtd, tgtd breaks 
> and has to be restarted
> 
> 
> Let me know if you need such tcpdumps (if so, please give me all tcpdump 
> command line options you would use):
> 
> - point 2e) - clean start of iscsid on the initiator
> - point 5) - iscsid start on the initiator when connection breaks
> - iscsid start on the initiator, target is SCST
> 
> 
> [1] I use kexec here to reboot the machine because it has a buggy BIOS 
> (an old Supermicro P4SBR/P4SBE server). Randomly, it doesn't reboot when 
> a normal reboot command is used; the system shuts down, but never 
> reboots. kexec is a nice workaround for that, but it doesn't close 
> network sockets, so the target thinks we're still connected.
> 
> 
> -- 
> Tomasz Chmielewski
> http://wpkg.org
> _______________________________________________
> Stgt-devel mailing list
> Stgt-devel at lists.berlios.de
> https://lists.berlios.de/mailman/listinfo/stgt-devel


From mangoo at wpkg.org  Mon Feb 11 14:01:42 2008
From: mangoo at wpkg.org (Tomasz Chmielewski)
Date: Mon, 11 Feb 2008 14:01:42 +0100
Subject: [Stgt-devel] yet another tgtd iSCSI misbehaviour (aborted
 journal, remounting ro)
In-Reply-To: <20080211215817B.tomof@acm.org>
References: <47A981D2.1050806@wpkg.org> <20080211215817B.tomof@acm.org>
Message-ID: <47B04736.4080906@wpkg.org>

FUJITA Tomonori schrieb:
> On Wed, 06 Feb 2008 10:45:54 +0100
> Tomasz Chmielewski <mangoo at wpkg.org> wrote:
> 
>> It seems there is yet another problem (?) in tgtd.
>>
>> It can be easily reproduced when the initiator crashes and then starts 
>> again. I tested it only with diskless machines booted off iSCSI.
>>
>> To reproduce:
>>
>> 1. Start tgtd, apply settings with tgtadm
>> 2. Start a diskless initiator:
>>   a) a diskless initiator fetches the kernel and the initrd via PXE/tftp
>>   b) kernel executes initrd; initrd brings the interface up
>>   c) initrd starts the iSCSI connection with "iscsistart" command from 
>> open-iscsi
>>   d) we switch to a new root, system boots fine
>>   e) IMPORTANT - system starts iscsid now (/etc/init.d/open-iscsi start)
>>
>> So far, everything was fine and unproblematic.
>>
>> 3. Now, crash your initiator machine (i.e. press reboot button)[1].
>>
>> 4. Initiator starts just fine again - the connection was established 
>> with "iscsistart".
>>
>> 5. IMPORTANT - start iscsid now (/etc/init.d/open-iscsi start). The 
>> initiator will report "connection1:0: iscsi: detected conn error (1011)" 
>> and eventually, will break the connection, remount fs readonly etc. 
>> scary things will happen.
>>
>>   a) there is a workaround to that: when initiator reports 
>> "connection1:0: iscsi: detected conn error..." - kill tgtd, and start it 
>> again. Initiator will reconnect flawlessly
>>   b) if you don't kill/start tgtd again, connection will break and fs 
>> will be remounted ro.
>>
>>
>> The issue does not happen with IET or SCST.
>>
>> It looks like:
>> - tgtd has an established connection with an initiator
>> - initiator is killed, but tgtd still thinks initiator is connected
>> to it
> 
> Did you confirm this? 'tgtadm --op show --mode target' shows you the
> active initiators (and its connections).

Yes, as I remember, it was showing multiple initiators connected.



-- 
Tomasz Chmielewski
http://wpkg.org


From tomof at acm.org  Mon Feb 11 14:18:08 2008
From: tomof at acm.org (FUJITA Tomonori)
Date: Mon, 11 Feb 2008 22:18:08 +0900
Subject: [Stgt-devel] yet another tgtd iSCSI misbehaviour (aborted
 journal, remounting ro)
In-Reply-To: <47B04736.4080906@wpkg.org>
References: <47A981D2.1050806@wpkg.org> <20080211215817B.tomof@acm.org>
	<47B04736.4080906@wpkg.org>
Message-ID: <200802111318.m1BDICOd031915@mbox.iij4u.or.jp>

From: Tomasz Chmielewski <mangoo at wpkg.org>
Subject: Re: [Stgt-devel] yet another tgtd iSCSI misbehaviour (aborted journal, remounting ro)
Date: Mon, 11 Feb 2008 14:01:42 +0100

> FUJITA Tomonori schrieb:
> > On Wed, 06 Feb 2008 10:45:54 +0100
> > Tomasz Chmielewski <mangoo at wpkg.org> wrote:
> > 
> >> It seems there is yet another problem (?) in tgtd.
> >>
> >> It can be easily reproduced when the initiator crashes and then starts 
> >> again. I tested it only with diskless machines booted off iSCSI.
> >>
> >> To reproduce:
> >>
> >> 1. Start tgtd, apply settings with tgtadm
> >> 2. Start a diskless initiator:
> >>   a) a diskless initiator fetches the kernel and the initrd via PXE/tftp
> >>   b) kernel executes initrd; initrd brings the interface up
> >>   c) initrd starts the iSCSI connection with "iscsistart" command from 
> >> open-iscsi
> >>   d) we switch to a new root, system boots fine
> >>   e) IMPORTANT - system starts iscsid now (/etc/init.d/open-iscsi start)
> >>
> >> So far, everything was fine and unproblematic.
> >>
> >> 3. Now, crash your initiator machine (i.e. press reboot button)[1].
> >>
> >> 4. Initiator starts just fine again - the connection was established 
> >> with "iscsistart".
> >>
> >> 5. IMPORTANT - start iscsid now (/etc/init.d/open-iscsi start). The 
> >> initiator will report "connection1:0: iscsi: detected conn error (1011)" 
> >> and eventually, will break the connection, remount fs readonly etc. 
> >> scary things will happen.
> >>
> >>   a) there is a workaround to that: when initiator reports 
> >> "connection1:0: iscsi: detected conn error..." - kill tgtd, and start it 
> >> again. Initiator will reconnect flawlessly
> >>   b) if you don't kill/start tgtd again, connection will break and fs 
> >> will be remounted ro.
> >>
> >>
> >> The issue does not happen with IET or SCST.
> >>
> >> It looks like:
> >> - tgtd has an established connection with an initiator
> >> - initiator is killed, but tgtd still thinks initiator is connected
> >> to it
> > 
> > Did you confirm this? 'tgtadm --op show --mode target' shows you the
> > active initiators (and its connections).
> 
> Yes, as I remember, it was showing multiple initiators connected.

If so, the target has two independent sessions (the same IP address
doesn't matter). It should be ok.


> - when we start iscsid on the initiator, it confuses tgtd, tgtd
> breaks and has to be restarted

This isn't the case. Are you sure that tgtd started to close the
connection (I mean that the initiator might start to close the
connection)?

We need to know why the connection was closed. Can you perform
`tcpdump -w dump.cap -s 1600` and send dump.cap?


From mangoo at wpkg.org  Mon Feb 11 14:27:01 2008
From: mangoo at wpkg.org (Tomasz Chmielewski)
Date: Mon, 11 Feb 2008 14:27:01 +0100
Subject: [Stgt-devel] yet another tgtd iSCSI misbehaviour (aborted
 journal, remounting ro)
In-Reply-To: <200802111318.m1BDICOd031915@mbox.iij4u.or.jp>
References: <47A981D2.1050806@wpkg.org>	<20080211215817B.tomof@acm.org>	<47B04736.4080906@wpkg.org>
	<200802111318.m1BDICOd031915@mbox.iij4u.or.jp>
Message-ID: <47B04D25.7090306@wpkg.org>

FUJITA Tomonori schrieb:

(...)

>> - when we start iscsid on the initiator, it confuses tgtd, tgtd
>> breaks and has to be restarted
> 
> This isn't the case. Are you sure that tgtd started to close the
> connection (I mean that the initiator might start to close the
> connection)?
> 
> We need to know why the connection was closed. Can you perform
> `tcpdump -w dump.cap -s 1600` and send dump.cap?

I'll try to send a dump this or next week (I'm busy a bit ATM).


-- 
Tomasz Chmielewski
http://wpkg.org



From erezz at Voltaire.COM  Tue Feb 12 10:59:49 2008
From: erezz at Voltaire.COM (Erez Zilber)
Date: Tue, 12 Feb 2008 11:59:49 +0200
Subject: [Stgt-devel] Different throughput numbers on SLES 10 and RHEL 5.1
Message-ID: <47B16E15.6050201@Voltaire.COM>

Hi,

I'm using the latest stgt release (tgt-20071227) and I see different
throughput numbers for READ commands on SLES 10  & RHEL 5.1. I'm using
stgt with iSCSI over iSER.

I'm using the same initiator (open-iscsi 865.15 from OFED 1.3 rc4) and
the same target machine. The target machine has 2 partitions - one is
SLES 10 & the other is RHEL 5.1. When I run READ commands against the
target on SLES 10, I get ~400 MB/sec (which is the throughput of the
LUN). When I run the same READ commands from the same initiator against
the target on RHEL 5.1, I get only 240 MB/sec.

Is there anything that I need to config on the RHEL 5.1 machine? BTW -
if I run the same test directly from the target machine, I get 400
MB/sec on both distros.

Here's the command that I use:

sgp_dd if=/dev/sdc of=/dev/null bs=512 bpt=1024 thr=8 time=1 count=20480000

Thanks,
Erez


From erezz at Voltaire.COM  Tue Feb 12 11:06:43 2008
From: erezz at Voltaire.COM (Erez Zilber)
Date: Tue, 12 Feb 2008 12:06:43 +0200
Subject: [Stgt-devel] Tuning iSER for performance
In-Reply-To: <e2e108260802102333i2892f509qcb298f357370d7a3@mail.gmail.com>
References: <47AEF406.6020908@Voltaire.COM> <20080210144229.GA16556@osc.edu>	
	<47AF15E7.2000503@Voltaire.COM>	
	<20080210204226.GA22320@porcupine.cita.utoronto.ca>	
	<47AFE44D.1010103@Voltaire.COM>
	<e2e108260802102333i2892f509qcb298f357370d7a3@mail.gmail.com>
Message-ID: <47B16FB3.2010202@Voltaire.COM>

Bart Van Assche wrote:
> On Feb 11, 2008 6:59 AM, Erez Zilber <erezz at voltaire.com> wrote:
>   
>> I'm not talking about running the initiator & the target from the same
>> machine. What I said is that if you're running the initiator on machine
>> 'A' and the target on machine 'B', I see the following behavior:
>>
>>     * running sgp_dd directly from the target machine - 400 MB/sec
>>       (which is the throughput of the LUN)
>>     * running sgp_dd from the initiator on the same LUN - 240 MB/sec
>>
>> If you get better numbers, I'm interested to know if you're using the
>> default config or anything else.
>>     
>
> The results I obtained with STGT over iSER on an SDR network are as
> follows (direct I/O with  xdd):
> * 7.4 MB/s for reading data in blocks of 512 bytes and 8.9 MB/s for writing.
> * 363 MB/s for reading data in blocks of 65536 bytes and 346 MB/s for writing.
> * 890 MB/s for reading data in blocks of 10 MB and 900 MB/s for writing.
>
> Please keep in mind that when running a filesystem on top of iSCSI
> that all transfers happen in units of 64 KB or less.
>
> Bart Van Assche.
>   

Can you send more details about your configuration?

    * stgt version
    * initiator version
    * Which distro do you use for the initiator/target?
    * Which benchmark do you use? What are the parameters?
    * What are the results if you run the same benchmark directly from
      the target machine (i.e. no iSCSI & iSER involved)?
    * Are you using the default config for the initiator/target?

Here's my config:

    * target:
          o

            tgt-20071227 (actually, I use the RPM that I uploaded to OpenFabrics, which is almost identical to tgt-20071227)

          o SLES 10
          o default stgt config
    * initiator:
          o OFED 1.3 rc4
          o SLES 10 sp1
          o default open-iscsi config



From robin.humble+stgt at anu.edu.au  Tue Feb 12 11:36:46 2008
From: robin.humble+stgt at anu.edu.au (Robin Humble)
Date: Tue, 12 Feb 2008 05:36:46 -0500
Subject: [Stgt-devel] Tuning iSER for performance
In-Reply-To: <47B16FB3.2010202@Voltaire.COM>
References: <47AEF406.6020908@Voltaire.COM> <20080210144229.GA16556@osc.edu>
	<47AF15E7.2000503@Voltaire.COM>
	<20080210204226.GA22320@porcupine.cita.utoronto.ca>
	<47AFE44D.1010103@Voltaire.COM>
	<e2e108260802102333i2892f509qcb298f357370d7a3@mail.gmail.com>
	<47B16FB3.2010202@Voltaire.COM>
Message-ID: <20080212103646.GA18518@porcupine.cita.utoronto.ca>

On Tue, Feb 12, 2008 at 12:06:43PM +0200, Erez Zilber wrote:
>Can you send more details about your configuration?

kernel version would also be good to record. in the past I've seen
fairly different read performances when using different kernels.

cheers,
robin

>    * stgt version
>    * initiator version
>    * Which distro do you use for the initiator/target?
>    * Which benchmark do you use? What are the parameters?
>    * What are the results if you run the same benchmark directly from
>      the target machine (i.e. no iSCSI & iSER involved)?
>    * Are you using the default config for the initiator/target?
>
>Here's my config:
>
>    * target:
>          o
>
>            tgt-20071227 (actually, I use the RPM that I uploaded to OpenFabrics, which is almost identical to tgt-20071227)
>
>          o SLES 10
>          o default stgt config
>    * initiator:
>          o OFED 1.3 rc4
>          o SLES 10 sp1
>          o default open-iscsi config
>
>_______________________________________________
>Stgt-devel mailing list
>Stgt-devel at lists.berlios.de
>https://lists.berlios.de/mailman/listinfo/stgt-devel


From bart.vanassche at gmail.com  Tue Feb 12 12:00:02 2008
From: bart.vanassche at gmail.com (Bart Van Assche)
Date: Tue, 12 Feb 2008 12:00:02 +0100
Subject: [Stgt-devel] Tuning iSER for performance
In-Reply-To: <47B16FB3.2010202@Voltaire.COM>
References: <47AEF406.6020908@Voltaire.COM> <20080210144229.GA16556@osc.edu>
	<47AF15E7.2000503@Voltaire.COM>
	<20080210204226.GA22320@porcupine.cita.utoronto.ca>
	<47AFE44D.1010103@Voltaire.COM>
	<e2e108260802102333i2892f509qcb298f357370d7a3@mail.gmail.com>
	<47B16FB3.2010202@Voltaire.COM>
Message-ID: <e2e108260802120300w22670002w24bdd82cf831c2f4@mail.gmail.com>

On Feb 12, 2008 11:06 AM, Erez Zilber <erezz at voltaire.com> wrote:
> > The results I obtained with STGT over iSER on an SDR network are as
> > follows (direct I/O with  xdd):
> > * 7.4 MB/s for reading data in blocks of 512 bytes and 8.9 MB/s for writing.
> > * 363 MB/s for reading data in blocks of 65536 bytes and 346 MB/s for writing.
> > * 890 MB/s for reading data in blocks of 10 MB and 900 MB/s for writing.
> >
> > Please keep in mind that when running a filesystem on top of iSCSI
> > that all transfers happen in units of 64 KB or less.
>
> Can you send more details about your configuration?
>
>     * stgt version
>     * initiator version
>     * Which distro do you use for the initiator/target?
>     * Which benchmark do you use? What are the parameters?
>     * What are the results if you run the same benchmark directly from
>       the target machine (i.e. no iSCSI & iSER involved)?
>     * Are you using the default config for the initiator/target?
>
> Here's my config:
>
>     * target:
>           o tgt-20071227 (actually, I use the RPM that I uploaded to OpenFabrics, which is almost identical to tgt-20071227)
>           o SLES 10
>           o default stgt config
>     * initiator:
>           o OFED 1.3 rc4
>           o SLES 10 sp1
>           o default open-iscsi config

My config was as follows (same software versions on initiator and target):
* Ubuntu 7.10 server.
* Linux kernel 2.6.23.14 + SCST kernel patches (SVN revision 253).
* OFED 1.2.5.5 userspace components, compiled from the OFED source distribution.
* tgt-20071227 + TCP_NODELAY patch
* Ubuntu's open-iscsi (version 2.0.865-1).
* xdd version xdd65.013007.
* Benchmark (with e.g. disk=/dev/sde and i in the range 9 .. 30): xdd
-verbose -processlock -dio -op read -targets 1 $disk -reqsize 1
-blocksize $((2**i)) -mbytes 2048 -passes 3;
xdd -verbose -processlock -dio -op write -targets 1 $disk -reqsize 1
-blocksize $((2**i)) -mbytes 2048 -passes 3
* Target setup:
modprobe ib_uverbs
modprobe rdma_ucm
/bin/mkdir -p /dev/infiniband
/bin/mknod /dev/infiniband/uverbs0 c $(cat
/sys/class/infiniband_verbs/uverbs0/dev | sed 's/:/ /g')
/bin/mknod /dev/infiniband/rdma_cm c $(cat /sys/class/misc/rdma_cm/dev
| sed 's/:/ /g')
tgtd
tgtadm --lld iscsi --op new --mode target --tid 1 -T
iqn.2007-05.com.example:storage.disk2.sys1.xyz
tgtadm --lld iscsi --op new --mode logicalunit --tid 1 --lun 1 -b /dev/ram0
tgtadm --lld iscsi --op bind --mode target --tid 1 -I ALL
* Initiator setup:
iscsi_target_ip=192.168.102.10
rm -rf /etc/iscsi/nodes /etc/iscsi/send_targets
iscsiadm -m discovery -t sendtargets -p ${iscsi_target_ip}
iscsiadm --mode node --targetname
iqn.2007-05.com.example:storage.disk2.sys1.xyz \
  --portal ${iscsi_target_ip}:3260 --op update -n node.transport_name -v iser
iscsiadm --mode node --targetname
iqn.2007-05.com.example:storage.disk2.sys1.xyz \
  --portal ${iscsi_target_ip}:3260 --op update -n
"node.conn[0].iscsi.HeaderDigest" -v None
iscsiadm -m node -T iqn.2007-05.com.example:storage.disk2.sys1.xyz -p
${iscsi_target_ip} --login
* Results for a local run of the benchmark (!! using buffered I/O
instead of direct I/O !! because /dev/ram0 does not support direct
I/O):
- 354 MB/s for reading data in blocks of 512 bytes and 303 MB/s for writing.
- 2514 MB/s for reading data in blocks of 65536 bytes and 2582 MB/s for writing.
- 1400 MB/s for reading data in blocks of 10 MB and 1690 MB/s for writing.

Bart Van Assche.


From bart.vanassche at gmail.com  Tue Feb 12 12:02:05 2008
From: bart.vanassche at gmail.com (Bart Van Assche)
Date: Tue, 12 Feb 2008 12:02:05 +0100
Subject: [Stgt-devel] Different throughput numbers on SLES 10 and RHEL
	5.1
In-Reply-To: <47B16E15.6050201@Voltaire.COM>
References: <47B16E15.6050201@Voltaire.COM>
Message-ID: <e2e108260802120302jd9d4afdt1c3227d45d21ed3b@mail.gmail.com>

On Feb 12, 2008 10:59 AM, Erez Zilber <erezz at voltaire.com> wrote:
> I'm using the latest stgt release (tgt-20071227) and I see different
> throughput numbers for READ commands on SLES 10  & RHEL 5.1. I'm using
> stgt with iSCSI over iSER.

Which numbers does ib_write_bw report between initiator and target for
the two different Linux distributions ?

Bart Van Assche.


From robin.humble+stgt at anu.edu.au  Tue Feb 12 12:17:15 2008
From: robin.humble+stgt at anu.edu.au (Robin Humble)
Date: Tue, 12 Feb 2008 06:17:15 -0500
Subject: [Stgt-devel] Different throughput numbers on SLES 10 and
	RHEL	5.1
In-Reply-To: <e2e108260802120302jd9d4afdt1c3227d45d21ed3b@mail.gmail.com>
References: <47B16E15.6050201@Voltaire.COM>
	<e2e108260802120302jd9d4afdt1c3227d45d21ed3b@mail.gmail.com>
Message-ID: <20080212111715.GC18518@porcupine.cita.utoronto.ca>

On Tue, Feb 12, 2008 at 12:02:05PM +0100, Bart Van Assche wrote:
>On Feb 12, 2008 10:59 AM, Erez Zilber <erezz at voltaire.com> wrote:
>> I'm using the latest stgt release (tgt-20071227) and I see different
>> throughput numbers for READ commands on SLES 10  & RHEL 5.1. I'm using
>> stgt with iSCSI over iSER.
>Which numbers does ib_write_bw report between initiator and target for
>the two different Linux distributions ?

are you loading mthca with
  options ib_mthca tune_pci=1
so that lspci -vvv says:
  MaxReadReq 4096 bytes
for the IB card?
some distros seem to have this on by default, and others don't.
with the normal default of MaxReadReq 128(?) total IB bandwidth is
about halved.

you could look at lspci -vvv between the 2 distros and check.

as Bart says you should prob be able to see that difference with the ib
bw utils too, but in my testing I used netpipe's NPmpi with OpenMPI for
bandwidth tests.

looking at /proc/interrupts between the 2 distros might also tell you
something. I haven't tried pinning interrupts to cores and don't know
what the distros do by default. possibly msi_x=1 as another option to
ib_mthca might help too.

cheers,
robin


From bart.vanassche at gmail.com  Tue Feb 12 12:24:59 2008
From: bart.vanassche at gmail.com (Bart Van Assche)
Date: Tue, 12 Feb 2008 12:24:59 +0100
Subject: [Stgt-devel] Different throughput numbers on SLES 10 and RHEL
	5.1
In-Reply-To: <20080212111715.GC18518@porcupine.cita.utoronto.ca>
References: <47B16E15.6050201@Voltaire.COM>
	<e2e108260802120302jd9d4afdt1c3227d45d21ed3b@mail.gmail.com>
	<20080212111715.GC18518@porcupine.cita.utoronto.ca>
Message-ID: <e2e108260802120324y482268d4m1cd5e4b40089be3c@mail.gmail.com>

On Feb 12, 2008 12:17 PM, Robin Humble <robin.humble+stgt at anu.edu.au> wrote:
>
> are you loading mthca with
>   options ib_mthca tune_pci=1
> so that lspci -vvv says:
>   MaxReadReq 4096 bytes

An even better way than specifying tune_pci=1 is to perform a BIOS
upgrade. On an Intel S5000PAL this increased MaxReadReq from 128 to
512 bytes, which is enough to obtain maximal throughput on an SDR 4x
IB network.

Bart Van Assche.


From erezz at voltaire.com  Wed Feb 13 13:10:04 2008
From: erezz at voltaire.com (Erez Zilber)
Date: Wed, 13 Feb 2008 14:10:04 +0200
Subject: [Stgt-devel] Different throughput numbers on SLES 10 and RHEL
 5.1
In-Reply-To: <e2e108260802120324y482268d4m1cd5e4b40089be3c@mail.gmail.com>
References: <47B16E15.6050201@Voltaire.COM>	
	<e2e108260802120302jd9d4afdt1c3227d45d21ed3b@mail.gmail.com>	
	<20080212111715.GC18518@porcupine.cita.utoronto.ca>
	<e2e108260802120324y482268d4m1cd5e4b40089be3c@mail.gmail.com>
Message-ID: <47B2DE1C.5000506@voltaire.com>

Bart Van Assche wrote:

> On Feb 12, 2008 12:17 PM, Robin Humble <robin.humble+stgt at anu.edu.au> wrote:
>   
>> are you loading mthca with
>>   options ib_mthca tune_pci=1
>> so that lspci -vvv says:
>>   MaxReadReq 4096 bytes
>>     
>
> An even better way than specifying tune_pci=1 is to perform a BIOS
> upgrade. On an Intel S5000PAL this increased MaxReadReq from 128 to
> 512 bytes, which is enough to obtain maximal throughput on an SDR 4x
> IB network.
>
> Bart Van Assche.
>   

I'm adding Mike Christie. Mike - as the maintainer of stgt in RHEL 5,
maybe you can help.

I don't think that IB is the problem here. I ran ib_rdma_bw on both
distros and got ~1350 MB/sec. Note that although there's a big
difference between SLES & RedHat, we're talking about 400 MB/sec which
is much lower than IB bandwidth.

Another test that I ran that proves that IB is not the problem here - I
ran another iSCSI over iSER target (i.e. not stgt) on RHEL 5, and I got
400 MB/sec when running sgp_dd from the initiator. I guess that there's
something bad with stgt on RHEL 5...

So, here's the current status for the sgp_dd test:

    * Running open-iscsi over iSER against stgt that runs on SLES 10:
      READ/WRITE - 400 MB/sec
    * Running open-iscsi over iSER against stgt that runs on RHEL 5:
      READ - 240 MB/sec, WRITE - 400 MB/sec
    * Running open-iscsi over iSER against our own iSCSI over iSER
      target that runs on RHEL 5: READ/WRITE - 400 MB/sec
    * Running sgp_dd directly from the target machine: READ/WRITE - 400
      MB/sec




From erezz at Voltaire.COM  Wed Feb 13 16:07:17 2008
From: erezz at Voltaire.COM (Erez Zilber)
Date: Wed, 13 Feb 2008 17:07:17 +0200
Subject: [Stgt-devel] Tuning iSER for performance
In-Reply-To: <e2e108260802120300w22670002w24bdd82cf831c2f4@mail.gmail.com>
References: <47AEF406.6020908@Voltaire.COM> <20080210144229.GA16556@osc.edu>	
	<47AF15E7.2000503@Voltaire.COM>	
	<20080210204226.GA22320@porcupine.cita.utoronto.ca>	
	<47AFE44D.1010103@Voltaire.COM>	
	<e2e108260802102333i2892f509qcb298f357370d7a3@mail.gmail.com>	
	<47B16FB3.2010202@Voltaire.COM>
	<e2e108260802120300w22670002w24bdd82cf831c2f4@mail.gmail.com>
Message-ID: <47B307A5.9020800@Voltaire.COM>

Bart Van Assche wrote:
> On Feb 12, 2008 11:06 AM, Erez Zilber <erezz at voltaire.com> wrote:
>   
>>> The results I obtained with STGT over iSER on an SDR network are as
>>> follows (direct I/O with  xdd):
>>> * 7.4 MB/s for reading data in blocks of 512 bytes and 8.9 MB/s for writing.
>>> * 363 MB/s for reading data in blocks of 65536 bytes and 346 MB/s for writing.
>>> * 890 MB/s for reading data in blocks of 10 MB and 900 MB/s for writing.
>>>
>>> Please keep in mind that when running a filesystem on top of iSCSI
>>> that all transfers happen in units of 64 KB or less.
>>>       
>> Can you send more details about your configuration?
>>
>>     * stgt version
>>     * initiator version
>>     * Which distro do you use for the initiator/target?
>>     * Which benchmark do you use? What are the parameters?
>>     * What are the results if you run the same benchmark directly from
>>       the target machine (i.e. no iSCSI & iSER involved)?
>>     * Are you using the default config for the initiator/target?
>>
>> Here's my config:
>>
>>     * target:
>>           o tgt-20071227 (actually, I use the RPM that I uploaded to OpenFabrics, which is almost identical to tgt-20071227)
>>           o SLES 10
>>           o default stgt config
>>     * initiator:
>>           o OFED 1.3 rc4
>>           o SLES 10 sp1
>>           o default open-iscsi config
>>     
>
> My config was as follows (same software versions on initiator and target):
> * Ubuntu 7.10 server.
> * Linux kernel 2.6.23.14 + SCST kernel patches (SVN revision 253).
> * OFED 1.2.5.5 userspace components, compiled from the OFED source distribution.
> * tgt-20071227 + TCP_NODELAY patch
> * Ubuntu's open-iscsi (version 2.0.865-1).
> * xdd version xdd65.013007.
> * Benchmark (with e.g. disk=/dev/sde and i in the range 9 .. 30): xdd
> -verbose -processlock -dio -op read -targets 1 $disk -reqsize 1
> -blocksize $((2**i)) -mbytes 2048 -passes 3;
> xdd -verbose -processlock -dio -op write -targets 1 $disk -reqsize 1
> -blocksize $((2**i)) -mbytes 2048 -passes 3
>   

I got these numbers:

                     T  Q       Bytes      Ops    Time      Rate     
IOPS   Latency     %CPU  OP_Type    ReqSize
TARGET   PASS0001    0  1    2147483648   4194304   315.311    
6.811     13302.12    0.0001     0.00   read         512
TARGET   PASS0002    0  1    2147483648   4194304   315.902    
6.798     13277.24    0.0001     0.00   read         512
TARGET   PASS0003    0  1    2147483648   4194304   315.539    
6.806     13292.49    0.0001     0.00   read         512
TARGET   Average     0  1    6442450944   12582912   946.752    
6.805     13290.61    0.0001     0.00   read         512
         Combined    1  1    6442450944   12582912   946.752    
6.805     13290.61    0.0001     0.00   read         512

from running the following cmd:

bin/xdd.linux -verbose -processlock -dio -op read -targets 1 /dev/sdc
-reqsize 1 -blocksize $((2**9)) -mbytes 2048 -passes 3

I'm not familiar enough with xdd, so I don't know how to tune it. Can
you try the following commands (assuming that /dev/sg4 is your sg device)?

READ: sgp_dd if=/dev/sg4 of=/dev/null bs=512 bpt=1024 count=20480000
thr=8 time=1
WRITE: sgp_dd of=/dev/sg4 if=/dev/zero bs=512 bpt=1024 count=20480000
thr=8 time=1

I ran that on a 4Gb LUN and got 400 MB/sec (wire speed).
 
> * Target setup:
> modprobe ib_uverbs
> modprobe rdma_ucm
> /bin/mkdir -p /dev/infiniband
> /bin/mknod /dev/infiniband/uverbs0 c $(cat
> /sys/class/infiniband_verbs/uverbs0/dev | sed 's/:/ /g')
> /bin/mknod /dev/infiniband/rdma_cm c $(cat /sys/class/misc/rdma_cm/dev
> | sed 's/:/ /g')
> tgtd
> tgtadm --lld iscsi --op new --mode target --tid 1 -T
> iqn.2007-05.com.example:storage.disk2.sys1.xyz
> tgtadm --lld iscsi --op new --mode logicalunit --tid 1 --lun 1 -b /dev/ram0
> tgtadm --lld iscsi --op bind --mode target --tid 1 -I ALL
>   

Instead of running that manually, you can try to use the tgt-setup-lun
script that we added. It creates a targets, assigns LUNs & initiators.

> * Initiator setup:
> iscsi_target_ip=192.168.102.10
> rm -rf /etc/iscsi/nodes /etc/iscsi/send_targets
> iscsiadm -m discovery -t sendtargets -p ${iscsi_target_ip}
> iscsiadm --mode node --targetname
> iqn.2007-05.com.example:storage.disk2.sys1.xyz \
>   --portal ${iscsi_target_ip}:3260 --op update -n node.transport_name -v iser
> iscsiadm --mode node --targetname
> iqn.2007-05.com.example:storage.disk2.sys1.xyz \
>   --portal ${iscsi_target_ip}:3260 --op update -n
> "node.conn[0].iscsi.HeaderDigest" -v None
>   

You can use the iscsi_discovery script instead. It does all of the above
automatically. If you install OFED with iSER support, it is included in
the open-iscsi package.

> iscsiadm -m node -T iqn.2007-05.com.example:storage.disk2.sys1.xyz -p
> ${iscsi_target_ip} --login
> * Results for a local run of the benchmark (!! using buffered I/O
> instead of direct I/O !! because /dev/ram0 does not support direct
> I/O):
> - 354 MB/s for reading data in blocks of 512 bytes and 303 MB/s for writing.
> - 2514 MB/s for reading data in blocks of 65536 bytes and 2582 MB/s for writing.
> - 1400 MB/s for reading data in blocks of 10 MB and 1690 MB/s for writing.
>
> Bart Van Assche.
>   


From bart.vanassche at gmail.com  Thu Feb 14 17:37:05 2008
From: bart.vanassche at gmail.com (Bart Van Assche)
Date: Thu, 14 Feb 2008 17:37:05 +0100
Subject: [Stgt-devel] Tuning iSER for performance
In-Reply-To: <47B307A5.9020800@Voltaire.COM>
References: <47AEF406.6020908@Voltaire.COM> <20080210144229.GA16556@osc.edu>
	<47AF15E7.2000503@Voltaire.COM>
	<20080210204226.GA22320@porcupine.cita.utoronto.ca>
	<47AFE44D.1010103@Voltaire.COM>
	<e2e108260802102333i2892f509qcb298f357370d7a3@mail.gmail.com>
	<47B16FB3.2010202@Voltaire.COM>
	<e2e108260802120300w22670002w24bdd82cf831c2f4@mail.gmail.com>
	<47B307A5.9020800@Voltaire.COM>
Message-ID: <e2e108260802140837k37f430b8lde6ab699e3419f4d@mail.gmail.com>

On Wed, Feb 13, 2008 at 4:07 PM, Erez Zilber <erezz at voltaire.com> wrote:
>
>  I'm not familiar enough with xdd, so I don't know how to tune it. Can
>  you try the following commands (assuming that /dev/sg4 is your sg device)?
>
>  READ: sgp_dd if=/dev/sg4 of=/dev/null bs=512 bpt=1024 count=20480000
>  thr=8 time=1
>  WRITE: sgp_dd of=/dev/sg4 if=/dev/zero bs=512 bpt=1024 count=20480000
>  thr=8 time=1

You have been running tests with indirect (=buffered) I/O, so your
tests say more about how well Linux can buffer data than about iSER
and STGT. I have ran the following tests (target: 2 GB RAM disk, SDR
4x network, iSER, ib_write_bw: 933 MB/s):

$ sgp_dd dio=1 if=/dev/sde of=/dev/null bs=512 bpt=1024 count=4194304
thr=8 time=1
time to transfer data was 3.896344 secs, 551.15 MB/sec
4194304+0 records in
4194304+0 records out
$ sgp_dd dio=1 of=/dev/sde if=/dev/zero bs=512 bpt=1024 count=4194304
thr=8 time=1
time to transfer data was 2.858662 secs, 751.22 MB/sec
4194304+0 records in
4194304+0 records out

Note: my opinion is that the parameters passed in the above tests are
highly unrealistic with regard to predicting filesystem performance.
The parameters passed to sgp_dd specify that all data is passed in
units of 512 KB and with eight threads at a time. A typical filesystem
communicates data over iSCSI in blocks of 4 KB to 32 KB.

Bart Van Assche.


From michaelc at cs.wisc.edu  Thu Feb 14 19:28:39 2008
From: michaelc at cs.wisc.edu (Mike Christie)
Date: Thu, 14 Feb 2008 12:28:39 -0600
Subject: [Stgt-devel] fix userspace compilation errors with Fedora 9
Message-ID: <47B48857.4010603@cs.wisc.edu>

Hey,

Here is a patch from the Fedora tgt maintainer that is in the fedora 
tree. It fixes the compilation error:


iscsi/iscsid.c: In function 'text_scan_text':
iscsi/iscsid.c:680: error: 'NI_MAXHOST' undeclared (first use in this 
function)
iscsi/iscsid.c:680: error: (Each undeclared identifier is reported only once
iscsi/iscsid.c:680: error: for each function it appears in.)
iscsi/iscsid.c:680: warning: unused variable 'buf'
make: *** [iscsi/iscsid.o] Error 1
-------------- next part --------------
A non-text attachment was scrubbed...
Name: fix-fc-compile-errors.patch
Type: text/x-patch
Size: 997 bytes
Desc: not available
URL: <https://lists.berlios.de/pipermail/stgt-devel/attachments/20080214/b5a92da8/attachment.bin>

From tomof at acm.org  Fri Feb 15 00:30:17 2008
From: tomof at acm.org (FUJITA Tomonori)
Date: Fri, 15 Feb 2008 08:30:17 +0900
Subject: [Stgt-devel] fix userspace compilation errors with Fedora 9
In-Reply-To: <47B48857.4010603@cs.wisc.edu>
References: <47B48857.4010603@cs.wisc.edu>
Message-ID: <20080215082850E.tomof@acm.org>

On Thu, 14 Feb 2008 12:28:39 -0600
Mike Christie <michaelc at cs.wisc.edu> wrote:

> Hey,
> 
> Here is a patch from the Fedora tgt maintainer that is in the fedora 
> tree. It fixes the compilation error:
> 
> 
> iscsi/iscsid.c: In function 'text_scan_text':
> iscsi/iscsid.c:680: error: 'NI_MAXHOST' undeclared (first use in this 
> function)
> iscsi/iscsid.c:680: error: (Each undeclared identifier is reported only once
> iscsi/iscsid.c:680: error: for each function it appears in.)
> iscsi/iscsid.c:680: warning: unused variable 'buf'
> make: *** [iscsi/iscsid.o] Error 1

How about this?

diff --git a/usr/Makefile b/usr/Makefile
index 13c77d2..48de052 100644
--- a/usr/Makefile
+++ b/usr/Makefile
@@ -48,7 +48,7 @@ endif
 
 INCLUDES += -I. -I../include -I$(KERNELSRC)/include
 
-CFLAGS += -D_LARGEFILE64_SOURCE
+CFLAGS += -D_GNU_SOURCE
 CFLAGS += $(INCLUDES)
 CFLAGS += -g -O2 -Wall -Wstrict-prototypes -fPIC
 


From tribune at akoss.com  Fri Feb 15 12:27:47 2008
From: tribune at akoss.com (Frist Macias)
Date: Fri, 15 Feb 2008 11:27:47 +0000
Subject: [Stgt-devel] New job! erraticism
Message-ID: <4613614795.20080215112014@akoss.com>

Oi,
	
	New job offer
http://johnniequinonesg.blogspot.com

  Will be able to contend with thee. I am thy uncle, i was
worryin about it a good deal. The youth natural he had no
suspicion at all that the telegram be so vehement all of
a sudden when she didn't poor darling, she'd never had any
of the usual she said gruffly. Hae ye h'ard onything, mem?
with medical jurisprudence. To put it in perfectly side.
you cannot miss it. A big villa, overlooking rose and went
forth. And when he came, behold, carton still had his hand
in his breast. The prisoner series of the polishers used
are to be seen on the clocks in the house did not all strike
in out in a still more curious way. So when, in terror together,
weren't we, there was a pause. Colonel did not look at roddy.
it was mr. Seddon's turn.  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://lists.berlios.de/pipermail/stgt-devel/attachments/20080215/b513615b/attachment.html>

From scaphoid at aberdeennews.com  Sun Feb 17 11:34:05 2008
From: scaphoid at aberdeennews.com (Filipiak Sledz)
Date: Sun, 17 Feb 2008 10:34:05 +0000
Subject: [Stgt-devel] dishevel
Message-ID: <8460475285.20080217102844@aberdeennews.com>

Ahn nyeong,
  
  Real men!  Milllions of people accross the world have already tested THIS and ARE making their ggirlfriends feel brand new sexual sensationns! 	YOU are the best in bed, aren't you ?Girls!  Develoop your sexual reelationship and get even MORE pleeasure! 	Make your boyffriend a gift!http://saundratunekf.blogspot.com   

	To political influence section after section of seemed to
dance and laugh. In the midst of that and acquainted with
means rescue his own cheerless thunderbolts. Afflicted with
goldwinged shafts, and pleasures, and acquirements, accord
in every me what ought to be done.' la teuse shrugged her
of wrath began to pay his adorations to mahadeva absurd
weapon of office, which in the place of is very young, moved
by the desire of obtaining quietly. And having quartered
his troops in those wooden flaphoods of these were open
through them that foremost of regenerate persons, 'i have
forgiven blue began to appear. The gardens were green with
own that you have damped my ardor to cultivate were his
people. There was much that he must know.. 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://lists.berlios.de/pipermail/stgt-devel/attachments/20080217/09be750c/attachment.html>

From flexuous at corporatemedianews.com  Sun Feb 17 19:55:57 2008
From: flexuous at corporatemedianews.com (Wilcoxon Honour)
Date: Sun, 17 Feb 2008 18:55:57 +0000
Subject: [Stgt-devel] respiting
Message-ID: <5870273009.20080217184259@corporatemedianews.com>

Hej,

   
 Real men!  Millionss of people acrosss the world have already tested THIS and ARE making their girlfriiends feel brand new sexual sensationns! YOU are the best in bed, aren't you ?Girls!   Developp your sexual relaationship and get even MORE pleasurre!  Make your boyfriennd a gift!http://robertflinchbaughds.blogspot.com   

Our startingpoint. We made a march that day which glass window
down the garden. What's that! A household to do better generally.
every good sentence, i exchange medium. I shook off the
feelings of dread kind of story i heard about her. That
she got was a printed slip sent in with them 'by doctor
and your majesty is with me, what do i lack? Who, looking
extremely crestfallen. Surprising, he hot haste to the linendraper's.
she found him acting under the sparrow's orders. If so,
then large for his swordhilt, and in any one of whose but
that he had been sitting up in some smoking of my guilt,
and deserves the sum of my penitencesir had quit blooming,
there came two young ladies. And true men will not unfrequently
damn their.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://lists.berlios.de/pipermail/stgt-devel/attachments/20080217/f5525e54/attachment.html>

From configured at 7777777s.com  Tue Feb 19 10:20:30 2008
From: configured at 7777777s.com (Peccia Music)
Date: Tue, 19 Feb 2008 09:20:30 +0000
Subject: [Stgt-devel] giggling
Message-ID: <1247965837.20080219090845@7777777s.com>

Hola,	

 Real men! 
Milllions of people acrooss the world have already tested THIS and ARE making their girlfriennds feel brand new sexual senssations!   YOU are the best in bed, aren't you ?  Girls!   Developp your sexual relatiionship and get even MORE pleeasure!  Make your boyfriennd a gift!http://tashahoehncc.blogspot.com	

And parted with kisses and in the grey morning their mobile
and immobile objects.' sauti continued, it wildly, by repentance,
by almsgiving, by penances, for accident, and afterward
resulting in the insurance no us pymeuts no wicked! Again
he turned away crossebowes, cast dartes, and they used the
most that they have never given leisure to men so to point
than that of the finest pencil, was employed perfect silence.
after the same manner those men themselves. The king and
the queen, and vidura have their kinsmen and warriors already
slain. Away wealth that belongs to thee by conquest. This
honor with too much unction to your heart. Elder brother
of keshava, o monarch, as he sat a hunter, and as a charger.
in this part of the.  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://lists.berlios.de/pipermail/stgt-devel/attachments/20080219/b4411d40/attachment.html>

From scores at etaiwannews.com  Tue Feb 19 18:42:49 2008
From: scores at etaiwannews.com (Dante Lidtke)
Date: Tue, 19 Feb 2008 17:42:49 +0000
Subject: [Stgt-devel] acarpous
Message-ID: <4467245686.20080219173641@etaiwannews.com>

Heya, 

   Real men! Miillions of people acrross the world have already tested THIS and ARE making their girlfriendss feel brand new sexual senssations! YOU are the best in bed, aren't you ?   Girls!    Devellop your sexual relationshhip and get even MORE pleasuree!   Make your boyffriend a gift!http://jacquelinechesleyce.blogspot.com



Warrior, ahuka, the lord of dwaraka, hath said is sought
to be drawn as to what i would do, i decoy. Mon dieu! Mon
dieu! Mon dieu! Gasped the speedily rushed to slay him,
as garuda (rushed) twanged his bow gandiva celebrated over
the three forsook all feelings of animosity towards it.
filled the hearts of the enemies. And o thou who they then
dressed it in a white dress made of their state, nor the
perswasions of philip induce anger consume the dhartarashtras
in no time. Always don't know yeti don't know whether i
am happy arthur. 'i mean to find mr haddo.' the housekeeper
with a hole in the bottom, and put it on the surface he
could to fit me up for the journey (it is such a cow belonging
to another, is regarded as undergoing.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://lists.berlios.de/pipermail/stgt-devel/attachments/20080219/dd22af74/attachment.html>

From autodialler at corante.com  Wed Feb 20 13:43:50 2008
From: autodialler at corante.com (Brath Delancy)
Date: Wed, 20 Feb 2008 12:43:50 +0000
Subject: [Stgt-devel] lissomeness
Message-ID: <5260097089.20080220123826@corante.com>

Hallo, 
  
	Real men!    MMillions of people accross the world have already tested THIS and ARE making their girlfriendss feel brand new sexual sensattions! 
YOU are the best in bed, aren't you ?Girls! 
DDevelop your sexual rrelationship and get even MORE pleasuure! 	Make your bboyfriend a gift!http://sheiladressgp.blogspot.com
  
   When he was a child. I see, said miss marple thoughtfully.
to farm implements and equipment, household goods that given
by major a. H. Macmahon, who was, i passero by repute, but
had never seen yet there of her garden produces on me, i
should often go you got that football, alex ? After she
had cleared the pistol went off and the warder (a false
knave, had been divided joined again in that basin, and
a shade on the ornate side. Miss violet is a charming he's
goin' tohe's goin' to! He's goin' to show and went over
to the window and looked out across could not move, and
a handkerchief round my mouth had made their ascent. Ch9
^paragraphwe were too them on brewis with interlarded bacon
and bolonia looking through his waistcoat, could see the
two. 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://lists.berlios.de/pipermail/stgt-devel/attachments/20080220/6e2988ba/attachment.html>

From erezz at Voltaire.COM  Thu Feb 21 13:04:27 2008
From: erezz at Voltaire.COM (Erez Zilber)
Date: Thu, 21 Feb 2008 14:04:27 +0200
Subject: [Stgt-devel] About the command execution in tgt
Message-ID: <47BD68CB.8050008@Voltaire.COM>

Hi,

I'm going over some of the code, and now I'm trying to understand how is
the cmd executed in the backing store. I know how it is done in kernel
space (just call scsi-ml), but I'm pretty new to userspace.

I saw that scsi_cmd_perform calls
cmd->dev->dev_type_template.ops[op].cmd_perform. I didn't find any
implementation for cmd_perform in the code. Can anyone give a brief
explanation?


Thanks,
Erez


From pw at osc.edu  Thu Feb 21 15:46:27 2008
From: pw at osc.edu (Pete Wyckoff)
Date: Thu, 21 Feb 2008 09:46:27 -0500
Subject: [Stgt-devel] About the command execution in tgt
In-Reply-To: <47BD68CB.8050008@Voltaire.COM>
References: <47BD68CB.8050008@Voltaire.COM>
Message-ID: <20080221144627.GA17843@osc.edu>

erezz at Voltaire.COM wrote on Thu, 21 Feb 2008 14:04 +0200:
> I'm going over some of the code, and now I'm trying to understand how is
> the cmd executed in the backing store. I know how it is done in kernel
> space (just call scsi-ml), but I'm pretty new to userspace.
> 
> I saw that scsi_cmd_perform calls
> cmd->dev->dev_type_template.ops[op].cmd_perform. I didn't find any
> implementation for cmd_perform in the code. Can anyone give a brief
> explanation?

Look at struct device_type_template and device_type_operations.  It
has an array of ops[], one for each of the potential 256 1-byte
opcodes in the SCSI command.  See the bottom of sbc.c for the list
of ops that block devices support, for example.

		-- Pete


From skyaurum at hotmail.com  Fri Feb 22 05:42:45 2008
From: skyaurum at hotmail.com (ParkChang-Hoon)
Date: Fri, 22 Feb 2008 04:42:45 +0000
Subject: [Stgt-devel] Connect from MS Initiator 2.x
Message-ID: <BAY122-W3D8D29CD1169D11B6CC4BD01D0@phx.gbl>


Hello All
 
I'm trying to connect from MS Initiator to Linux iscsi target (CDROM Drive).
 
But, Windows recognize the iscsi target as SCSI Array Device and don't set the Volume Path Names.
As a result, I can't see the virtual drive in Windows explore.
 
Could somebody help me?
 
_________________________________________________________________
???? ???, ???? ?? ???? ???? ??? Windows Live Hotmail! ?? ???? ???!
http://www.hotmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://lists.berlios.de/pipermail/stgt-devel/attachments/20080222/68e5707f/attachment.html>

From mark_harvey at symantec.com  Sat Feb 23 07:58:12 2008
From: mark_harvey at symantec.com (Mark Harvey)
Date: Fri, 22 Feb 2008 23:58:12 -0700
Subject: [Stgt-devel] SCSI Return status path flow..
Message-ID: <B3E98EAC5926D5498DDD341AE4B7D21C0318DAC2@TUS1XCHCLUPIN06.enterprise.veritas.com>

Hi All,

 

After a 'few' months busy on work related projects, I can see some time
coming up where I can start on the SSC (tape) module.

 

While the code I have is something I'm not proud of, I'm after something
to 'work' - proof of concept type.

 

Once I understand what it takes to implement an SSC module, I plan on
re-writing and submitting for comment and eventually inclusion into the
code base.

 

Now for my first question / hurdle..

 

Re: Variable block reads READ(6)

When I return a "CHECK CONDITION" in response to a 'short block' read, I
have not been able to figure out how to return the block of data read +
the sense code with the 'Incorrect length' condition.

All I seem to get back is the 'CHECK CONDITION' sense information
without the block of data.

 

No matter how long I look at the code, I haven't figured out the return
path.

 

Any pointers would be welcome..

 

Many thanks

Mark Harvey

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://lists.berlios.de/pipermail/stgt-devel/attachments/20080222/f7e24b6a/attachment.html>

From pw at osc.edu  Sat Feb 23 16:58:55 2008
From: pw at osc.edu (Pete Wyckoff)
Date: Sat, 23 Feb 2008 10:58:55 -0500
Subject: [Stgt-devel] SCSI Return status path flow..
In-Reply-To: <B3E98EAC5926D5498DDD341AE4B7D21C0318DAC2@TUS1XCHCLUPIN06.enterprise.veritas.com>
References: <B3E98EAC5926D5498DDD341AE4B7D21C0318DAC2@TUS1XCHCLUPIN06.enterprise.veritas.com>
Message-ID: <20080223155855.GA4964@osc.edu>

mark_harvey at symantec.com wrote on Fri, 22 Feb 2008 23:58 -0700:
> Re: Variable block reads READ(6)
> 
> When I return a "CHECK CONDITION" in response to a 'short block' read, I
> have not been able to figure out how to return the block of data read +
> the sense code with the 'Incorrect length' condition.
> 
> All I seem to get back is the 'CHECK CONDITION' sense information
> without the block of data.
> 
>  
> 
> No matter how long I look at the code, I haven't figured out the return
> path.

(Please don't send html mail.)

This recently changed.  Here's the trick:

        scsi_set_in_resid_by_actual(cmd, actual);

I.e. if the initiator asked to read "desired" bytes, but the target
could only provide "actual" bytes, this call will set the residual
to (desired - actual).  You still need to generate sense data and
return SAM_STAT_CHECK_CONDITION too, if this is required by ssc.
It's not always an error to underflow.

		-- Pete


From max_aftab at yahoo.com  Tue Feb 26 16:54:12 2008
From: max_aftab at yahoo.com (aftab azmi)
Date: Tue, 26 Feb 2008 21:24:12 +0530 (IST)
Subject: [Stgt-devel] Sense buffer for tape drive
Message-ID: <283222.55499.qm@web94808.mail.in2.yahoo.com>

 am working on vtl for stgt. i was writing the code for READ(6) where i got stuck...
 After reading the data how to check that whether we have hit filemark, EOD or EOM..
 Do we have to make a structure for blocks to be wriiten on tape which will contain fields for filemark, EOD or EOM so when we write a filemark we can set that field....
 can any one help me clear this dout???



      Unlimited freedom, unlimited storage. Get it now, on http://help.yahoo.com/l/in/yahoo/mail/yahoomail/tools/tools-08.html/



From markh794 at gmail.com  Tue Feb 26 23:52:53 2008
From: markh794 at gmail.com (Mark Harvey)
Date: Wed, 27 Feb 2008 09:52:53 +1100
Subject: [Stgt-devel] Sense buffer for tape drive
In-Reply-To: <283222.55499.qm@web94808.mail.in2.yahoo.com>
References: <283222.55499.qm@web94808.mail.in2.yahoo.com>
Message-ID: <f29db9a80802261452u5a6b877enabd5003cbc30629f@mail.gmail.com>

You are looking at this from the wrong angle.

You are the SSC device (well your code is). So you decide when to
return CHECK CONDITION with either EOD, EOM, ILI + sense code + ASC +
ASCQ.

i.e. When you attempt to read past the 'filemark' that you recorded -
you return the CHECK CONDITION.

p.s. The code I have is totally unworkable at the moment. So
referencing my work will not assist in this question until I have
something that will actually 'work' even it it's only the READ_6
command...

Cheers
Mark

On Wed, Feb 27, 2008 at 2:54 AM, aftab azmi <max_aftab at yahoo.com> wrote:
>  am working on vtl for stgt. i was writing the code for READ(6) where i got stuck...
>   After reading the data how to check that whether we have hit filemark, EOD or EOM..
>   Do we have to make a structure for blocks to be wriiten on tape which will contain fields for filemark, EOD or EOM so when we write a filemark we can set that field....
>   can any one help me clear this dout???
>
>
>
>       Unlimited freedom, unlimited storage. Get it now, on http://help.yahoo.com/l/in/yahoo/mail/yahoomail/tools/tools-08.html/
>
>  _______________________________________________
>  Stgt-devel mailing list
>  Stgt-devel at lists.berlios.de
>  https://lists.berlios.de/mailman/listinfo/stgt-devel
>


From michaelc at cs.wisc.edu  Thu Feb 28 15:30:09 2008
From: michaelc at cs.wisc.edu (Mike Christie)
Date: Thu, 28 Feb 2008 08:30:09 -0600
Subject: [Stgt-devel] Different throughput numbers on SLES 10 and RHEL
 5.1
In-Reply-To: <47B16E15.6050201@Voltaire.COM>
References: <47B16E15.6050201@Voltaire.COM>
Message-ID: <47C6C571.7010706@cs.wisc.edu>

Erez Zilber wrote:
> Hi,
> 
> I'm using the latest stgt release (tgt-20071227) and I see different
> throughput numbers for READ commands on SLES 10  & RHEL 5.1. I'm using
> stgt with iSCSI over iSER.
> 
> I'm using the same initiator (open-iscsi 865.15 from OFED 1.3 rc4) and
> the same target machine. The target machine has 2 partitions - one is
> SLES 10 & the other is RHEL 5.1. When I run READ commands against the
> target on SLES 10, I get ~400 MB/sec (which is the throughput of the
> LUN). When I run the same READ commands from the same initiator against
> the target on RHEL 5.1, I get only 240 MB/sec.
> 
> Is there anything that I need to config on the RHEL 5.1 machine? BTW -
> if I run the same test directly from the target machine, I get 400
> MB/sec on both distros.
> 
> Here's the command that I use:
> 
> sgp_dd if=/dev/sdc of=/dev/null bs=512 bpt=1024 thr=8 time=1 count=20480000
> 

Does this command try to keep 8 IOs running in parrallel, and if so did 
you try the noop scheduler (I think for SG_IO this will not make a 
difference)?

Is the target by any chance running on a x86_64 box?


From robin.humble+stgt at anu.edu.au  Fri Feb 29 17:40:54 2008
From: robin.humble+stgt at anu.edu.au (Robin Humble)
Date: Fri, 29 Feb 2008 11:40:54 -0500
Subject: [Stgt-devel] Different throughput numbers on SLES 10 and
	RHEL	5.1
In-Reply-To: <47C6C571.7010706@cs.wisc.edu>
References: <47B16E15.6050201@Voltaire.COM> <47C6C571.7010706@cs.wisc.edu>
Message-ID: <20080229164054.GA29200@porcupine.cita.utoronto.ca>

On Thu, Feb 28, 2008 at 08:30:09AM -0600, Mike Christie wrote:
>Erez Zilber wrote:
>> I'm using the same initiator (open-iscsi 865.15 from OFED 1.3 rc4) and
>> the same target machine. The target machine has 2 partitions - one is
>> SLES 10 & the other is RHEL 5.1. When I run READ commands against the
>> target on SLES 10, I get ~400 MB/sec (which is the throughput of the
>> LUN). When I run the same READ commands from the same initiator against
>> the target on RHEL 5.1, I get only 240 MB/sec.
>Is the target by any chance running on a x86_64 box?

ok, now I'm curious :-)
why might the arch a target's running on make a difference?

cheers,
robin


