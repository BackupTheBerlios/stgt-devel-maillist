From fujita.tomonori at lab.ntt.co.jp  Tue Aug  1 04:37:03 2006
From: fujita.tomonori at lab.ntt.co.jp (FUJITA Tomonori)
Date: Tue, 01 Aug 2006 11:37:03 +0900
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <1154379923.8544.4.camel@trinity.ogc.int>
References: <1154379923.8544.4.camel@trinity.ogc.int>
Message-ID: <20060801113703H.fujita.tomonori@lab.ntt.co.jp>

From: Tom Tucker <tom at opengridcomputing.com>
Subject: [Stgt-devel] User-mode iSER
Date: Mon, 31 Jul 2006 16:05:23 -0500

> Tomo:
> 
> I heard a rumor that moving even more of the iSER target design into
> user mode was considered at the OLS. I think this is a very interesting
> idea and would like to know what you and others think of this in general
> and if there are any specific issues that people think make this
> difficult.

Yeah, we thought about that.

It's still not clear that tgt iSCSI target driver (*1) is accepted to
mainline. We can use lots of parts of open-iscsi code for it, however,
you can say that iSCSI target software can be implemented in user
space.

Mike said that returning from vacation, he clean up and submit the
iSCSI target driver to scsi-ml for discussion.

If we fail to put it into mainline, I'll implement iscsi target
software in user space, which uses tgt user-space code (SCSI
processing, management, etc). So, is it possible that we integrate
iSER into user-space iSCSI target software?


*1) the iSCSI (tcp) target driver for tgt (which partially works)

svn+ssh://svn.berlios.de/svnroot/repos/stgt/trunk/istgt


From tom at opengridcomputing.com  Tue Aug  1 15:09:13 2006
From: tom at opengridcomputing.com (Tom Tucker)
Date: Tue, 01 Aug 2006 08:09:13 -0500
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <20060801113703H.fujita.tomonori@lab.ntt.co.jp>
References: <1154379923.8544.4.camel@trinity.ogc.int>
	<20060801113703H.fujita.tomonori@lab.ntt.co.jp>
Message-ID: <1154437753.31727.5.camel@trinity.ogc.int>

On Tue, 2006-08-01 at 11:37 +0900, FUJITA Tomonori wrote:
> From: Tom Tucker <tom at opengridcomputing.com>
> Subject: [Stgt-devel] User-mode iSER
> Date: Mon, 31 Jul 2006 16:05:23 -0500
> 
> > Tomo:
> > 
> > I heard a rumor that moving even more of the iSER target design into
> > user mode was considered at the OLS. I think this is a very interesting
> > idea and would like to know what you and others think of this in general
> > and if there are any specific issues that people think make this
> > difficult.
> 
> Yeah, we thought about that.
> 
> It's still not clear that tgt iSCSI target driver (*1) is accepted to
> mainline. We can use lots of parts of open-iscsi code for it, however,
> you can say that iSCSI target software can be implemented in user
> space.

Also, won't a user-mode approach support virtual target devices more
easily? 

> 
> Mike said that returning from vacation, he clean up and submit the
> iSCSI target driver to scsi-ml for discussion.

Do you know When does he gets back?

> 
> If we fail to put it into mainline, I'll implement iscsi target
> software in user space, which uses tgt user-space code (SCSI
> processing, management, etc). So, is it possible that we integrate
> iSER into user-space iSCSI target software?

Yes it is possible to use iSER as a user-mode transport. In fact, iSER
supports kernel-bypass, so there is no additional overhead vs. i/o in
the kernel. 


> 
> *1) the iSCSI (tcp) target driver for tgt (which partially works)
> 
> svn+ssh://svn.berlios.de/svnroot/repos/stgt/trunk/istgt
> _______________________________________________
> Stgt-devel mailing list
> Stgt-devel at lists.berlios.de
> http://bat.berlios.de/mailman/listinfo/stgt-devel



From tom at opengridcomputing.com  Tue Aug  1 20:42:44 2006
From: tom at opengridcomputing.com (Tom Tucker)
Date: Tue, 01 Aug 2006 13:42:44 -0500
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <20060801113703H.fujita.tomonori@lab.ntt.co.jp>
References: <1154379923.8544.4.camel@trinity.ogc.int>
	<20060801113703H.fujita.tomonori@lab.ntt.co.jp>
Message-ID: <1154457764.9903.24.camel@trinity.ogc.int>

What do people think about something like this...

The target architecture is implemented to the extent possible entirely
in user-mode. The architecture intends to support multiple Target Device
Types, SCSI Transport Types and Network Transport Types. The enclosed
figure below illustrates the components of the architecture.

At the top of the figure are the different Target Device Type Drivers.
These "drivers" are implemented in user-mode as libraries and plug into
the Target Interface Layer. The Target Device Type drivers each support
a particular class of device. For example, the SCSI Disk Driver supports
SCSI disks, the Block Device driver supports generic block devices
(e.g. /dev/md0, etc..) and the File Device Driver supports files as
target devices. In most cases, the Target Device Type Drivers call
existing system call interfaces to communicate with the actual target
device, e.g. open, close, read, write, ioctl, etc... High performance
implementations may use private kernel interfaces to improve
performance. 

The Target Interface Layer implements a generic target device
independent API called the Target Device API, and a SCSI transport
independent API called the SCSI Transport API. This Target Interface
Layer implements a target/SCSI transport switch that allows any Target
Device Type to be associated with any SCSI Transport Type. 

The SCSI Transport Class Drivers implement support for the various SCSI
transport types: SRP Transport implements the SCSI RDMA Protocol
transport, FCP Transport implements the Fiber Channel transport type,
and the iSCSI Transport implements the iSCSI transport type. These
drivers sit between the Target Interface Layer and the Network Interface
Layer. 

The Network Interface Layer implements a SCSI transport independent API
called the Transport Class API and a network transport independent API
called the Transport API. The Network Interface Layer allows a SCSI
Transport Class driver to support multiple network transports. For
example, the iSCSI Transport driver will support TCP, IB, and iWARP as
network transports. The details of a particular SCSI Transport Class's
device enumeration, login and management are implemented in the SCSI
Transport Class driver (e.g. iSCSI Transport). The details of a
particular network transport's connection management paradigm are
implemented in the Transport Provider driver (e.g. RDMA driver).

The Transport Provider Drivers implement the Transport Provider API and
provide core network I/O services to the Network Interface Layer. The
Transport API is a transport independent interface for creating
endpoints, service points, accepting incoming connection requests and
performing I/O on an endpoint.

The Management Agent interfaces with the Target Interface Layer and
performs management functions such as creating targets, devices, loading
and storing persistent configurations and other management related
functions.

The various API referred to above are basically simplified versions of
the existing scsi_transport_template, scsi_host, scsi_host_template
interfaces, etc... from the current kernel implementation. The
interfaces between the various components, however, can be reduced to
function calls since everything resides user mode. 

I think the only tough issue here is with copy avoidance for the network
user/kernel interface and target device user/kernel interfaces.
Initially, these could be prototyped without regard to this issue and
see what kind of performance we could get. The RDMA network transports
already provide copy avoidance, however, TCP/FC would require some
cleverness.

Thoughts?

-------------- next part --------------
A non-text attachment was scrubbed...
Name: user-target.pdf
Type: application/pdf
Size: 23541 bytes
Desc: not available
URL: <https://lists.berlios.de/pipermail/stgt-devel/attachments/20060801/188f7dc4/attachment.pdf>

From mingz at ele.uri.edu  Tue Aug  1 20:49:36 2006
From: mingz at ele.uri.edu (Ming Zhang)
Date: Tue, 01 Aug 2006 14:49:36 -0400
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <1154457764.9903.24.camel@trinity.ogc.int>
References: <1154379923.8544.4.camel@trinity.ogc.int>
	<20060801113703H.fujita.tomonori@lab.ntt.co.jp>
	<1154457764.9903.24.camel@trinity.ogc.int>
Message-ID: <1154458176.2829.57.camel@localhost.localdomain>

my 2c. u figure ignores other device types like VT/VTL or bridge. your
target device type are only TYPE_DISK here. also scsi/block/file just
physical media used by TYPE_DISK.

Ming


On Tue, 2006-08-01 at 13:42 -0500, Tom Tucker wrote:
> What do people think about something like this...
> 
> The target architecture is implemented to the extent possible entirely
> in user-mode. The architecture intends to support multiple Target Device
> Types, SCSI Transport Types and Network Transport Types. The enclosed
> figure below illustrates the components of the architecture.
> 
> At the top of the figure are the different Target Device Type Drivers.
> These "drivers" are implemented in user-mode as libraries and plug into
> the Target Interface Layer. The Target Device Type drivers each support
> a particular class of device. For example, the SCSI Disk Driver supports
> SCSI disks, the Block Device driver supports generic block devices
> (e.g. /dev/md0, etc..) and the File Device Driver supports files as
> target devices. In most cases, the Target Device Type Drivers call
> existing system call interfaces to communicate with the actual target
> device, e.g. open, close, read, write, ioctl, etc... High performance
> implementations may use private kernel interfaces to improve
> performance. 
> 
> The Target Interface Layer implements a generic target device
> independent API called the Target Device API, and a SCSI transport
> independent API called the SCSI Transport API. This Target Interface
> Layer implements a target/SCSI transport switch that allows any Target
> Device Type to be associated with any SCSI Transport Type. 
> 
> The SCSI Transport Class Drivers implement support for the various SCSI
> transport types: SRP Transport implements the SCSI RDMA Protocol
> transport, FCP Transport implements the Fiber Channel transport type,
> and the iSCSI Transport implements the iSCSI transport type. These
> drivers sit between the Target Interface Layer and the Network Interface
> Layer. 
> 
> The Network Interface Layer implements a SCSI transport independent API
> called the Transport Class API and a network transport independent API
> called the Transport API. The Network Interface Layer allows a SCSI
> Transport Class driver to support multiple network transports. For
> example, the iSCSI Transport driver will support TCP, IB, and iWARP as
> network transports. The details of a particular SCSI Transport Class's
> device enumeration, login and management are implemented in the SCSI
> Transport Class driver (e.g. iSCSI Transport). The details of a
> particular network transport's connection management paradigm are
> implemented in the Transport Provider driver (e.g. RDMA driver).
> 
> The Transport Provider Drivers implement the Transport Provider API and
> provide core network I/O services to the Network Interface Layer. The
> Transport API is a transport independent interface for creating
> endpoints, service points, accepting incoming connection requests and
> performing I/O on an endpoint.
> 
> The Management Agent interfaces with the Target Interface Layer and
> performs management functions such as creating targets, devices, loading
> and storing persistent configurations and other management related
> functions.
> 
> The various API referred to above are basically simplified versions of
> the existing scsi_transport_template, scsi_host, scsi_host_template
> interfaces, etc... from the current kernel implementation. The
> interfaces between the various components, however, can be reduced to
> function calls since everything resides user mode. 
> 
> I think the only tough issue here is with copy avoidance for the network
> user/kernel interface and target device user/kernel interfaces.
> Initially, these could be prototyped without regard to this issue and
> see what kind of performance we could get. The RDMA network transports
> already provide copy avoidance, however, TCP/FC would require some
> cleverness.
> 
> Thoughts?
> 
> _______________________________________________
> Stgt-devel mailing list
> Stgt-devel at lists.berlios.de
> http://bat.berlios.de/mailman/listinfo/stgt-devel



From tom at opengridcomputing.com  Tue Aug  1 21:00:56 2006
From: tom at opengridcomputing.com (Tom Tucker)
Date: Tue, 01 Aug 2006 14:00:56 -0500
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <1154458176.2829.57.camel@localhost.localdomain>
References: <1154379923.8544.4.camel@trinity.ogc.int>
	<20060801113703H.fujita.tomonori@lab.ntt.co.jp>
	<1154457764.9903.24.camel@trinity.ogc.int>
	<1154458176.2829.57.camel@localhost.localdomain>
Message-ID: <1154458856.9903.27.camel@trinity.ogc.int>

On Tue, 2006-08-01 at 14:49 -0400, Ming Zhang wrote:
> my 2c. u figure ignores other device types like VT/VTL or bridge. your
> target device type are only TYPE_DISK here.

Yeah, I should put in ellipses... These types are not precluded.

>  also scsi/block/file just
> physical media used by TYPE_DISK.

Yes, but there seemed to be some interest in exporting a file as a SCSI
Target, or even anonymously mapped memory...

What else should we be thinking about?

> 
> Ming
> 
> 
> On Tue, 2006-08-01 at 13:42 -0500, Tom Tucker wrote:
> > What do people think about something like this...
> > 
> > The target architecture is implemented to the extent possible entirely
> > in user-mode. The architecture intends to support multiple Target Device
> > Types, SCSI Transport Types and Network Transport Types. The enclosed
> > figure below illustrates the components of the architecture.
> > 
> > At the top of the figure are the different Target Device Type Drivers.
> > These "drivers" are implemented in user-mode as libraries and plug into
> > the Target Interface Layer. The Target Device Type drivers each support
> > a particular class of device. For example, the SCSI Disk Driver supports
> > SCSI disks, the Block Device driver supports generic block devices
> > (e.g. /dev/md0, etc..) and the File Device Driver supports files as
> > target devices. In most cases, the Target Device Type Drivers call
> > existing system call interfaces to communicate with the actual target
> > device, e.g. open, close, read, write, ioctl, etc... High performance
> > implementations may use private kernel interfaces to improve
> > performance. 
> > 
> > The Target Interface Layer implements a generic target device
> > independent API called the Target Device API, and a SCSI transport
> > independent API called the SCSI Transport API. This Target Interface
> > Layer implements a target/SCSI transport switch that allows any Target
> > Device Type to be associated with any SCSI Transport Type. 
> > 
> > The SCSI Transport Class Drivers implement support for the various SCSI
> > transport types: SRP Transport implements the SCSI RDMA Protocol
> > transport, FCP Transport implements the Fiber Channel transport type,
> > and the iSCSI Transport implements the iSCSI transport type. These
> > drivers sit between the Target Interface Layer and the Network Interface
> > Layer. 
> > 
> > The Network Interface Layer implements a SCSI transport independent API
> > called the Transport Class API and a network transport independent API
> > called the Transport API. The Network Interface Layer allows a SCSI
> > Transport Class driver to support multiple network transports. For
> > example, the iSCSI Transport driver will support TCP, IB, and iWARP as
> > network transports. The details of a particular SCSI Transport Class's
> > device enumeration, login and management are implemented in the SCSI
> > Transport Class driver (e.g. iSCSI Transport). The details of a
> > particular network transport's connection management paradigm are
> > implemented in the Transport Provider driver (e.g. RDMA driver).
> > 
> > The Transport Provider Drivers implement the Transport Provider API and
> > provide core network I/O services to the Network Interface Layer. The
> > Transport API is a transport independent interface for creating
> > endpoints, service points, accepting incoming connection requests and
> > performing I/O on an endpoint.
> > 
> > The Management Agent interfaces with the Target Interface Layer and
> > performs management functions such as creating targets, devices, loading
> > and storing persistent configurations and other management related
> > functions.
> > 
> > The various API referred to above are basically simplified versions of
> > the existing scsi_transport_template, scsi_host, scsi_host_template
> > interfaces, etc... from the current kernel implementation. The
> > interfaces between the various components, however, can be reduced to
> > function calls since everything resides user mode. 
> > 
> > I think the only tough issue here is with copy avoidance for the network
> > user/kernel interface and target device user/kernel interfaces.
> > Initially, these could be prototyped without regard to this issue and
> > see what kind of performance we could get. The RDMA network transports
> > already provide copy avoidance, however, TCP/FC would require some
> > cleverness.
> > 
> > Thoughts?
> > 
> > _______________________________________________
> > Stgt-devel mailing list
> > Stgt-devel at lists.berlios.de
> > http://bat.berlios.de/mailman/listinfo/stgt-devel
> 
> _______________________________________________
> Stgt-devel mailing list
> Stgt-devel at lists.berlios.de
> http://bat.berlios.de/mailman/listinfo/stgt-devel



From mingz at ele.uri.edu  Tue Aug  1 21:56:20 2006
From: mingz at ele.uri.edu (Ming Zhang)
Date: Tue, 01 Aug 2006 15:56:20 -0400
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <1154458856.9903.27.camel@trinity.ogc.int>
References: <1154379923.8544.4.camel@trinity.ogc.int>
	<20060801113703H.fujita.tomonori@lab.ntt.co.jp>
	<1154457764.9903.24.camel@trinity.ogc.int>
	<1154458176.2829.57.camel@localhost.localdomain>
	<1154458856.9903.27.camel@trinity.ogc.int>
Message-ID: <1154462180.2829.59.camel@localhost.localdomain>

On Tue, 2006-08-01 at 14:00 -0500, Tom Tucker wrote:
> On Tue, 2006-08-01 at 14:49 -0400, Ming Zhang wrote:
> > my 2c. u figure ignores other device types like VT/VTL or bridge. your
> > target device type are only TYPE_DISK here.
> 
> Yeah, I should put in ellipses... These types are not precluded.
> 
> >  also scsi/block/file just
> > physical media used by TYPE_DISK.
> 
> Yes, but there seemed to be some interest in exporting a file as a SCSI
> Target, or even anonymously mapped memory...
> 
> What else should we be thinking about?

what about the AoE? maybe people want AoE target as well. or AoE will
not be considered because of its non-SCSI nature?




> 
> > 
> > Ming
> > 
> > 
> > On Tue, 2006-08-01 at 13:42 -0500, Tom Tucker wrote:
> > > What do people think about something like this...
> > > 
> > > The target architecture is implemented to the extent possible entirely
> > > in user-mode. The architecture intends to support multiple Target Device
> > > Types, SCSI Transport Types and Network Transport Types. The enclosed
> > > figure below illustrates the components of the architecture.
> > > 
> > > At the top of the figure are the different Target Device Type Drivers.
> > > These "drivers" are implemented in user-mode as libraries and plug into
> > > the Target Interface Layer. The Target Device Type drivers each support
> > > a particular class of device. For example, the SCSI Disk Driver supports
> > > SCSI disks, the Block Device driver supports generic block devices
> > > (e.g. /dev/md0, etc..) and the File Device Driver supports files as
> > > target devices. In most cases, the Target Device Type Drivers call
> > > existing system call interfaces to communicate with the actual target
> > > device, e.g. open, close, read, write, ioctl, etc... High performance
> > > implementations may use private kernel interfaces to improve
> > > performance. 
> > > 
> > > The Target Interface Layer implements a generic target device
> > > independent API called the Target Device API, and a SCSI transport
> > > independent API called the SCSI Transport API. This Target Interface
> > > Layer implements a target/SCSI transport switch that allows any Target
> > > Device Type to be associated with any SCSI Transport Type. 
> > > 
> > > The SCSI Transport Class Drivers implement support for the various SCSI
> > > transport types: SRP Transport implements the SCSI RDMA Protocol
> > > transport, FCP Transport implements the Fiber Channel transport type,
> > > and the iSCSI Transport implements the iSCSI transport type. These
> > > drivers sit between the Target Interface Layer and the Network Interface
> > > Layer. 
> > > 
> > > The Network Interface Layer implements a SCSI transport independent API
> > > called the Transport Class API and a network transport independent API
> > > called the Transport API. The Network Interface Layer allows a SCSI
> > > Transport Class driver to support multiple network transports. For
> > > example, the iSCSI Transport driver will support TCP, IB, and iWARP as
> > > network transports. The details of a particular SCSI Transport Class's
> > > device enumeration, login and management are implemented in the SCSI
> > > Transport Class driver (e.g. iSCSI Transport). The details of a
> > > particular network transport's connection management paradigm are
> > > implemented in the Transport Provider driver (e.g. RDMA driver).
> > > 
> > > The Transport Provider Drivers implement the Transport Provider API and
> > > provide core network I/O services to the Network Interface Layer. The
> > > Transport API is a transport independent interface for creating
> > > endpoints, service points, accepting incoming connection requests and
> > > performing I/O on an endpoint.
> > > 
> > > The Management Agent interfaces with the Target Interface Layer and
> > > performs management functions such as creating targets, devices, loading
> > > and storing persistent configurations and other management related
> > > functions.
> > > 
> > > The various API referred to above are basically simplified versions of
> > > the existing scsi_transport_template, scsi_host, scsi_host_template
> > > interfaces, etc... from the current kernel implementation. The
> > > interfaces between the various components, however, can be reduced to
> > > function calls since everything resides user mode. 
> > > 
> > > I think the only tough issue here is with copy avoidance for the network
> > > user/kernel interface and target device user/kernel interfaces.
> > > Initially, these could be prototyped without regard to this issue and
> > > see what kind of performance we could get. The RDMA network transports
> > > already provide copy avoidance, however, TCP/FC would require some
> > > cleverness.
> > > 
> > > Thoughts?
> > > 
> > > _______________________________________________
> > > Stgt-devel mailing list
> > > Stgt-devel at lists.berlios.de
> > > http://bat.berlios.de/mailman/listinfo/stgt-devel
> > 
> > _______________________________________________
> > Stgt-devel mailing list
> > Stgt-devel at lists.berlios.de
> > http://bat.berlios.de/mailman/listinfo/stgt-devel
> 
> _______________________________________________
> Stgt-devel mailing list
> Stgt-devel at lists.berlios.de
> http://bat.berlios.de/mailman/listinfo/stgt-devel



From tom at opengridcomputing.com  Tue Aug  1 22:10:43 2006
From: tom at opengridcomputing.com (Tom Tucker)
Date: Tue, 01 Aug 2006 15:10:43 -0500
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <1154462180.2829.59.camel@localhost.localdomain>
References: <1154379923.8544.4.camel@trinity.ogc.int>
	<20060801113703H.fujita.tomonori@lab.ntt.co.jp>
	<1154457764.9903.24.camel@trinity.ogc.int>
	<1154458176.2829.57.camel@localhost.localdomain>
	<1154458856.9903.27.camel@trinity.ogc.int>
	<1154462180.2829.59.camel@localhost.localdomain>
Message-ID: <1154463043.9903.40.camel@trinity.ogc.int>

On Tue, 2006-08-01 at 15:56 -0400, Ming Zhang wrote:
> On Tue, 2006-08-01 at 14:00 -0500, Tom Tucker wrote:
> > On Tue, 2006-08-01 at 14:49 -0400, Ming Zhang wrote:
> > > my 2c. u figure ignores other device types like VT/VTL or bridge. your
> > > target device type are only TYPE_DISK here.
> > 
> > Yeah, I should put in ellipses... These types are not precluded.
> > 
> > >  also scsi/block/file just
> > > physical media used by TYPE_DISK.
> > 
> > Yes, but there seemed to be some interest in exporting a file as a SCSI
> > Target, or even anonymously mapped memory...
> > 
> > What else should we be thinking about?
> 
> what about the AoE? maybe people want AoE target as well. or AoE will
> not be considered because of its non-SCSI nature?

I thought about that, but the existing arch. didn't support it and
didn't know if others thought it was desirable. We would need another
abstraction layer for ATA vs. SCSI. 

Do others think this is necessary/desirable?

> 
> 
> 
> > 
> > > 
> > > Ming
> > > 
> > > 
> > > On Tue, 2006-08-01 at 13:42 -0500, Tom Tucker wrote:
> > > > What do people think about something like this...
> > > > 
> > > > The target architecture is implemented to the extent possible entirely
> > > > in user-mode. The architecture intends to support multiple Target Device
> > > > Types, SCSI Transport Types and Network Transport Types. The enclosed
> > > > figure below illustrates the components of the architecture.
> > > > 
> > > > At the top of the figure are the different Target Device Type Drivers.
> > > > These "drivers" are implemented in user-mode as libraries and plug into
> > > > the Target Interface Layer. The Target Device Type drivers each support
> > > > a particular class of device. For example, the SCSI Disk Driver supports
> > > > SCSI disks, the Block Device driver supports generic block devices
> > > > (e.g. /dev/md0, etc..) and the File Device Driver supports files as
> > > > target devices. In most cases, the Target Device Type Drivers call
> > > > existing system call interfaces to communicate with the actual target
> > > > device, e.g. open, close, read, write, ioctl, etc... High performance
> > > > implementations may use private kernel interfaces to improve
> > > > performance. 
> > > > 
> > > > The Target Interface Layer implements a generic target device
> > > > independent API called the Target Device API, and a SCSI transport
> > > > independent API called the SCSI Transport API. This Target Interface
> > > > Layer implements a target/SCSI transport switch that allows any Target
> > > > Device Type to be associated with any SCSI Transport Type. 
> > > > 
> > > > The SCSI Transport Class Drivers implement support for the various SCSI
> > > > transport types: SRP Transport implements the SCSI RDMA Protocol
> > > > transport, FCP Transport implements the Fiber Channel transport type,
> > > > and the iSCSI Transport implements the iSCSI transport type. These
> > > > drivers sit between the Target Interface Layer and the Network Interface
> > > > Layer. 
> > > > 
> > > > The Network Interface Layer implements a SCSI transport independent API
> > > > called the Transport Class API and a network transport independent API
> > > > called the Transport API. The Network Interface Layer allows a SCSI
> > > > Transport Class driver to support multiple network transports. For
> > > > example, the iSCSI Transport driver will support TCP, IB, and iWARP as
> > > > network transports. The details of a particular SCSI Transport Class's
> > > > device enumeration, login and management are implemented in the SCSI
> > > > Transport Class driver (e.g. iSCSI Transport). The details of a
> > > > particular network transport's connection management paradigm are
> > > > implemented in the Transport Provider driver (e.g. RDMA driver).
> > > > 
> > > > The Transport Provider Drivers implement the Transport Provider API and
> > > > provide core network I/O services to the Network Interface Layer. The
> > > > Transport API is a transport independent interface for creating
> > > > endpoints, service points, accepting incoming connection requests and
> > > > performing I/O on an endpoint.
> > > > 
> > > > The Management Agent interfaces with the Target Interface Layer and
> > > > performs management functions such as creating targets, devices, loading
> > > > and storing persistent configurations and other management related
> > > > functions.
> > > > 
> > > > The various API referred to above are basically simplified versions of
> > > > the existing scsi_transport_template, scsi_host, scsi_host_template
> > > > interfaces, etc... from the current kernel implementation. The
> > > > interfaces between the various components, however, can be reduced to
> > > > function calls since everything resides user mode. 
> > > > 
> > > > I think the only tough issue here is with copy avoidance for the network
> > > > user/kernel interface and target device user/kernel interfaces.
> > > > Initially, these could be prototyped without regard to this issue and
> > > > see what kind of performance we could get. The RDMA network transports
> > > > already provide copy avoidance, however, TCP/FC would require some
> > > > cleverness.
> > > > 
> > > > Thoughts?
> > > > 
> > > > _______________________________________________
> > > > Stgt-devel mailing list
> > > > Stgt-devel at lists.berlios.de
> > > > http://bat.berlios.de/mailman/listinfo/stgt-devel
> > > 
> > > _______________________________________________
> > > Stgt-devel mailing list
> > > Stgt-devel at lists.berlios.de
> > > http://bat.berlios.de/mailman/listinfo/stgt-devel
> > 
> > _______________________________________________
> > Stgt-devel mailing list
> > Stgt-devel at lists.berlios.de
> > http://bat.berlios.de/mailman/listinfo/stgt-devel
> 



From mingz at ele.uri.edu  Tue Aug  1 22:21:11 2006
From: mingz at ele.uri.edu (Ming Zhang)
Date: Tue, 01 Aug 2006 16:21:11 -0400
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <1154458856.9903.27.camel@trinity.ogc.int>
References: <1154379923.8544.4.camel@trinity.ogc.int>
	<20060801113703H.fujita.tomonori@lab.ntt.co.jp>
	<1154457764.9903.24.camel@trinity.ogc.int>
	<1154458176.2829.57.camel@localhost.localdomain>
	<1154458856.9903.27.camel@trinity.ogc.int>
Message-ID: <1154463671.2829.63.camel@localhost.localdomain>

On Tue, 2006-08-01 at 14:00 -0500, Tom Tucker wrote:
> On Tue, 2006-08-01 at 14:49 -0400, Ming Zhang wrote:
> > my 2c. u figure ignores other device types like VT/VTL or bridge. your
> > target device type are only TYPE_DISK here.
> 
> Yeah, I should put in ellipses... These types are not precluded.
> 
> >  also scsi/block/file just
> > physical media used by TYPE_DISK.
> 
> Yes, but there seemed to be some interest in exporting a file as a SCSI
> Target, or even anonymously mapped memory...
> 
> What else should we be thinking about?

SPI is not mentioned in your pic.

and it will be better if kernel/user space line is marked. so people
know your intention and can comment in that if need. otherwise, i saw no
difference from stgt or scst.

also license. :P what license(s) will be used and allowed for each part.

ming



> 
> > 
> > Ming
> > 
> > 
> > On Tue, 2006-08-01 at 13:42 -0500, Tom Tucker wrote:
> > > What do people think about something like this...
> > > 
> > > The target architecture is implemented to the extent possible entirely
> > > in user-mode. The architecture intends to support multiple Target Device
> > > Types, SCSI Transport Types and Network Transport Types. The enclosed
> > > figure below illustrates the components of the architecture.
> > > 
> > > At the top of the figure are the different Target Device Type Drivers.
> > > These "drivers" are implemented in user-mode as libraries and plug into
> > > the Target Interface Layer. The Target Device Type drivers each support
> > > a particular class of device. For example, the SCSI Disk Driver supports
> > > SCSI disks, the Block Device driver supports generic block devices
> > > (e.g. /dev/md0, etc..) and the File Device Driver supports files as
> > > target devices. In most cases, the Target Device Type Drivers call
> > > existing system call interfaces to communicate with the actual target
> > > device, e.g. open, close, read, write, ioctl, etc... High performance
> > > implementations may use private kernel interfaces to improve
> > > performance. 
> > > 
> > > The Target Interface Layer implements a generic target device
> > > independent API called the Target Device API, and a SCSI transport
> > > independent API called the SCSI Transport API. This Target Interface
> > > Layer implements a target/SCSI transport switch that allows any Target
> > > Device Type to be associated with any SCSI Transport Type. 
> > > 
> > > The SCSI Transport Class Drivers implement support for the various SCSI
> > > transport types: SRP Transport implements the SCSI RDMA Protocol
> > > transport, FCP Transport implements the Fiber Channel transport type,
> > > and the iSCSI Transport implements the iSCSI transport type. These
> > > drivers sit between the Target Interface Layer and the Network Interface
> > > Layer. 
> > > 
> > > The Network Interface Layer implements a SCSI transport independent API
> > > called the Transport Class API and a network transport independent API
> > > called the Transport API. The Network Interface Layer allows a SCSI
> > > Transport Class driver to support multiple network transports. For
> > > example, the iSCSI Transport driver will support TCP, IB, and iWARP as
> > > network transports. The details of a particular SCSI Transport Class's
> > > device enumeration, login and management are implemented in the SCSI
> > > Transport Class driver (e.g. iSCSI Transport). The details of a
> > > particular network transport's connection management paradigm are
> > > implemented in the Transport Provider driver (e.g. RDMA driver).
> > > 
> > > The Transport Provider Drivers implement the Transport Provider API and
> > > provide core network I/O services to the Network Interface Layer. The
> > > Transport API is a transport independent interface for creating
> > > endpoints, service points, accepting incoming connection requests and
> > > performing I/O on an endpoint.
> > > 
> > > The Management Agent interfaces with the Target Interface Layer and
> > > performs management functions such as creating targets, devices, loading
> > > and storing persistent configurations and other management related
> > > functions.
> > > 
> > > The various API referred to above are basically simplified versions of
> > > the existing scsi_transport_template, scsi_host, scsi_host_template
> > > interfaces, etc... from the current kernel implementation. The
> > > interfaces between the various components, however, can be reduced to
> > > function calls since everything resides user mode. 
> > > 
> > > I think the only tough issue here is with copy avoidance for the network
> > > user/kernel interface and target device user/kernel interfaces.
> > > Initially, these could be prototyped without regard to this issue and
> > > see what kind of performance we could get. The RDMA network transports
> > > already provide copy avoidance, however, TCP/FC would require some
> > > cleverness.
> > > 
> > > Thoughts?
> > > 
> > > _______________________________________________
> > > Stgt-devel mailing list
> > > Stgt-devel at lists.berlios.de
> > > http://bat.berlios.de/mailman/listinfo/stgt-devel
> > 
> > _______________________________________________
> > Stgt-devel mailing list
> > Stgt-devel at lists.berlios.de
> > http://bat.berlios.de/mailman/listinfo/stgt-devel
> 
> _______________________________________________
> Stgt-devel mailing list
> Stgt-devel at lists.berlios.de
> http://bat.berlios.de/mailman/listinfo/stgt-devel



From tom at opengridcomputing.com  Tue Aug  1 22:23:04 2006
From: tom at opengridcomputing.com (Tom Tucker)
Date: Tue, 01 Aug 2006 15:23:04 -0500
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <1154463671.2829.63.camel@localhost.localdomain>
References: <1154379923.8544.4.camel@trinity.ogc.int>
	<20060801113703H.fujita.tomonori@lab.ntt.co.jp>
	<1154457764.9903.24.camel@trinity.ogc.int>
	<1154458176.2829.57.camel@localhost.localdomain>
	<1154458856.9903.27.camel@trinity.ogc.int>
	<1154463671.2829.63.camel@localhost.localdomain>
Message-ID: <1154463784.9903.44.camel@trinity.ogc.int>

On Tue, 2006-08-01 at 16:21 -0400, Ming Zhang wrote:
> On Tue, 2006-08-01 at 14:00 -0500, Tom Tucker wrote:
> > On Tue, 2006-08-01 at 14:49 -0400, Ming Zhang wrote:
> > > my 2c. u figure ignores other device types like VT/VTL or bridge. your
> > > target device type are only TYPE_DISK here.
> > 
> > Yeah, I should put in ellipses... These types are not precluded.
> > 
> > >  also scsi/block/file just
> > > physical media used by TYPE_DISK.
> > 
> > Yes, but there seemed to be some interest in exporting a file as a SCSI
> > Target, or even anonymously mapped memory...
> > 
> > What else should we be thinking about?
> 
> SPI is not mentioned in your pic.
> 
> and it will be better if kernel/user space line is marked. so people
> know your intention and can comment in that if need. otherwise, i saw no
> difference from stgt or scst.

Someone else mentioned that. I'll add a line.

> 
> also license. :P what license(s) will be used and allowed for each part.

Dual BSD/GPL
> 
> ming
> 
> 
> 
> > 
> > > 
> > > Ming
> > > 
> > > 
> > > On Tue, 2006-08-01 at 13:42 -0500, Tom Tucker wrote:
> > > > What do people think about something like this...
> > > > 
> > > > The target architecture is implemented to the extent possible entirely
> > > > in user-mode. The architecture intends to support multiple Target Device
> > > > Types, SCSI Transport Types and Network Transport Types. The enclosed
> > > > figure below illustrates the components of the architecture.
> > > > 
> > > > At the top of the figure are the different Target Device Type Drivers.
> > > > These "drivers" are implemented in user-mode as libraries and plug into
> > > > the Target Interface Layer. The Target Device Type drivers each support
> > > > a particular class of device. For example, the SCSI Disk Driver supports
> > > > SCSI disks, the Block Device driver supports generic block devices
> > > > (e.g. /dev/md0, etc..) and the File Device Driver supports files as
> > > > target devices. In most cases, the Target Device Type Drivers call
> > > > existing system call interfaces to communicate with the actual target
> > > > device, e.g. open, close, read, write, ioctl, etc... High performance
> > > > implementations may use private kernel interfaces to improve
> > > > performance. 
> > > > 
> > > > The Target Interface Layer implements a generic target device
> > > > independent API called the Target Device API, and a SCSI transport
> > > > independent API called the SCSI Transport API. This Target Interface
> > > > Layer implements a target/SCSI transport switch that allows any Target
> > > > Device Type to be associated with any SCSI Transport Type. 
> > > > 
> > > > The SCSI Transport Class Drivers implement support for the various SCSI
> > > > transport types: SRP Transport implements the SCSI RDMA Protocol
> > > > transport, FCP Transport implements the Fiber Channel transport type,
> > > > and the iSCSI Transport implements the iSCSI transport type. These
> > > > drivers sit between the Target Interface Layer and the Network Interface
> > > > Layer. 
> > > > 
> > > > The Network Interface Layer implements a SCSI transport independent API
> > > > called the Transport Class API and a network transport independent API
> > > > called the Transport API. The Network Interface Layer allows a SCSI
> > > > Transport Class driver to support multiple network transports. For
> > > > example, the iSCSI Transport driver will support TCP, IB, and iWARP as
> > > > network transports. The details of a particular SCSI Transport Class's
> > > > device enumeration, login and management are implemented in the SCSI
> > > > Transport Class driver (e.g. iSCSI Transport). The details of a
> > > > particular network transport's connection management paradigm are
> > > > implemented in the Transport Provider driver (e.g. RDMA driver).
> > > > 
> > > > The Transport Provider Drivers implement the Transport Provider API and
> > > > provide core network I/O services to the Network Interface Layer. The
> > > > Transport API is a transport independent interface for creating
> > > > endpoints, service points, accepting incoming connection requests and
> > > > performing I/O on an endpoint.
> > > > 
> > > > The Management Agent interfaces with the Target Interface Layer and
> > > > performs management functions such as creating targets, devices, loading
> > > > and storing persistent configurations and other management related
> > > > functions.
> > > > 
> > > > The various API referred to above are basically simplified versions of
> > > > the existing scsi_transport_template, scsi_host, scsi_host_template
> > > > interfaces, etc... from the current kernel implementation. The
> > > > interfaces between the various components, however, can be reduced to
> > > > function calls since everything resides user mode. 
> > > > 
> > > > I think the only tough issue here is with copy avoidance for the network
> > > > user/kernel interface and target device user/kernel interfaces.
> > > > Initially, these could be prototyped without regard to this issue and
> > > > see what kind of performance we could get. The RDMA network transports
> > > > already provide copy avoidance, however, TCP/FC would require some
> > > > cleverness.
> > > > 
> > > > Thoughts?
> > > > 
> > > > _______________________________________________
> > > > Stgt-devel mailing list
> > > > Stgt-devel at lists.berlios.de
> > > > http://bat.berlios.de/mailman/listinfo/stgt-devel
> > > 
> > > _______________________________________________
> > > Stgt-devel mailing list
> > > Stgt-devel at lists.berlios.de
> > > http://bat.berlios.de/mailman/listinfo/stgt-devel
> > 
> > _______________________________________________
> > Stgt-devel mailing list
> > Stgt-devel at lists.berlios.de
> > http://bat.berlios.de/mailman/listinfo/stgt-devel
> 



From mingz at ele.uri.edu  Tue Aug  1 22:31:10 2006
From: mingz at ele.uri.edu (Ming Zhang)
Date: Tue, 01 Aug 2006 16:31:10 -0400
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <1154463784.9903.44.camel@trinity.ogc.int>
References: <1154379923.8544.4.camel@trinity.ogc.int>
	<20060801113703H.fujita.tomonori@lab.ntt.co.jp>
	<1154457764.9903.24.camel@trinity.ogc.int>
	<1154458176.2829.57.camel@localhost.localdomain>
	<1154458856.9903.27.camel@trinity.ogc.int>
	<1154463671.2829.63.camel@localhost.localdomain>
	<1154463784.9903.44.camel@trinity.ogc.int>
Message-ID: <1154464270.2829.66.camel@localhost.localdomain>

On Tue, 2006-08-01 at 15:23 -0500, Tom Tucker wrote:
> On Tue, 2006-08-01 at 16:21 -0400, Ming Zhang wrote:
> > On Tue, 2006-08-01 at 14:00 -0500, Tom Tucker wrote:
> > > On Tue, 2006-08-01 at 14:49 -0400, Ming Zhang wrote:
> > > > my 2c. u figure ignores other device types like VT/VTL or bridge. your
> > > > target device type are only TYPE_DISK here.
> > > 
> > > Yeah, I should put in ellipses... These types are not precluded.
> > > 
> > > >  also scsi/block/file just
> > > > physical media used by TYPE_DISK.
> > > 
> > > Yes, but there seemed to be some interest in exporting a file as a SCSI
> > > Target, or even anonymously mapped memory...
> > > 
> > > What else should we be thinking about?
> > 
> > SPI is not mentioned in your pic.
> > 
> > and it will be better if kernel/user space line is marked. so people
> > know your intention and can comment in that if need. otherwise, i saw no
> > difference from stgt or scst.
> 
> Someone else mentioned that. I'll add a line.
> 

cool.

> > 
> > also license. :P what license(s) will be used and allowed for each part.
> 
> Dual BSD/GPL

cool again.

i bet vendor will love to jump onto this. ;)


> > 
> > ming
> > 
> > 
> > 
> > > 
> > > > 
> > > > Ming
> > > > 
> > > > 
> > > > On Tue, 2006-08-01 at 13:42 -0500, Tom Tucker wrote:
> > > > > What do people think about something like this...
> > > > > 
> > > > > The target architecture is implemented to the extent possible entirely
> > > > > in user-mode. The architecture intends to support multiple Target Device
> > > > > Types, SCSI Transport Types and Network Transport Types. The enclosed
> > > > > figure below illustrates the components of the architecture.
> > > > > 
> > > > > At the top of the figure are the different Target Device Type Drivers.
> > > > > These "drivers" are implemented in user-mode as libraries and plug into
> > > > > the Target Interface Layer. The Target Device Type drivers each support
> > > > > a particular class of device. For example, the SCSI Disk Driver supports
> > > > > SCSI disks, the Block Device driver supports generic block devices
> > > > > (e.g. /dev/md0, etc..) and the File Device Driver supports files as
> > > > > target devices. In most cases, the Target Device Type Drivers call
> > > > > existing system call interfaces to communicate with the actual target
> > > > > device, e.g. open, close, read, write, ioctl, etc... High performance
> > > > > implementations may use private kernel interfaces to improve
> > > > > performance. 
> > > > > 
> > > > > The Target Interface Layer implements a generic target device
> > > > > independent API called the Target Device API, and a SCSI transport
> > > > > independent API called the SCSI Transport API. This Target Interface
> > > > > Layer implements a target/SCSI transport switch that allows any Target
> > > > > Device Type to be associated with any SCSI Transport Type. 
> > > > > 
> > > > > The SCSI Transport Class Drivers implement support for the various SCSI
> > > > > transport types: SRP Transport implements the SCSI RDMA Protocol
> > > > > transport, FCP Transport implements the Fiber Channel transport type,
> > > > > and the iSCSI Transport implements the iSCSI transport type. These
> > > > > drivers sit between the Target Interface Layer and the Network Interface
> > > > > Layer. 
> > > > > 
> > > > > The Network Interface Layer implements a SCSI transport independent API
> > > > > called the Transport Class API and a network transport independent API
> > > > > called the Transport API. The Network Interface Layer allows a SCSI
> > > > > Transport Class driver to support multiple network transports. For
> > > > > example, the iSCSI Transport driver will support TCP, IB, and iWARP as
> > > > > network transports. The details of a particular SCSI Transport Class's
> > > > > device enumeration, login and management are implemented in the SCSI
> > > > > Transport Class driver (e.g. iSCSI Transport). The details of a
> > > > > particular network transport's connection management paradigm are
> > > > > implemented in the Transport Provider driver (e.g. RDMA driver).
> > > > > 
> > > > > The Transport Provider Drivers implement the Transport Provider API and
> > > > > provide core network I/O services to the Network Interface Layer. The
> > > > > Transport API is a transport independent interface for creating
> > > > > endpoints, service points, accepting incoming connection requests and
> > > > > performing I/O on an endpoint.
> > > > > 
> > > > > The Management Agent interfaces with the Target Interface Layer and
> > > > > performs management functions such as creating targets, devices, loading
> > > > > and storing persistent configurations and other management related
> > > > > functions.
> > > > > 
> > > > > The various API referred to above are basically simplified versions of
> > > > > the existing scsi_transport_template, scsi_host, scsi_host_template
> > > > > interfaces, etc... from the current kernel implementation. The
> > > > > interfaces between the various components, however, can be reduced to
> > > > > function calls since everything resides user mode. 
> > > > > 
> > > > > I think the only tough issue here is with copy avoidance for the network
> > > > > user/kernel interface and target device user/kernel interfaces.
> > > > > Initially, these could be prototyped without regard to this issue and
> > > > > see what kind of performance we could get. The RDMA network transports
> > > > > already provide copy avoidance, however, TCP/FC would require some
> > > > > cleverness.
> > > > > 
> > > > > Thoughts?
> > > > > 
> > > > > _______________________________________________
> > > > > Stgt-devel mailing list
> > > > > Stgt-devel at lists.berlios.de
> > > > > http://bat.berlios.de/mailman/listinfo/stgt-devel
> > > > 
> > > > _______________________________________________
> > > > Stgt-devel mailing list
> > > > Stgt-devel at lists.berlios.de
> > > > http://bat.berlios.de/mailman/listinfo/stgt-devel
> > > 
> > > _______________________________________________
> > > Stgt-devel mailing list
> > > Stgt-devel at lists.berlios.de
> > > http://bat.berlios.de/mailman/listinfo/stgt-devel
> > 
> 
> _______________________________________________
> Stgt-devel mailing list
> Stgt-devel at lists.berlios.de
> http://bat.berlios.de/mailman/listinfo/stgt-devel



From tom at opengridcomputing.com  Tue Aug  1 22:43:09 2006
From: tom at opengridcomputing.com (Tom Tucker)
Date: Tue, 01 Aug 2006 15:43:09 -0500
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <1154463671.2829.63.camel@localhost.localdomain>
References: <1154379923.8544.4.camel@trinity.ogc.int>
	<20060801113703H.fujita.tomonori@lab.ntt.co.jp>
	<1154457764.9903.24.camel@trinity.ogc.int>
	<1154458176.2829.57.camel@localhost.localdomain>
	<1154458856.9903.27.camel@trinity.ogc.int>
	<1154463671.2829.63.camel@localhost.localdomain>
Message-ID: <1154464989.9903.54.camel@trinity.ogc.int>

On Tue, 2006-08-01 at 16:21 -0400, Ming Zhang wrote:
> On Tue, 2006-08-01 at 14:00 -0500, Tom Tucker wrote:
> > On Tue, 2006-08-01 at 14:49 -0400, Ming Zhang wrote:
> > > my 2c. u figure ignores other device types like VT/VTL or bridge. your
> > > target device type are only TYPE_DISK here.
> > 
> > Yeah, I should put in ellipses... These types are not precluded.
> > 
> > >  also scsi/block/file just
> > > physical media used by TYPE_DISK.
> > 
> > Yes, but there seemed to be some interest in exporting a file as a SCSI
> > Target, or even anonymously mapped memory...
> > 
> > What else should we be thinking about?
> 
> SPI is not mentioned in your pic.

Hmm. Doesn't this sit on the target device side underneath /dev/sdN?

> 
> and it will be better if kernel/user space line is marked. so people
> know your intention and can comment in that if need. otherwise, i saw no
> difference from stgt or scst.

Attaches is a new picture with kernel/user boundaries. I think the
boundary is somewhat fuzzy at the top and bottom due to the fact that
the API is different for each target type and for each network provider
type. 

For example, the sd driver will use open /dev/sdN and submit ioctl to
read/write the disk, whereas the file target will
open("/home/thisandthat", ...) and submit lseek/read/write to read/write
the file.

On the network side, the TCP provider would use socket, listen, accept,
send, recv (at least initially), the RMDA provider would use
rdma_resolve_addr, rdma_resolve_route, rdma_listen, rdma_accept,
rdma_create_qp, rdma_post_send, etc....

My only point is that the kernel/user interface is not a straight line
since some of these interfaces are higher level than others.



> 
> also license. :P what license(s) will be used and allowed for each part.
> 
> ming
> 
> 
> 
> > 
> > > 
> > > Ming
> > > 
> > > 
> > > On Tue, 2006-08-01 at 13:42 -0500, Tom Tucker wrote:
> > > > What do people think about something like this...
> > > > 
> > > > The target architecture is implemented to the extent possible entirely
> > > > in user-mode. The architecture intends to support multiple Target Device
> > > > Types, SCSI Transport Types and Network Transport Types. The enclosed
> > > > figure below illustrates the components of the architecture.
> > > > 
> > > > At the top of the figure are the different Target Device Type Drivers.
> > > > These "drivers" are implemented in user-mode as libraries and plug into
> > > > the Target Interface Layer. The Target Device Type drivers each support
> > > > a particular class of device. For example, the SCSI Disk Driver supports
> > > > SCSI disks, the Block Device driver supports generic block devices
> > > > (e.g. /dev/md0, etc..) and the File Device Driver supports files as
> > > > target devices. In most cases, the Target Device Type Drivers call
> > > > existing system call interfaces to communicate with the actual target
> > > > device, e.g. open, close, read, write, ioctl, etc... High performance
> > > > implementations may use private kernel interfaces to improve
> > > > performance. 
> > > > 
> > > > The Target Interface Layer implements a generic target device
> > > > independent API called the Target Device API, and a SCSI transport
> > > > independent API called the SCSI Transport API. This Target Interface
> > > > Layer implements a target/SCSI transport switch that allows any Target
> > > > Device Type to be associated with any SCSI Transport Type. 
> > > > 
> > > > The SCSI Transport Class Drivers implement support for the various SCSI
> > > > transport types: SRP Transport implements the SCSI RDMA Protocol
> > > > transport, FCP Transport implements the Fiber Channel transport type,
> > > > and the iSCSI Transport implements the iSCSI transport type. These
> > > > drivers sit between the Target Interface Layer and the Network Interface
> > > > Layer. 
> > > > 
> > > > The Network Interface Layer implements a SCSI transport independent API
> > > > called the Transport Class API and a network transport independent API
> > > > called the Transport API. The Network Interface Layer allows a SCSI
> > > > Transport Class driver to support multiple network transports. For
> > > > example, the iSCSI Transport driver will support TCP, IB, and iWARP as
> > > > network transports. The details of a particular SCSI Transport Class's
> > > > device enumeration, login and management are implemented in the SCSI
> > > > Transport Class driver (e.g. iSCSI Transport). The details of a
> > > > particular network transport's connection management paradigm are
> > > > implemented in the Transport Provider driver (e.g. RDMA driver).
> > > > 
> > > > The Transport Provider Drivers implement the Transport Provider API and
> > > > provide core network I/O services to the Network Interface Layer. The
> > > > Transport API is a transport independent interface for creating
> > > > endpoints, service points, accepting incoming connection requests and
> > > > performing I/O on an endpoint.
> > > > 
> > > > The Management Agent interfaces with the Target Interface Layer and
> > > > performs management functions such as creating targets, devices, loading
> > > > and storing persistent configurations and other management related
> > > > functions.
> > > > 
> > > > The various API referred to above are basically simplified versions of
> > > > the existing scsi_transport_template, scsi_host, scsi_host_template
> > > > interfaces, etc... from the current kernel implementation. The
> > > > interfaces between the various components, however, can be reduced to
> > > > function calls since everything resides user mode. 
> > > > 
> > > > I think the only tough issue here is with copy avoidance for the network
> > > > user/kernel interface and target device user/kernel interfaces.
> > > > Initially, these could be prototyped without regard to this issue and
> > > > see what kind of performance we could get. The RDMA network transports
> > > > already provide copy avoidance, however, TCP/FC would require some
> > > > cleverness.
> > > > 
> > > > Thoughts?
> > > > 
> > > > _______________________________________________
> > > > Stgt-devel mailing list
> > > > Stgt-devel at lists.berlios.de
> > > > http://bat.berlios.de/mailman/listinfo/stgt-devel
> > > 
> > > _______________________________________________
> > > Stgt-devel mailing list
> > > Stgt-devel at lists.berlios.de
> > > http://bat.berlios.de/mailman/listinfo/stgt-devel
> > 
> > _______________________________________________
> > Stgt-devel mailing list
> > Stgt-devel at lists.berlios.de
> > http://bat.berlios.de/mailman/listinfo/stgt-devel
> 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: user-target-picture.pdf
Type: application/pdf
Size: 23969 bytes
Desc: not available
URL: <https://lists.berlios.de/pipermail/stgt-devel/attachments/20060801/560c6025/attachment.pdf>

From mingz at ele.uri.edu  Tue Aug  1 23:24:33 2006
From: mingz at ele.uri.edu (Ming Zhang)
Date: Tue, 01 Aug 2006 17:24:33 -0400
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <1154464989.9903.54.camel@trinity.ogc.int>
References: <1154379923.8544.4.camel@trinity.ogc.int>
	<20060801113703H.fujita.tomonori@lab.ntt.co.jp>
	<1154457764.9903.24.camel@trinity.ogc.int>
	<1154458176.2829.57.camel@localhost.localdomain>
	<1154458856.9903.27.camel@trinity.ogc.int>
	<1154463671.2829.63.camel@localhost.localdomain>
	<1154464989.9903.54.camel@trinity.ogc.int>
Message-ID: <1154467473.2829.72.camel@localhost.localdomain>

On Tue, 2006-08-01 at 15:43 -0500, Tom Tucker wrote:
> On Tue, 2006-08-01 at 16:21 -0400, Ming Zhang wrote:
> > On Tue, 2006-08-01 at 14:00 -0500, Tom Tucker wrote:
> > > On Tue, 2006-08-01 at 14:49 -0400, Ming Zhang wrote:
> > > > my 2c. u figure ignores other device types like VT/VTL or bridge. your
> > > > target device type are only TYPE_DISK here.
> > > 
> > > Yeah, I should put in ellipses... These types are not precluded.
> > > 
> > > >  also scsi/block/file just
> > > > physical media used by TYPE_DISK.
> > > 
> > > Yes, but there seemed to be some interest in exporting a file as a SCSI
> > > Target, or even anonymously mapped memory...
> > > 
> > > What else should we be thinking about?
> > 
> > SPI is not mentioned in your pic.
> 
> Hmm. Doesn't this sit on the target device side underneath /dev/sdN?

sorry but i mean SPI transport, or interface with INI.

> 
> > 
> > and it will be better if kernel/user space line is marked. so people
> > know your intention and can comment in that if need. otherwise, i saw no
> > difference from stgt or scst.
> 
> Attaches is a new picture with kernel/user boundaries. I think the
> boundary is somewhat fuzzy at the top and bottom due to the fact that
> the API is different for each target type and for each network provider
> type. 
> 
> For example, the sd driver will use open /dev/sdN and submit ioctl to
> read/write the disk, whereas the file target will
> open("/home/thisandthat", ...) and submit lseek/read/write to read/write
> the file.
> 
> On the network side, the TCP provider would use socket, listen, accept,
> send, recv (at least initially), the RMDA provider would use
> rdma_resolve_addr, rdma_resolve_route, rdma_listen, rdma_accept,
> rdma_create_qp, rdma_post_send, etc....
> 
> My only point is that the kernel/user interface is not a straight line
> since some of these interfaces are higher level than others.

so you have even all transports in user space? zero copy socket is not
easy. and can FCP drivers, like a target mode driver for a QLA or LSI
HBA can be in user space as well?

ming


> 
> 
> 
> > 
> > also license. :P what license(s) will be used and allowed for each part.
> > 
> > ming
> > 
> > 
> > 
> > > 
> > > > 
> > > > Ming
> > > > 
> > > > 
> > > > On Tue, 2006-08-01 at 13:42 -0500, Tom Tucker wrote:
> > > > > What do people think about something like this...
> > > > > 
> > > > > The target architecture is implemented to the extent possible entirely
> > > > > in user-mode. The architecture intends to support multiple Target Device
> > > > > Types, SCSI Transport Types and Network Transport Types. The enclosed
> > > > > figure below illustrates the components of the architecture.
> > > > > 
> > > > > At the top of the figure are the different Target Device Type Drivers.
> > > > > These "drivers" are implemented in user-mode as libraries and plug into
> > > > > the Target Interface Layer. The Target Device Type drivers each support
> > > > > a particular class of device. For example, the SCSI Disk Driver supports
> > > > > SCSI disks, the Block Device driver supports generic block devices
> > > > > (e.g. /dev/md0, etc..) and the File Device Driver supports files as
> > > > > target devices. In most cases, the Target Device Type Drivers call
> > > > > existing system call interfaces to communicate with the actual target
> > > > > device, e.g. open, close, read, write, ioctl, etc... High performance
> > > > > implementations may use private kernel interfaces to improve
> > > > > performance. 
> > > > > 
> > > > > The Target Interface Layer implements a generic target device
> > > > > independent API called the Target Device API, and a SCSI transport
> > > > > independent API called the SCSI Transport API. This Target Interface
> > > > > Layer implements a target/SCSI transport switch that allows any Target
> > > > > Device Type to be associated with any SCSI Transport Type. 
> > > > > 
> > > > > The SCSI Transport Class Drivers implement support for the various SCSI
> > > > > transport types: SRP Transport implements the SCSI RDMA Protocol
> > > > > transport, FCP Transport implements the Fiber Channel transport type,
> > > > > and the iSCSI Transport implements the iSCSI transport type. These
> > > > > drivers sit between the Target Interface Layer and the Network Interface
> > > > > Layer. 
> > > > > 
> > > > > The Network Interface Layer implements a SCSI transport independent API
> > > > > called the Transport Class API and a network transport independent API
> > > > > called the Transport API. The Network Interface Layer allows a SCSI
> > > > > Transport Class driver to support multiple network transports. For
> > > > > example, the iSCSI Transport driver will support TCP, IB, and iWARP as
> > > > > network transports. The details of a particular SCSI Transport Class's
> > > > > device enumeration, login and management are implemented in the SCSI
> > > > > Transport Class driver (e.g. iSCSI Transport). The details of a
> > > > > particular network transport's connection management paradigm are
> > > > > implemented in the Transport Provider driver (e.g. RDMA driver).
> > > > > 
> > > > > The Transport Provider Drivers implement the Transport Provider API and
> > > > > provide core network I/O services to the Network Interface Layer. The
> > > > > Transport API is a transport independent interface for creating
> > > > > endpoints, service points, accepting incoming connection requests and
> > > > > performing I/O on an endpoint.
> > > > > 
> > > > > The Management Agent interfaces with the Target Interface Layer and
> > > > > performs management functions such as creating targets, devices, loading
> > > > > and storing persistent configurations and other management related
> > > > > functions.
> > > > > 
> > > > > The various API referred to above are basically simplified versions of
> > > > > the existing scsi_transport_template, scsi_host, scsi_host_template
> > > > > interfaces, etc... from the current kernel implementation. The
> > > > > interfaces between the various components, however, can be reduced to
> > > > > function calls since everything resides user mode. 
> > > > > 
> > > > > I think the only tough issue here is with copy avoidance for the network
> > > > > user/kernel interface and target device user/kernel interfaces.
> > > > > Initially, these could be prototyped without regard to this issue and
> > > > > see what kind of performance we could get. The RDMA network transports
> > > > > already provide copy avoidance, however, TCP/FC would require some
> > > > > cleverness.
> > > > > 
> > > > > Thoughts?
> > > > > 
> > > > > _______________________________________________
> > > > > Stgt-devel mailing list
> > > > > Stgt-devel at lists.berlios.de
> > > > > http://bat.berlios.de/mailman/listinfo/stgt-devel
> > > > 
> > > > _______________________________________________
> > > > Stgt-devel mailing list
> > > > Stgt-devel at lists.berlios.de
> > > > http://bat.berlios.de/mailman/listinfo/stgt-devel
> > > 
> > > _______________________________________________
> > > Stgt-devel mailing list
> > > Stgt-devel at lists.berlios.de
> > > http://bat.berlios.de/mailman/listinfo/stgt-devel
> > 
> _______________________________________________
> Stgt-devel mailing list
> Stgt-devel at lists.berlios.de
> http://bat.berlios.de/mailman/listinfo/stgt-devel



From tom at opengridcomputing.com  Tue Aug  1 23:38:10 2006
From: tom at opengridcomputing.com (Tom Tucker)
Date: Tue, 01 Aug 2006 16:38:10 -0500
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <1154467473.2829.72.camel@localhost.localdomain>
References: <1154379923.8544.4.camel@trinity.ogc.int>
	<20060801113703H.fujita.tomonori@lab.ntt.co.jp>
	<1154457764.9903.24.camel@trinity.ogc.int>
	<1154458176.2829.57.camel@localhost.localdomain>
	<1154458856.9903.27.camel@trinity.ogc.int>
	<1154463671.2829.63.camel@localhost.localdomain>
	<1154464989.9903.54.camel@trinity.ogc.int>
	<1154467473.2829.72.camel@localhost.localdomain>
Message-ID: <1154468290.9903.68.camel@trinity.ogc.int>

On Tue, 2006-08-01 at 17:24 -0400, Ming Zhang wrote:
> On Tue, 2006-08-01 at 15:43 -0500, Tom Tucker wrote:
> > On Tue, 2006-08-01 at 16:21 -0400, Ming Zhang wrote:
> > > On Tue, 2006-08-01 at 14:00 -0500, Tom Tucker wrote:
> > > > On Tue, 2006-08-01 at 14:49 -0400, Ming Zhang wrote:
> > > > > my 2c. u figure ignores other device types like VT/VTL or bridge. your
> > > > > target device type are only TYPE_DISK here.
> > > > 
> > > > Yeah, I should put in ellipses... These types are not precluded.
> > > > 
> > > > >  also scsi/block/file just
> > > > > physical media used by TYPE_DISK.
> > > > 
> > > > Yes, but there seemed to be some interest in exporting a file as a SCSI
> > > > Target, or even anonymously mapped memory...
> > > > 
> > > > What else should we be thinking about?
> > > 
> > > SPI is not mentioned in your pic.
> > 
> > Hmm. Doesn't this sit on the target device side underneath /dev/sdN?
> 
> sorry but i mean SPI transport, or interface with INI.
> 
> > 
> > > 
> > > and it will be better if kernel/user space line is marked. so people
> > > know your intention and can comment in that if need. otherwise, i saw no
> > > difference from stgt or scst.
> > 
> > Attaches is a new picture with kernel/user boundaries. I think the
> > boundary is somewhat fuzzy at the top and bottom due to the fact that
> > the API is different for each target type and for each network provider
> > type. 
> > 
> > For example, the sd driver will use open /dev/sdN and submit ioctl to
> > read/write the disk, whereas the file target will
> > open("/home/thisandthat", ...) and submit lseek/read/write to read/write
> > the file.
> > 
> > On the network side, the TCP provider would use socket, listen, accept,
> > send, recv (at least initially), the RMDA provider would use
> > rdma_resolve_addr, rdma_resolve_route, rdma_listen, rdma_accept,
> > rdma_create_qp, rdma_post_send, etc....
> > 
> > My only point is that the kernel/user interface is not a straight line
> > since some of these interfaces are higher level than others.
> 
> so you have even all transports in user space? zero copy socket is not
> easy. 

I think this is the area where we will need to get fancy if we want
higher performance. To avoid the copy, we would have to migrate to
netchannels (if they every happen) or implement our own simple tear-away
buffer scheme on top of a socket. I think this is phase-ii, however. 

How about on the target device side? How expensive/inefficient is the
ioctl interface to /dev/sd?

> and can FCP drivers, like a target mode driver for a QLA or LSI
> HBA can be in user space as well?

No. These will be in the kernel, but I'm not considering these drivers
as part of this subsystem. Are they part of IET?

> 
> ming
> 
> 
> > 
> > 
> > 
> > > 
> > > also license. :P what license(s) will be used and allowed for each part.
> > > 
> > > ming
> > > 
> > > 
> > > 
> > > > 
> > > > > 
> > > > > Ming
> > > > > 
> > > > > 
> > > > > On Tue, 2006-08-01 at 13:42 -0500, Tom Tucker wrote:
> > > > > > What do people think about something like this...
> > > > > > 
> > > > > > The target architecture is implemented to the extent possible entirely
> > > > > > in user-mode. The architecture intends to support multiple Target Device
> > > > > > Types, SCSI Transport Types and Network Transport Types. The enclosed
> > > > > > figure below illustrates the components of the architecture.
> > > > > > 
> > > > > > At the top of the figure are the different Target Device Type Drivers.
> > > > > > These "drivers" are implemented in user-mode as libraries and plug into
> > > > > > the Target Interface Layer. The Target Device Type drivers each support
> > > > > > a particular class of device. For example, the SCSI Disk Driver supports
> > > > > > SCSI disks, the Block Device driver supports generic block devices
> > > > > > (e.g. /dev/md0, etc..) and the File Device Driver supports files as
> > > > > > target devices. In most cases, the Target Device Type Drivers call
> > > > > > existing system call interfaces to communicate with the actual target
> > > > > > device, e.g. open, close, read, write, ioctl, etc... High performance
> > > > > > implementations may use private kernel interfaces to improve
> > > > > > performance. 
> > > > > > 
> > > > > > The Target Interface Layer implements a generic target device
> > > > > > independent API called the Target Device API, and a SCSI transport
> > > > > > independent API called the SCSI Transport API. This Target Interface
> > > > > > Layer implements a target/SCSI transport switch that allows any Target
> > > > > > Device Type to be associated with any SCSI Transport Type. 
> > > > > > 
> > > > > > The SCSI Transport Class Drivers implement support for the various SCSI
> > > > > > transport types: SRP Transport implements the SCSI RDMA Protocol
> > > > > > transport, FCP Transport implements the Fiber Channel transport type,
> > > > > > and the iSCSI Transport implements the iSCSI transport type. These
> > > > > > drivers sit between the Target Interface Layer and the Network Interface
> > > > > > Layer. 
> > > > > > 
> > > > > > The Network Interface Layer implements a SCSI transport independent API
> > > > > > called the Transport Class API and a network transport independent API
> > > > > > called the Transport API. The Network Interface Layer allows a SCSI
> > > > > > Transport Class driver to support multiple network transports. For
> > > > > > example, the iSCSI Transport driver will support TCP, IB, and iWARP as
> > > > > > network transports. The details of a particular SCSI Transport Class's
> > > > > > device enumeration, login and management are implemented in the SCSI
> > > > > > Transport Class driver (e.g. iSCSI Transport). The details of a
> > > > > > particular network transport's connection management paradigm are
> > > > > > implemented in the Transport Provider driver (e.g. RDMA driver).
> > > > > > 
> > > > > > The Transport Provider Drivers implement the Transport Provider API and
> > > > > > provide core network I/O services to the Network Interface Layer. The
> > > > > > Transport API is a transport independent interface for creating
> > > > > > endpoints, service points, accepting incoming connection requests and
> > > > > > performing I/O on an endpoint.
> > > > > > 
> > > > > > The Management Agent interfaces with the Target Interface Layer and
> > > > > > performs management functions such as creating targets, devices, loading
> > > > > > and storing persistent configurations and other management related
> > > > > > functions.
> > > > > > 
> > > > > > The various API referred to above are basically simplified versions of
> > > > > > the existing scsi_transport_template, scsi_host, scsi_host_template
> > > > > > interfaces, etc... from the current kernel implementation. The
> > > > > > interfaces between the various components, however, can be reduced to
> > > > > > function calls since everything resides user mode. 
> > > > > > 
> > > > > > I think the only tough issue here is with copy avoidance for the network
> > > > > > user/kernel interface and target device user/kernel interfaces.
> > > > > > Initially, these could be prototyped without regard to this issue and
> > > > > > see what kind of performance we could get. The RDMA network transports
> > > > > > already provide copy avoidance, however, TCP/FC would require some
> > > > > > cleverness.
> > > > > > 
> > > > > > Thoughts?
> > > > > > 
> > > > > > _______________________________________________
> > > > > > Stgt-devel mailing list
> > > > > > Stgt-devel at lists.berlios.de
> > > > > > http://bat.berlios.de/mailman/listinfo/stgt-devel
> > > > > 
> > > > > _______________________________________________
> > > > > Stgt-devel mailing list
> > > > > Stgt-devel at lists.berlios.de
> > > > > http://bat.berlios.de/mailman/listinfo/stgt-devel
> > > > 
> > > > _______________________________________________
> > > > Stgt-devel mailing list
> > > > Stgt-devel at lists.berlios.de
> > > > http://bat.berlios.de/mailman/listinfo/stgt-devel
> > > 
> > _______________________________________________
> > Stgt-devel mailing list
> > Stgt-devel at lists.berlios.de
> > http://bat.berlios.de/mailman/listinfo/stgt-devel
> 



From fujita.tomonori at lab.ntt.co.jp  Wed Aug  2 00:21:10 2006
From: fujita.tomonori at lab.ntt.co.jp (FUJITA Tomonori)
Date: Wed, 2 Aug 2006 07:21:10 +0900 (JST)
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <1154437753.31727.5.camel@trinity.ogc.int>
References: <1154379923.8544.4.camel@trinity.ogc.int>
	<20060801113703H.fujita.tomonori@lab.ntt.co.jp>
	<1154437753.31727.5.camel@trinity.ogc.int>
Message-ID: <20060803071057F.fujita.tomonori@lab.ntt.co.jp>

From: Tom Tucker <tom at opengridcomputing.com>
Subject: Re: [Stgt-devel] User-mode iSER
Date: Tue, 01 Aug 2006 08:09:13 -0500

> On Tue, 2006-08-01 at 11:37 +0900, FUJITA Tomonori wrote:
> > From: Tom Tucker <tom at opengridcomputing.com>
> > Subject: [Stgt-devel] User-mode iSER
> > Date: Mon, 31 Jul 2006 16:05:23 -0500
> > 
> > > Tomo:
> > > 
> > > I heard a rumor that moving even more of the iSER target design into
> > > user mode was considered at the OLS. I think this is a very interesting
> > > idea and would like to know what you and others think of this in general
> > > and if there are any specific issues that people think make this
> > > difficult.
> > 
> > Yeah, we thought about that.
> > 
> > It's still not clear that tgt iSCSI target driver (*1) is accepted to
> > mainline. We can use lots of parts of open-iscsi code for it, however,
> > you can say that iSCSI target software can be implemented in user
> > space.
> 
> Also, won't a user-mode approach support virtual target devices more
> easily? 

There's no difference. Note that we try to push a small portion of the
iSCSI tcp driver into kernel (iSCSI protocol processing). Both
approaches perform SCSI protocol processing, I/O in user space.

I think that you can easily implement any kind of vitalization, device
vitalization (like virtual tape library) and backing vitalization
(snapshot, encryption, compression, etc) in user space with both
approaches.


> > Mike said that returning from vacation, he clean up and submit the
> > iSCSI target driver to scsi-ml for discussion.
> 
> Do you know When does he gets back?

He said (on open-iscsi mailing list) that he is off form July 31st to
Aug 6th.


> > If we fail to put it into mainline, I'll implement iscsi target
> > software in user space, which uses tgt user-space code (SCSI
> > processing, management, etc). So, is it possible that we integrate
> > iSER into user-space iSCSI target software?
> 
> Yes it is possible to use iSER as a user-mode transport. In fact, iSER
> supports kernel-bypass, so there is no additional overhead vs. i/o in
> the kernel. 

I see. Thanks.



From fujita.tomonori at lab.ntt.co.jp  Wed Aug  2 00:21:10 2006
From: fujita.tomonori at lab.ntt.co.jp (FUJITA Tomonori)
Date: Wed, 2 Aug 2006 07:21:10 +0900 (JST)
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <1154464270.2829.66.camel@localhost.localdomain>
References: <1154463671.2829.63.camel@localhost.localdomain>
	<1154463784.9903.44.camel@trinity.ogc.int>
	<1154464270.2829.66.camel@localhost.localdomain>
Message-ID: <20060803071530D.fujita.tomonori@lab.ntt.co.jp>

From: Ming Zhang <mingz at ele.uri.edu>
Subject: Re: [Stgt-devel] User-mode iSER
Date: Tue, 01 Aug 2006 16:31:10 -0400

> On Tue, 2006-08-01 at 15:23 -0500, Tom Tucker wrote:
> > On Tue, 2006-08-01 at 16:21 -0400, Ming Zhang wrote:
> > > On Tue, 2006-08-01 at 14:00 -0500, Tom Tucker wrote:
> > > > On Tue, 2006-08-01 at 14:49 -0400, Ming Zhang wrote:
> > > > > my 2c. u figure ignores other device types like VT/VTL or bridge. your
> > > > > target device type are only TYPE_DISK here.
> > > > 
> > > > Yeah, I should put in ellipses... These types are not precluded.
> > > > 
> > > > >  also scsi/block/file just
> > > > > physical media used by TYPE_DISK.
> > > > 
> > > > Yes, but there seemed to be some interest in exporting a file as a SCSI
> > > > Target, or even anonymously mapped memory...
> > > > 
> > > > What else should we be thinking about?
> > > 
> > > SPI is not mentioned in your pic.
> > > 
> > > and it will be better if kernel/user space line is marked. so people
> > > know your intention and can comment in that if need. otherwise, i saw no
> > > difference from stgt or scst.
> > 
> > Someone else mentioned that. I'll add a line.
> > 
> 
> cool.
> 
> > > 
> > > also license. :P what license(s) will be used and allowed for each part.
> > 
> > Dual BSD/GPL
> 
> cool again.
> 
> i bet vendor will love to jump onto this. ;)

Only the iSER component. The rest will be released under GPL.



From fujita.tomonori at lab.ntt.co.jp  Wed Aug  2 00:21:09 2006
From: fujita.tomonori at lab.ntt.co.jp (FUJITA Tomonori)
Date: Wed, 2 Aug 2006 07:21:09 +0900 (JST)
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <1154464989.9903.54.camel@trinity.ogc.int>
References: <1154458856.9903.27.camel@trinity.ogc.int>
	<1154463671.2829.63.camel@localhost.localdomain>
	<1154464989.9903.54.camel@trinity.ogc.int>
Message-ID: <20060803065429X.fujita.tomonori@lab.ntt.co.jp>

From: Tom Tucker <tom at opengridcomputing.com>
Subject: Re: [Stgt-devel] User-mode iSER
Date: Tue, 01 Aug 2006 15:43:09 -0500

> > and it will be better if kernel/user space line is marked. so people
> > know your intention and can comment in that if need. otherwise, i saw no
> > difference from stgt or scst.
> 
> Attaches is a new picture with kernel/user boundaries. I think the
> boundary is somewhat fuzzy at the top and bottom due to the fact that
> the API is different for each target type and for each network provider
> type. 
> 
> For example, the sd driver will use open /dev/sdN and submit ioctl to
> read/write the disk, whereas the file target will
> open("/home/thisandthat", ...) and submit lseek/read/write to read/write
> the file.
> 
> On the network side, the TCP provider would use socket, listen, accept,
> send, recv (at least initially), the RMDA provider would use
> rdma_resolve_addr, rdma_resolve_route, rdma_listen, rdma_accept,
> rdma_create_qp, rdma_post_send, etc....
> 
> My only point is that the kernel/user interface is not a straight line
> since some of these interfaces are higher level than others.

Yes. Most of the tgt drivers (except for iSCSI tcp and iSER drivers)
need their own in-kernel part. Oh, iSCSI hardware drivers (like
qla4xxx) need the in-kernel part too.



From fujita.tomonori at lab.ntt.co.jp  Wed Aug  2 00:21:09 2006
From: fujita.tomonori at lab.ntt.co.jp (FUJITA Tomonori)
Date: Wed, 2 Aug 2006 07:21:09 +0900 (JST)
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <1154462180.2829.59.camel@localhost.localdomain>
References: <1154458176.2829.57.camel@localhost.localdomain>
	<1154458856.9903.27.camel@trinity.ogc.int>
	<1154462180.2829.59.camel@localhost.localdomain>
Message-ID: <20060803064725W.fujita.tomonori@lab.ntt.co.jp>

From: Ming Zhang <mingz at ele.uri.edu>
Subject: Re: [Stgt-devel] User-mode iSER
Date: Tue, 01 Aug 2006 15:56:20 -0400

> On Tue, 2006-08-01 at 14:00 -0500, Tom Tucker wrote:
> > On Tue, 2006-08-01 at 14:49 -0400, Ming Zhang wrote:
> > > my 2c. u figure ignores other device types like VT/VTL or bridge. your
> > > target device type are only TYPE_DISK here.
> > 
> > Yeah, I should put in ellipses... These types are not precluded.
> > 
> > >  also scsi/block/file just
> > > physical media used by TYPE_DISK.
> > 
> > Yes, but there seemed to be some interest in exporting a file as a SCSI
> > Target, or even anonymously mapped memory...
> > 
> > What else should we be thinking about?
> 
> what about the AoE? maybe people want AoE target as well. or AoE will
> not be considered because of its non-SCSI nature?

No AoE support. We tried before, however, the current in-kernel stgt
code is fully integrated with the SCSI-mid layer, that is, we use the
data structures and functions. It is not an independent component, a
part of the SCSI-mid layer.



From tom at opengridcomputing.com  Wed Aug  2 00:41:48 2006
From: tom at opengridcomputing.com (Tom Tucker)
Date: Tue, 01 Aug 2006 17:41:48 -0500
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <20060803071530D.fujita.tomonori@lab.ntt.co.jp>
References: <1154463671.2829.63.camel@localhost.localdomain>
	<1154463784.9903.44.camel@trinity.ogc.int>
	<1154464270.2829.66.camel@localhost.localdomain>
	<20060803071530D.fujita.tomonori@lab.ntt.co.jp>
Message-ID: <1154472108.9903.70.camel@trinity.ogc.int>

On Wed, 2006-08-02 at 07:21 +0900, FUJITA Tomonori wrote:
> From: Ming Zhang <mingz at ele.uri.edu>
> Subject: Re: [Stgt-devel] User-mode iSER
> Date: Tue, 01 Aug 2006 16:31:10 -0400
> 
> > On Tue, 2006-08-01 at 15:23 -0500, Tom Tucker wrote:
> > > On Tue, 2006-08-01 at 16:21 -0400, Ming Zhang wrote:
> > > > On Tue, 2006-08-01 at 14:00 -0500, Tom Tucker wrote:
> > > > > On Tue, 2006-08-01 at 14:49 -0400, Ming Zhang wrote:
> > > > > > my 2c. u figure ignores other device types like VT/VTL or bridge. your
> > > > > > target device type are only TYPE_DISK here.
> > > > > 
> > > > > Yeah, I should put in ellipses... These types are not precluded.
> > > > > 
> > > > > >  also scsi/block/file just
> > > > > > physical media used by TYPE_DISK.
> > > > > 
> > > > > Yes, but there seemed to be some interest in exporting a file as a SCSI
> > > > > Target, or even anonymously mapped memory...
> > > > > 
> > > > > What else should we be thinking about?
> > > > 
> > > > SPI is not mentioned in your pic.
> > > > 
> > > > and it will be better if kernel/user space line is marked. so people
> > > > know your intention and can comment in that if need. otherwise, i saw no
> > > > difference from stgt or scst.
> > > 
> > > Someone else mentioned that. I'll add a line.
> > > 
> > 
> > cool.
> > 
> > > > 
> > > > also license. :P what license(s) will be used and allowed for each part.
> > > 
> > > Dual BSD/GPL
> > 
> > cool again.
> > 
> > i bet vendor will love to jump onto this. ;)
> 
> Only the iSER component. The rest will be released under GPL.
> 

Yes, anything we beg borrow or steal from GPL is GPL...




From mingz at ele.uri.edu  Wed Aug  2 00:53:26 2006
From: mingz at ele.uri.edu (Ming Zhang)
Date: Tue, 01 Aug 2006 18:53:26 -0400
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <20060803064725W.fujita.tomonori@lab.ntt.co.jp>
References: <1154458176.2829.57.camel@localhost.localdomain>
	<1154458856.9903.27.camel@trinity.ogc.int>
	<1154462180.2829.59.camel@localhost.localdomain>
	<20060803064725W.fujita.tomonori@lab.ntt.co.jp>
Message-ID: <1154472806.2829.74.camel@localhost.localdomain>

On Wed, 2006-08-02 at 07:21 +0900, FUJITA Tomonori wrote:
> From: Ming Zhang <mingz at ele.uri.edu>
> Subject: Re: [Stgt-devel] User-mode iSER
> Date: Tue, 01 Aug 2006 15:56:20 -0400
> 
> > On Tue, 2006-08-01 at 14:00 -0500, Tom Tucker wrote:
> > > On Tue, 2006-08-01 at 14:49 -0400, Ming Zhang wrote:
> > > > my 2c. u figure ignores other device types like VT/VTL or bridge. your
> > > > target device type are only TYPE_DISK here.
> > > 
> > > Yeah, I should put in ellipses... These types are not precluded.
> > > 
> > > >  also scsi/block/file just
> > > > physical media used by TYPE_DISK.
> > > 
> > > Yes, but there seemed to be some interest in exporting a file as a SCSI
> > > Target, or even anonymously mapped memory...
> > > 
> > > What else should we be thinking about?
> > 
> > what about the AoE? maybe people want AoE target as well. or AoE will
> > not be considered because of its non-SCSI nature?
> 
> No AoE support. We tried before, however, the current in-kernel stgt
> code is fully integrated with the SCSI-mid layer, that is, we use the
> data structures and functions. It is not an independent component, a
> part of the SCSI-mid layer.
> 

yes. AoE is not SCSI related. Anyway I have no interest on Aoe as
well. ;)

Ming




From mingz at ele.uri.edu  Wed Aug  2 00:54:44 2006
From: mingz at ele.uri.edu (Ming Zhang)
Date: Tue, 01 Aug 2006 18:54:44 -0400
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <20060803071530D.fujita.tomonori@lab.ntt.co.jp>
References: <1154463671.2829.63.camel@localhost.localdomain>
	<1154463784.9903.44.camel@trinity.ogc.int>
	<1154464270.2829.66.camel@localhost.localdomain>
	<20060803071530D.fujita.tomonori@lab.ntt.co.jp>
Message-ID: <1154472884.2829.76.camel@localhost.localdomain>

On Wed, 2006-08-02 at 07:21 +0900, FUJITA Tomonori wrote:
> From: Ming Zhang <mingz at ele.uri.edu>
> Subject: Re: [Stgt-devel] User-mode iSER
> Date: Tue, 01 Aug 2006 16:31:10 -0400
> 
> > On Tue, 2006-08-01 at 15:23 -0500, Tom Tucker wrote:
> > > On Tue, 2006-08-01 at 16:21 -0400, Ming Zhang wrote:
> > > > On Tue, 2006-08-01 at 14:00 -0500, Tom Tucker wrote:
> > > > > On Tue, 2006-08-01 at 14:49 -0400, Ming Zhang wrote:
> > > > > > my 2c. u figure ignores other device types like VT/VTL or bridge. your
> > > > > > target device type are only TYPE_DISK here.
> > > > > 
> > > > > Yeah, I should put in ellipses... These types are not precluded.
> > > > > 
> > > > > >  also scsi/block/file just
> > > > > > physical media used by TYPE_DISK.
> > > > > 
> > > > > Yes, but there seemed to be some interest in exporting a file as a SCSI
> > > > > Target, or even anonymously mapped memory...
> > > > > 
> > > > > What else should we be thinking about?
> > > > 
> > > > SPI is not mentioned in your pic.
> > > > 
> > > > and it will be better if kernel/user space line is marked. so people
> > > > know your intention and can comment in that if need. otherwise, i saw no
> > > > difference from stgt or scst.
> > > 
> > > Someone else mentioned that. I'll add a line.
> > > 
> > 
> > cool.
> > 
> > > > 
> > > > also license. :P what license(s) will be used and allowed for each part.
> > > 
> > > Dual BSD/GPL
> > 
> > cool again.
> > 
> > i bet vendor will love to jump onto this. ;)
> 
> Only the iSER component. The rest will be released under GPL.

then is a VT/VTL company write a target mode driver and need to link to
this target, means it has to be GPL as well?

Ming

> 



From mingz at ele.uri.edu  Wed Aug  2 00:56:29 2006
From: mingz at ele.uri.edu (Ming Zhang)
Date: Tue, 01 Aug 2006 18:56:29 -0400
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <20060803065429X.fujita.tomonori@lab.ntt.co.jp>
References: <1154458856.9903.27.camel@trinity.ogc.int>
	<1154463671.2829.63.camel@localhost.localdomain>
	<1154464989.9903.54.camel@trinity.ogc.int>
	<20060803065429X.fujita.tomonori@lab.ntt.co.jp>
Message-ID: <1154472989.2829.78.camel@localhost.localdomain>

On Wed, 2006-08-02 at 07:21 +0900, FUJITA Tomonori wrote:
> From: Tom Tucker <tom at opengridcomputing.com>
> Subject: Re: [Stgt-devel] User-mode iSER
> Date: Tue, 01 Aug 2006 15:43:09 -0500
> 
> > > and it will be better if kernel/user space line is marked. so people
> > > know your intention and can comment in that if need. otherwise, i saw no
> > > difference from stgt or scst.
> > 
> > Attaches is a new picture with kernel/user boundaries. I think the
> > boundary is somewhat fuzzy at the top and bottom due to the fact that
> > the API is different for each target type and for each network provider
> > type. 
> > 
> > For example, the sd driver will use open /dev/sdN and submit ioctl to
> > read/write the disk, whereas the file target will
> > open("/home/thisandthat", ...) and submit lseek/read/write to read/write
> > the file.
> > 
> > On the network side, the TCP provider would use socket, listen, accept,
> > send, recv (at least initially), the RMDA provider would use
> > rdma_resolve_addr, rdma_resolve_route, rdma_listen, rdma_accept,
> > rdma_create_qp, rdma_post_send, etc....
> > 
> > My only point is that the kernel/user interface is not a straight line
> > since some of these interfaces are higher level than others.
> 
> Yes. Most of the tgt drivers (except for iSCSI tcp and iSER drivers)
> need their own in-kernel part. Oh, iSCSI hardware drivers (like
> qla4xxx) need the in-kernel part too.
> 

so you want iscsi tcp in user space as well? 

ming




From mingz at ele.uri.edu  Wed Aug  2 00:59:57 2006
From: mingz at ele.uri.edu (Ming Zhang)
Date: Tue, 01 Aug 2006 18:59:57 -0400
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <1154468290.9903.68.camel@trinity.ogc.int>
References: <1154379923.8544.4.camel@trinity.ogc.int>
	<20060801113703H.fujita.tomonori@lab.ntt.co.jp>
	<1154457764.9903.24.camel@trinity.ogc.int>
	<1154458176.2829.57.camel@localhost.localdomain>
	<1154458856.9903.27.camel@trinity.ogc.int>
	<1154463671.2829.63.camel@localhost.localdomain>
	<1154464989.9903.54.camel@trinity.ogc.int>
	<1154467473.2829.72.camel@localhost.localdomain>
	<1154468290.9903.68.camel@trinity.ogc.int>
Message-ID: <1154473197.2829.83.camel@localhost.localdomain>

On Tue, 2006-08-01 at 16:38 -0500, Tom Tucker wrote:
> On Tue, 2006-08-01 at 17:24 -0400, Ming Zhang wrote:
> > On Tue, 2006-08-01 at 15:43 -0500, Tom Tucker wrote:
> > > On Tue, 2006-08-01 at 16:21 -0400, Ming Zhang wrote:
> > > > On Tue, 2006-08-01 at 14:00 -0500, Tom Tucker wrote:
> > > > > On Tue, 2006-08-01 at 14:49 -0400, Ming Zhang wrote:
> > > > > > my 2c. u figure ignores other device types like VT/VTL or bridge. your
> > > > > > target device type are only TYPE_DISK here.
> > > > > 
> > > > > Yeah, I should put in ellipses... These types are not precluded.
> > > > > 
> > > > > >  also scsi/block/file just
> > > > > > physical media used by TYPE_DISK.
> > > > > 
> > > > > Yes, but there seemed to be some interest in exporting a file as a SCSI
> > > > > Target, or even anonymously mapped memory...
> > > > > 
> > > > > What else should we be thinking about?
> > > > 
> > > > SPI is not mentioned in your pic.
> > > 
> > > Hmm. Doesn't this sit on the target device side underneath /dev/sdN?
> > 
> > sorry but i mean SPI transport, or interface with INI.
> > 
> > > 
> > > > 
> > > > and it will be better if kernel/user space line is marked. so people
> > > > know your intention and can comment in that if need. otherwise, i saw no
> > > > difference from stgt or scst.
> > > 
> > > Attaches is a new picture with kernel/user boundaries. I think the
> > > boundary is somewhat fuzzy at the top and bottom due to the fact that
> > > the API is different for each target type and for each network provider
> > > type. 
> > > 
> > > For example, the sd driver will use open /dev/sdN and submit ioctl to
> > > read/write the disk, whereas the file target will
> > > open("/home/thisandthat", ...) and submit lseek/read/write to read/write
> > > the file.
> > > 
> > > On the network side, the TCP provider would use socket, listen, accept,
> > > send, recv (at least initially), the RMDA provider would use
> > > rdma_resolve_addr, rdma_resolve_route, rdma_listen, rdma_accept,
> > > rdma_create_qp, rdma_post_send, etc....
> > > 
> > > My only point is that the kernel/user interface is not a straight line
> > > since some of these interfaces are higher level than others.
> > 
> > so you have even all transports in user space? zero copy socket is not
> > easy. 
> 
> I think this is the area where we will need to get fancy if we want
> higher performance. To avoid the copy, we would have to migrate to
> netchannels (if they every happen) or implement our own simple tear-away
> buffer scheme on top of a socket. I think this is phase-ii, however. 

ok, otherwise copy to user space and copy back to kernel for disk = low
performance. yes, direct io can be used here, but then u lose whole
cache benefits.

> 
> How about on the target device side? How expensive/inefficient is the
> ioctl interface to /dev/sd?
> 
> > and can FCP drivers, like a target mode driver for a QLA or LSI
> > HBA can be in user space as well?
> 
> No. These will be in the kernel, but I'm not considering these drivers
> as part of this subsystem. Are they part of IET?

no IET only contain iscsi tcp transport.

you need an in-kernel target mode driver for FCP HBA. and i think this
are one type of transports.


> 
> > 
> > ming
> > 
> > 
> > > 
> > > 
> > > 
> > > > 
> > > > also license. :P what license(s) will be used and allowed for each part.
> > > > 
> > > > ming
> > > > 
> > > > 
> > > > 
> > > > > 
> > > > > > 
> > > > > > Ming
> > > > > > 
> > > > > > 
> > > > > > On Tue, 2006-08-01 at 13:42 -0500, Tom Tucker wrote:
> > > > > > > What do people think about something like this...
> > > > > > > 
> > > > > > > The target architecture is implemented to the extent possible entirely
> > > > > > > in user-mode. The architecture intends to support multiple Target Device
> > > > > > > Types, SCSI Transport Types and Network Transport Types. The enclosed
> > > > > > > figure below illustrates the components of the architecture.
> > > > > > > 
> > > > > > > At the top of the figure are the different Target Device Type Drivers.
> > > > > > > These "drivers" are implemented in user-mode as libraries and plug into
> > > > > > > the Target Interface Layer. The Target Device Type drivers each support
> > > > > > > a particular class of device. For example, the SCSI Disk Driver supports
> > > > > > > SCSI disks, the Block Device driver supports generic block devices
> > > > > > > (e.g. /dev/md0, etc..) and the File Device Driver supports files as
> > > > > > > target devices. In most cases, the Target Device Type Drivers call
> > > > > > > existing system call interfaces to communicate with the actual target
> > > > > > > device, e.g. open, close, read, write, ioctl, etc... High performance
> > > > > > > implementations may use private kernel interfaces to improve
> > > > > > > performance. 
> > > > > > > 
> > > > > > > The Target Interface Layer implements a generic target device
> > > > > > > independent API called the Target Device API, and a SCSI transport
> > > > > > > independent API called the SCSI Transport API. This Target Interface
> > > > > > > Layer implements a target/SCSI transport switch that allows any Target
> > > > > > > Device Type to be associated with any SCSI Transport Type. 
> > > > > > > 
> > > > > > > The SCSI Transport Class Drivers implement support for the various SCSI
> > > > > > > transport types: SRP Transport implements the SCSI RDMA Protocol
> > > > > > > transport, FCP Transport implements the Fiber Channel transport type,
> > > > > > > and the iSCSI Transport implements the iSCSI transport type. These
> > > > > > > drivers sit between the Target Interface Layer and the Network Interface
> > > > > > > Layer. 
> > > > > > > 
> > > > > > > The Network Interface Layer implements a SCSI transport independent API
> > > > > > > called the Transport Class API and a network transport independent API
> > > > > > > called the Transport API. The Network Interface Layer allows a SCSI
> > > > > > > Transport Class driver to support multiple network transports. For
> > > > > > > example, the iSCSI Transport driver will support TCP, IB, and iWARP as
> > > > > > > network transports. The details of a particular SCSI Transport Class's
> > > > > > > device enumeration, login and management are implemented in the SCSI
> > > > > > > Transport Class driver (e.g. iSCSI Transport). The details of a
> > > > > > > particular network transport's connection management paradigm are
> > > > > > > implemented in the Transport Provider driver (e.g. RDMA driver).
> > > > > > > 
> > > > > > > The Transport Provider Drivers implement the Transport Provider API and
> > > > > > > provide core network I/O services to the Network Interface Layer. The
> > > > > > > Transport API is a transport independent interface for creating
> > > > > > > endpoints, service points, accepting incoming connection requests and
> > > > > > > performing I/O on an endpoint.
> > > > > > > 
> > > > > > > The Management Agent interfaces with the Target Interface Layer and
> > > > > > > performs management functions such as creating targets, devices, loading
> > > > > > > and storing persistent configurations and other management related
> > > > > > > functions.
> > > > > > > 
> > > > > > > The various API referred to above are basically simplified versions of
> > > > > > > the existing scsi_transport_template, scsi_host, scsi_host_template
> > > > > > > interfaces, etc... from the current kernel implementation. The
> > > > > > > interfaces between the various components, however, can be reduced to
> > > > > > > function calls since everything resides user mode. 
> > > > > > > 
> > > > > > > I think the only tough issue here is with copy avoidance for the network
> > > > > > > user/kernel interface and target device user/kernel interfaces.
> > > > > > > Initially, these could be prototyped without regard to this issue and
> > > > > > > see what kind of performance we could get. The RDMA network transports
> > > > > > > already provide copy avoidance, however, TCP/FC would require some
> > > > > > > cleverness.
> > > > > > > 
> > > > > > > Thoughts?
> > > > > > > 
> > > > > > > _______________________________________________
> > > > > > > Stgt-devel mailing list
> > > > > > > Stgt-devel at lists.berlios.de
> > > > > > > http://bat.berlios.de/mailman/listinfo/stgt-devel
> > > > > > 
> > > > > > _______________________________________________
> > > > > > Stgt-devel mailing list
> > > > > > Stgt-devel at lists.berlios.de
> > > > > > http://bat.berlios.de/mailman/listinfo/stgt-devel
> > > > > 
> > > > > _______________________________________________
> > > > > Stgt-devel mailing list
> > > > > Stgt-devel at lists.berlios.de
> > > > > http://bat.berlios.de/mailman/listinfo/stgt-devel
> > > > 
> > > _______________________________________________
> > > Stgt-devel mailing list
> > > Stgt-devel at lists.berlios.de
> > > http://bat.berlios.de/mailman/listinfo/stgt-devel
> > 
> 
> _______________________________________________
> Stgt-devel mailing list
> Stgt-devel at lists.berlios.de
> http://bat.berlios.de/mailman/listinfo/stgt-devel



From fujita.tomonori at lab.ntt.co.jp  Wed Aug  2 01:01:18 2006
From: fujita.tomonori at lab.ntt.co.jp (FUJITA Tomonori)
Date: Wed, 02 Aug 2006 08:01:18 +0900
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <1154472989.2829.78.camel@localhost.localdomain>
References: <1154464989.9903.54.camel@trinity.ogc.int>
	<20060803065429X.fujita.tomonori@lab.ntt.co.jp>
	<1154472989.2829.78.camel@localhost.localdomain>
Message-ID: <20060802080118O.fujita.tomonori@lab.ntt.co.jp>

From: Ming Zhang <mingz at ele.uri.edu>
Subject: Re: [Stgt-devel] User-mode iSER
Date: Tue, 01 Aug 2006 18:56:29 -0400

> On Wed, 2006-08-02 at 07:21 +0900, FUJITA Tomonori wrote:
> > From: Tom Tucker <tom at opengridcomputing.com>
> > Subject: Re: [Stgt-devel] User-mode iSER
> > Date: Tue, 01 Aug 2006 15:43:09 -0500
> > 
> > > > and it will be better if kernel/user space line is marked. so people
> > > > know your intention and can comment in that if need. otherwise, i saw no
> > > > difference from stgt or scst.
> > > 
> > > Attaches is a new picture with kernel/user boundaries. I think the
> > > boundary is somewhat fuzzy at the top and bottom due to the fact that
> > > the API is different for each target type and for each network provider
> > > type. 
> > > 
> > > For example, the sd driver will use open /dev/sdN and submit ioctl to
> > > read/write the disk, whereas the file target will
> > > open("/home/thisandthat", ...) and submit lseek/read/write to read/write
> > > the file.
> > > 
> > > On the network side, the TCP provider would use socket, listen, accept,
> > > send, recv (at least initially), the RMDA provider would use
> > > rdma_resolve_addr, rdma_resolve_route, rdma_listen, rdma_accept,
> > > rdma_create_qp, rdma_post_send, etc....
> > > 
> > > My only point is that the kernel/user interface is not a straight line
> > > since some of these interfaces are higher level than others.
> > 
> > Yes. Most of the tgt drivers (except for iSCSI tcp and iSER drivers)
> > need their own in-kernel part. Oh, iSCSI hardware drivers (like
> > qla4xxx) need the in-kernel part too.
> > 
> 
> so you want iscsi tcp in user space as well? 

Please read my first mail before sending mails.


From mingz at ele.uri.edu  Wed Aug  2 01:12:16 2006
From: mingz at ele.uri.edu (Ming Zhang)
Date: Tue, 01 Aug 2006 19:12:16 -0400
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <20060803065429X.fujita.tomonori@lab.ntt.co.jp>
References: <1154458856.9903.27.camel@trinity.ogc.int>
	<1154463671.2829.63.camel@localhost.localdomain>
	<1154464989.9903.54.camel@trinity.ogc.int>
	<20060803065429X.fujita.tomonori@lab.ntt.co.jp>
Message-ID: <1154473936.2829.87.camel@localhost.localdomain>

On Wed, 2006-08-02 at 07:21 +0900, FUJITA Tomonori wrote:
> From: Tom Tucker <tom at opengridcomputing.com>
> Subject: Re: [Stgt-devel] User-mode iSER
> Date: Tue, 01 Aug 2006 15:43:09 -0500
> 
> > > and it will be better if kernel/user space line is marked. so people
> > > know your intention and can comment in that if need. otherwise, i saw no
> > > difference from stgt or scst.
> > 
> > Attaches is a new picture with kernel/user boundaries. I think the
> > boundary is somewhat fuzzy at the top and bottom due to the fact that
> > the API is different for each target type and for each network provider
> > type. 
> > 
> > For example, the sd driver will use open /dev/sdN and submit ioctl to
> > read/write the disk, whereas the file target will
> > open("/home/thisandthat", ...) and submit lseek/read/write to read/write
> > the file.
> > 
> > On the network side, the TCP provider would use socket, listen, accept,
> > send, recv (at least initially), the RMDA provider would use
> > rdma_resolve_addr, rdma_resolve_route, rdma_listen, rdma_accept,
> > rdma_create_qp, rdma_post_send, etc....
> > 
> > My only point is that the kernel/user interface is not a straight line
> > since some of these interfaces are higher level than others.
> 
> Yes. Most of the tgt drivers (except for iSCSI tcp and iSER drivers)
> need their own in-kernel part. Oh, iSCSI hardware drivers (like
> qla4xxx) need the in-kernel part too.

can we say that u want the parts that need to handle interrupt and
registers in kernel and then hand to a common user-space scsi target
layer?



> 



From tom at opengridcomputing.com  Wed Aug  2 15:54:20 2006
From: tom at opengridcomputing.com (Tom Tucker)
Date: Wed, 02 Aug 2006 08:54:20 -0500
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <1154472884.2829.76.camel@localhost.localdomain>
References: <1154463671.2829.63.camel@localhost.localdomain>
	<1154463784.9903.44.camel@trinity.ogc.int>
	<1154464270.2829.66.camel@localhost.localdomain>
	<20060803071530D.fujita.tomonori@lab.ntt.co.jp>
	<1154472884.2829.76.camel@localhost.localdomain>
Message-ID: <1154526860.11954.1.camel@trinity.ogc.int>

[...snip...]
> > 
> > Only the iSER component. The rest will be released under GPL.
> 
> then is a VT/VTL company write a target mode driver and need to link to
> this target, means it has to be GPL as well?

The code can be used either as GPL or as BSD. That's the dual part of
the license. When the code is linked with GPL code as part of a Linux
component, it is GPL. If someone wants to take the iSER code and use it
for their own purposes under a BSD license, they can do so, but they
would have to find another source for the GPL only portions of the
target.

> 
> Ming
> 
> > 
> 



From tom at opengridcomputing.com  Wed Aug  2 15:55:08 2006
From: tom at opengridcomputing.com (Tom Tucker)
Date: Wed, 02 Aug 2006 08:55:08 -0500
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <1154472989.2829.78.camel@localhost.localdomain>
References: <1154458856.9903.27.camel@trinity.ogc.int>
	<1154463671.2829.63.camel@localhost.localdomain>
	<1154464989.9903.54.camel@trinity.ogc.int>
	<20060803065429X.fujita.tomonori@lab.ntt.co.jp>
	<1154472989.2829.78.camel@localhost.localdomain>
Message-ID: <1154526908.11954.3.camel@trinity.ogc.int>


[...snip...]
> > 
> 
> so you want iscsi tcp in user space as well? 

Yes.

> 
> ming
> 
> 



From tom at opengridcomputing.com  Wed Aug  2 16:01:37 2006
From: tom at opengridcomputing.com (Tom Tucker)
Date: Wed, 02 Aug 2006 09:01:37 -0500
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <1154473197.2829.83.camel@localhost.localdomain>
References: <1154379923.8544.4.camel@trinity.ogc.int>
	<20060801113703H.fujita.tomonori@lab.ntt.co.jp>
	<1154457764.9903.24.camel@trinity.ogc.int>
	<1154458176.2829.57.camel@localhost.localdomain>
	<1154458856.9903.27.camel@trinity.ogc.int>
	<1154463671.2829.63.camel@localhost.localdomain>
	<1154464989.9903.54.camel@trinity.ogc.int>
	<1154467473.2829.72.camel@localhost.localdomain>
	<1154468290.9903.68.camel@trinity.ogc.int>
	<1154473197.2829.83.camel@localhost.localdomain>
Message-ID: <1154527297.11954.9.camel@trinity.ogc.int>

[...snip...]
> > 
> > I think this is the area where we will need to get fancy if we want
> > higher performance. To avoid the copy, we would have to migrate to
> > netchannels (if they every happen) or implement our own simple tear-away
> > buffer scheme on top of a socket. I think this is phase-ii, however. 
> 
> ok, otherwise copy to user space and copy back to kernel for disk = low
> performance. yes, direct io can be used here, but then u lose whole
> cache benefits.

Can you elaborate on the loss of "whole cache benefits". 


> you need an in-kernel target mode driver for FCP HBA. and i think this
> are one type of transports.

One possibility is to move up the kernel/user line to just above the
network provider layer and make this a zero-copy interface. This would
support zcopy for TCP, FC and RDMA. 

I don't think you would want this to be a netlink based interface,
however, I think you would want it to be a syscall (or ioctl)
interface...and this makes me worry that the Linux kernel guys wouldn't
like that.

> 
> 
> > 



From mingz at ele.uri.edu  Wed Aug  2 16:19:43 2006
From: mingz at ele.uri.edu (Ming Zhang)
Date: Wed, 02 Aug 2006 10:19:43 -0400
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <1154527297.11954.9.camel@trinity.ogc.int>
References: <1154379923.8544.4.camel@trinity.ogc.int>
	<20060801113703H.fujita.tomonori@lab.ntt.co.jp>
	<1154457764.9903.24.camel@trinity.ogc.int>
	<1154458176.2829.57.camel@localhost.localdomain>
	<1154458856.9903.27.camel@trinity.ogc.int>
	<1154463671.2829.63.camel@localhost.localdomain>
	<1154464989.9903.54.camel@trinity.ogc.int>
	<1154467473.2829.72.camel@localhost.localdomain>
	<1154468290.9903.68.camel@trinity.ogc.int>
	<1154473197.2829.83.camel@localhost.localdomain>
	<1154527297.11954.9.camel@trinity.ogc.int>
Message-ID: <1154528383.2665.5.camel@localhost.localdomain>

On Wed, 2006-08-02 at 09:01 -0500, Tom Tucker wrote:
> [...snip...]
> > > 
> > > I think this is the area where we will need to get fancy if we want
> > > higher performance. To avoid the copy, we would have to migrate to
> > > netchannels (if they every happen) or implement our own simple tear-away
> > > buffer scheme on top of a socket. I think this is phase-ii, however. 
> > 
> > ok, otherwise copy to user space and copy back to kernel for disk = low
> > performance. yes, direct io can be used here, but then u lose whole
> > cache benefits.
> 
> Can you elaborate on the loss of "whole cache benefits". 

if you use a Linux box as a storage server, it will be desired to use
page cache as storage cache. though this will bring data integrity
issues, but so many people still want to have it for specific
applications.


> 
> 
> > you need an in-kernel target mode driver for FCP HBA. and i t shink this
> > are one type of transports.
> 
> One possibility is to move up the kernel/user line to just above the
> network provider layer and make this a zero-copy interface. This would
> support zcopy for TCP, FC and RDMA. 
> 
> I don't think you would want this to be a netlink based interface,
> however, I think you would want it to be a syscall (or ioctl)
> interface...and this makes me worry that the Linux kernel guys wouldn't
> like that.

i could be wrong, in previous stgt design, the data need not to be
copied to user space. but there are needs that process/transforming data
before writing it to disk. for that, you need a zero copy for sure. as
you said, kernel guy maybe dislike both.




From mingz at ele.uri.edu  Wed Aug  2 16:24:00 2006
From: mingz at ele.uri.edu (Ming Zhang)
Date: Wed, 02 Aug 2006 10:24:00 -0400
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <1154526860.11954.1.camel@trinity.ogc.int>
References: <1154463671.2829.63.camel@localhost.localdomain>
	<1154463784.9903.44.camel@trinity.ogc.int>
	<1154464270.2829.66.camel@localhost.localdomain>
	<20060803071530D.fujita.tomonori@lab.ntt.co.jp>
	<1154472884.2829.76.camel@localhost.localdomain>
	<1154526860.11954.1.camel@trinity.ogc.int>
Message-ID: <1154528640.2665.10.camel@localhost.localdomain>

On Wed, 2006-08-02 at 08:54 -0500, Tom Tucker wrote:
> [...snip...]
> > > 
> > > Only the iSER component. The rest will be released under GPL.
> > 
> > then is a VT/VTL company write a target mode driver and need to link to
> > this target, means it has to be GPL as well?
> 
> The code can be used either as GPL or as BSD. That's the dual part of
> the license. When the code is linked with GPL code as part of a Linux
> component, it is GPL. If someone wants to take the iSER code and use it
> for their own purposes under a BSD license, they can do so, but they
> would have to find another source for the GPL only portions of the
> target.

tricky. i guess HW vendor will like this while SW vendor will not jump
in.


> 
> > 
> > Ming 
> > 
> > > 
> > 
> 



From nezhinsky at gmail.com  Wed Aug  2 16:59:46 2006
From: nezhinsky at gmail.com (Alexander Nezhinsky)
Date: Wed, 2 Aug 2006 17:59:46 +0300
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <1154528640.2665.10.camel@localhost.localdomain>
References: <1154463671.2829.63.camel@localhost.localdomain>
	<1154463784.9903.44.camel@trinity.ogc.int>
	<1154464270.2829.66.camel@localhost.localdomain>
	<20060803071530D.fujita.tomonori@lab.ntt.co.jp>
	<1154472884.2829.76.camel@localhost.localdomain>
	<1154526860.11954.1.camel@trinity.ogc.int>
	<1154528640.2665.10.camel@localhost.localdomain>
Message-ID: <5eb093080608020759s1b14a798hb762898c414b1607@mail.gmail.com>

Tom,

>* > > Attaches is a new picture with kernel/user boundaries. I think the
*>* > > boundary is somewhat fuzzy at the top and bottom due to the fact
that
*>* > > the API is different for each target type and for each network
provider
*>* > > type.
*>* > >
*>* > > For example, the sd driver will use open /dev/sdN and submit ioctl
to
*>* > > read/write the disk, whereas the file target will
*>* > > open("/home/thisandthat", ...) and submit lseek/read/write to
read/write *>* > > the file.
*>* > > *
*
Regarding your diagram. Boxes marked "SCSI Disk Driver" interfacing /dev/sdX
and "Block Device Driver" interfacing /dev/mdX are probably using the same
API. /dev/sdX are normalized to the same "Block Device" interface as
/dev/mdX. So no ioctl calls, the same open/read/write.
Did you mean that the two need different management mechanisms which should
be present in the corresponding user-space libraries?
I guess "SCSI Disk Driver" should interface /dev/sgX devices exported by sg
driver and allowing direct access to a SCSI disk. sg uses ioctl calls where
explicit scsi commands are passed. No cache will be used in this case, just
as with direct IO through a block device. And the copy issue is to be
addressed here too.
**
*>* > > On the network side, the TCP provider would use socket, listen,
accept,
*>* > > send, recv (at least initially), the RMDA provider would use
*>* > > rdma_resolve_addr, rdma_resolve_route, rdma_listen, rdma_accept,
*>* > > rdma_create_qp, rdma_post_send, etc....
*>* > >
*>* > > My only point is that the kernel/user interface is not a straight
line
*>* > > since some of these interfaces are higher level than others.
*
*As all transports interface "Network interface layer" using the same API,
then all transports should have at least a user-space driver. **While some
should also have an in-kernel part (e.g. FCP whose driver may remain intact,
plus perhaps a special adaptation driver to enable zero-copy
operation), others may do without additional kernel modules (e.g. iSER may
use user-space IB verbs).  *
*So the user-kernel line may remain where it is (under the user-space
transport drivers) with a note that some transports may need additional
boxes underneath as well.
*
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://lists.berlios.de/pipermail/stgt-devel/attachments/20060802/30d2ff58/attachment.html>

From tom at opengridcomputing.com  Wed Aug  2 17:39:21 2006
From: tom at opengridcomputing.com (Tom Tucker)
Date: Wed, 02 Aug 2006 10:39:21 -0500
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <5eb093080608020759s1b14a798hb762898c414b1607@mail.gmail.com>
References: <1154463671.2829.63.camel@localhost.localdomain>
	<1154463784.9903.44.camel@trinity.ogc.int>
	<1154464270.2829.66.camel@localhost.localdomain>
	<20060803071530D.fujita.tomonori@lab.ntt.co.jp>
	<1154472884.2829.76.camel@localhost.localdomain>
	<1154526860.11954.1.camel@trinity.ogc.int>
	<1154528640.2665.10.camel@localhost.localdomain>
	<5eb093080608020759s1b14a798hb762898c414b1607@mail.gmail.com>
Message-ID: <1154533161.11954.33.camel@trinity.ogc.int>

On Wed, 2006-08-02 at 17:59 +0300, Alexander Nezhinsky wrote:
> Tom,
>  
> > > > Attaches is a new picture with kernel/user boundaries. I think
> the
> > > > boundary is somewhat fuzzy at the top and bottom due to the fact
> that
> > > > the API is different for each target type and for each network
> provider 
> > > > type. 
> > > > 
> > > > For example, the sd driver will use open /dev/sdN and submit
> ioctl to
> > > > read/write the disk, whereas the file target will 
> > > > open("/home/thisandthat", ...) and submit lseek/read/write to
> read/write > > > the file.
> > > > 
>  
> Regarding your diagram. Boxes marked "SCSI Disk Driver"
> interfacing /dev/sdX and "Block Device Driver" interfacing /dev/mdX
> are probably using the same API. /dev/sdX are normalized to the same
> "Block Device" interface as /dev/mdX. So no ioctl calls, the
> same open/read/write. 
> Did you mean that the two need different management mechanisms which
> should be present in the corresponding user-space libraries? 
> I guess "SCSI Disk Driver" should interface /dev/sgX devices exported
> by sg driver and allowing direct access to a SCSI disk. sg uses ioctl
> calls where explicit scsi commands are passed. No cache will be used
> in this case, just as with direct IO through a block device. And the
> copy issue is to be addressed here too. 

Yes, this is what I meant. I'll fix the diagram.

> 
>   
> 
> > > > On the network side, the TCP provider would use socket, listen,
> accept,
> > > > send, recv (at least initially), the RMDA provider would use
> > > > rdma_resolve_addr, rdma_resolve_route, rdma_listen,
> rdma_accept, 
> > > > rdma_create_qp, rdma_post_send, etc....
> > > > 
> > > > My only point is that the kernel/user interface is not a
> straight line
> > > > since some of these interfaces are higher level than others. 
> As all transports interface "Network interface layer" using the same
> API, then all transports should have at least a user-space driver.
> While some should also have an in-kernel part (e.g. FCP whose driver
> may remain intact, plus perhaps a special adaptation driver to enable
> zero-copy operation), others may do without additional kernel modules
> ( e.g. iSER may use user-space IB verbs).  
> So the user-kernel line may remain where it is (under the user-space
> transport drivers) with a note that some transports may need
> additional boxes underneath as well.

Yes.




From tom at opengridcomputing.com  Wed Aug  2 17:58:40 2006
From: tom at opengridcomputing.com (Tom Tucker)
Date: Wed, 02 Aug 2006 10:58:40 -0500
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <20060803071057F.fujita.tomonori@lab.ntt.co.jp>
References: <1154379923.8544.4.camel@trinity.ogc.int>
	<20060801113703H.fujita.tomonori@lab.ntt.co.jp>
	<1154437753.31727.5.camel@trinity.ogc.int>
	<20060803071057F.fujita.tomonori@lab.ntt.co.jp>
Message-ID: <1154534320.11954.44.camel@trinity.ogc.int>

On Wed, 2006-08-02 at 07:21 +0900, FUJITA Tomonori wrote:
[...snip...]
> > 
> > Also, won't a user-mode approach support virtual target devices more
> > easily? 
> 
> There's no difference. Note that we try to push a small portion of the
> iSCSI tcp driver into kernel (iSCSI protocol processing). Both
> approaches perform SCSI protocol processing, I/O in user space.
> I think that you can easily implement any kind of vitalization, device
> vitalization (like virtual tape library) and backing vitalization
> (snapshot, encryption, compression, etc) in user space with both
> approaches.

Yes, I think this is true, in the current design, the target device I/O
is done in user space, so adding a new device type to trunk/usr is just
as easy. The event that initiates this I/O though comes from the kernel
over a netlink socket. Moving this all to user-space "might" make this
perform better and simplify the architecture.  

Do you think this is true or does it create as many problems as it
solves?

> 




From fujita.tomonori at lab.ntt.co.jp  Thu Aug  3 00:33:02 2006
From: fujita.tomonori at lab.ntt.co.jp (FUJITA Tomonori)
Date: Thu, 03 Aug 2006 07:33:02 +0900
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <1154533161.11954.33.camel@trinity.ogc.int>
References: <1154528640.2665.10.camel@localhost.localdomain>
	<5eb093080608020759s1b14a798hb762898c414b1607@mail.gmail.com>
	<1154533161.11954.33.camel@trinity.ogc.int>
Message-ID: <20060803073302V.fujita.tomonori@lab.ntt.co.jp>

From: Tom Tucker <tom at opengridcomputing.com>
Subject: Re: [Stgt-devel] User-mode iSER
Date: Wed, 02 Aug 2006 10:58:40 -0500

> On Wed, 2006-08-02 at 07:21 +0900, FUJITA Tomonori wrote:
> [...snip...]
> > > 
> > > Also, won't a user-mode approach support virtual target devices more
> > > easily? 
> > 
> > There's no difference. Note that we try to push a small portion of the
> > iSCSI tcp driver into kernel (iSCSI protocol processing). Both
> > approaches perform SCSI protocol processing, I/O in user space.
> > I think that you can easily implement any kind of vitalization, device
> > vitalization (like virtual tape library) and backing vitalization
> > (snapshot, encryption, compression, etc) in user space with both
> > approaches.
> 
> Yes, I think this is true, in the current design, the target device I/O
> is done in user space, so adding a new device type to trunk/usr is just
> as easy. The event that initiates this I/O though comes from the kernel
> over a netlink socket.

We don't use netlink because it turned out that we cannot pass
user-space pointers via netlik due to its philosophy.

The pathch to replace netlink is at:
http://marc.theaimsgroup.com/?l=linux-scsi&m=115413498823780&w=2

The reason why we cannot netlink is at:
http://lkml.org/lkml/2006/4/19/165


> Moving this all to user-space "might" make this perform better and
> simplify the architecture.
>
> Do you think this is true or does it create as many problems as it
> solves?

I'm not sure. That might be true if we think about only target drivers
that can be implemented in user-space (iSCSI tcp for generic NICs,
iSER), but we also need to support target drivers that needs in-kernel
support.

Anyway, as I said in the first mail, we don't know where iSCSI tcp for
generic NICs and iSER drivers live. So just wait for few days.


From fujita.tomonori at lab.ntt.co.jp  Thu Aug  3 03:19:18 2006
From: fujita.tomonori at lab.ntt.co.jp (FUJITA Tomonori)
Date: Thu, 03 Aug 2006 10:19:18 +0900
Subject: [Stgt-devel] project status
Message-ID: <20060803101918D.fujita.tomonori@lab.ntt.co.jp>

I tried to write up the current project status.

First, let me make a statement:

Please let us know if you know hosting for open source projects,
providing git service. We like to move everything (kernel and
user-space code) from the current subversion tree.

By the way, I've uploaded OLS tgt paper and slides.

http://stgt.berlios.de/


Here's the summary:
-----

- tgt core

-- kernel-space

It turned out that we used netlink wrongly so we replaced netlink. We
need bi-directional, high-speed interface between user and kernel
space. Currently, there isn't such interface in mainline. So we use
mapped ring buffer between kernel and user spaces by using own
character device (I need to replace the very old way to create a
character device). If we find something better, we will replace the
current code (netdev guys seems to bring something promising for
network AIO).

One issue to solve soon is a reference counting issue. The current
design allows you remove the kernel modules any time and it leads to
SCSI command (and other stuff) leak.


-- user-space

The user-space code still has junk mainly because we've redesigned tgt
several times. I've been working on it, but it's not finished.

The most urgent issue is that we need to shut down each target entity
cleanly (it is related with the above reference counting issue).

Another important issue is a configuration scheme. We expect that each
target driver has own configuration scheme and uses our management
tool, tgtadm. We need to work on this.

Fun work to adding new features includes supporting metadata disk
formats such as snapshot (CoW), SCSI bridge (like FC-iSCSI), SCSI
device emulations like Virtual Tape Library, etc. I don't have time to
implement SCSI device emulations in the near future (we don't
implement the SCSI protocol completely yet) but supporting metadata
disk formats is not difficult (and the snapshot feature is very
useful).


- target drivers

-- ibmvio

It works, though there are some issues, like OOM handling and a better
configuration scheme.

If the following Xen SCSI driver will be accepted, we have three SRP
drivers in mainline, Infiniband, IBM pSeries, Xen. So I think that
something like scsi_transport_srp would be nice.


-- Xen

I've submitted an updated version of the Xen SCSI front/back drivers
that works like ibmvio (that is, both use the SRP protocol and kinda
virtual HBA concept).

http://lists.xensource.com/archives/html/xen-devel/2006-08/msg00096.html

I've not got any responses from Xen Cambridge camp so far, so I'm not
sure whether it will go into Xen tree.


From tom at opengridcomputing.com  Thu Aug  3 05:46:38 2006
From: tom at opengridcomputing.com (Tom Tucker)
Date: Wed, 02 Aug 2006 22:46:38 -0500
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <20060803073302V.fujita.tomonori@lab.ntt.co.jp>
References: <1154528640.2665.10.camel@localhost.localdomain>
	<5eb093080608020759s1b14a798hb762898c414b1607@mail.gmail.com>
	<1154533161.11954.33.camel@trinity.ogc.int>
	<20060803073302V.fujita.tomonori@lab.ntt.co.jp>
Message-ID: <1154576798.17864.2.camel@bigtime.es335.com>

On Thu, 2006-08-03 at 07:33 +0900, FUJITA Tomonori wrote:
> From: Tom Tucker <tom at opengridcomputing.com>
> Subject: Re: [Stgt-devel] User-mode iSER
> Date: Wed, 02 Aug 2006 10:58:40 -0500
> 
> > On Wed, 2006-08-02 at 07:21 +0900, FUJITA Tomonori wrote:
> > [...snip...]
> > > > 
> > > > Also, won't a user-mode approach support virtual target devices more
> > > > easily? 
> > > 
> > > There's no difference. Note that we try to push a small portion of the
> > > iSCSI tcp driver into kernel (iSCSI protocol processing). Both
> > > approaches perform SCSI protocol processing, I/O in user space.
> > > I think that you can easily implement any kind of vitalization, device
> > > vitalization (like virtual tape library) and backing vitalization
> > > (snapshot, encryption, compression, etc) in user space with both
> > > approaches.
> > 
> > Yes, I think this is true, in the current design, the target device I/O
> > is done in user space, so adding a new device type to trunk/usr is just
> > as easy. The event that initiates this I/O though comes from the kernel
> > over a netlink socket.
> 
> We don't use netlink because it turned out that we cannot pass
> user-space pointers via netlik due to its philosophy.
> 
> The pathch to replace netlink is at:
> http://marc.theaimsgroup.com/?l=linux-scsi&m=115413498823780&w=2
> 
> The reason why we cannot netlink is at:
> http://lkml.org/lkml/2006/4/19/165
> 
Ah...my bad. I just updated and see that many things have changed. It's
looking good...

> 
> > Moving this all to user-space "might" make this perform better and
> > simplify the architecture.
> >
> > Do you think this is true or does it create as many problems as it
> > solves?
> 
> I'm not sure. That might be true if we think about only target drivers
> that can be implemented in user-space (iSCSI tcp for generic NICs,
> iSER), but we also need to support target drivers that needs in-kernel
> support.
> 
> Anyway, as I said in the first mail, we don't know where iSCSI tcp for
> generic NICs and iSER drivers live. So just wait for few days.

Sure. Thanks for the update.




From danb at voltaire.com  Thu Aug  3 10:34:33 2006
From: danb at voltaire.com (Dan Bar Dov)
Date: Thu, 3 Aug 2006 11:34:33 +0300
Subject: [Stgt-devel] User-mode iSER
Message-ID: <D4F8F0B3820E754C887699BEF26A8940014CF63A@taurus.voltaire.com>

 

> -----Original Message-----
> From: stgt-devel-bounces at lists.berlios.de 
> [mailto:stgt-devel-bounces at lists.berlios.de] On Behalf Of Ming Zhang
> Sent: Wednesday, August 02, 2006 5:20 PM
> To: Tom Tucker
> Cc: FUJITA Tomonori; stgt-devel at lists.berlios.de
> Subject: Re: [Stgt-devel] User-mode iSER
> 
> On Wed, 2006-08-02 at 09:01 -0500, Tom Tucker wrote:
> > [...snip...]
> > > > 
> > > > I think this is the area where we will need to get 
> fancy if we want
> > > > higher performance. To avoid the copy, we would have to 
> migrate to
> > > > netchannels (if they every happen) or implement our own 
> simple tear-away
> > > > buffer scheme on top of a socket. I think this is 
> phase-ii, however. 
> > > 
> > > ok, otherwise copy to user space and copy back to kernel 
> for disk = low
> > > performance. yes, direct io can be used here, but then u 
> lose whole
> > > cache benefits.
> > 
> > Can you elaborate on the loss of "whole cache benefits". 
> 
> if you use a Linux box as a storage server, it will be desired to use
> page cache as storage cache. though this will bring data integrity
> issues, but so many people still want to have it for specific
> applications.
> 

I don't think page cache as storage cache makes sense. If you look
at the networked storage, you have caching on the initiator (client) side
and you have caching on the target (storage server) side. Storage
servers usually have write-behind cache, and the better ones, have
it battery backed up for data integrity's sake. Storage admins know to
shutd down write behind caching if it is not backed up.

In linux box as storage server, write-behind implies sending a success 
response before that data is actually on the storage, and write-through 
means you don't reply until the actual storage wrote the data.

So for a write behind - the target simply needs to send a success when it 
received all the data - befor it is actually written - the page cache is not 
going to change anything regarding the timing of that respones.

If the target we plan needs to be reliable, it must support a write-through
policy since backing up the memory does not seem feasible for a home-grown 
setup. For write-through we must "really" write the data - and that means the
page cache does not give us any advantages.

For reads, a read-ahead policy can be implemented quite easy without the 
page-cache.

> 
> > 
> > 
> > > you need an in-kernel target mode driver for FCP HBA. and 
> i t shink this
> > > are one type of transports.
> > 
> > One possibility is to move up the kernel/user line to just above the
> > network provider layer and make this a zero-copy interface. 
> This would
> > support zcopy for TCP, FC and RDMA. 
> > 
> > I don't think you would want this to be a netlink based interface,
> > however, I think you would want it to be a syscall (or ioctl)
> > interface...and this makes me worry that the Linux kernel 
> guys wouldn't
> > like that.
> 
> i could be wrong, in previous stgt design, the data need not to be
> copied to user space. but there are needs that 
> process/transforming data
> before writing it to disk. for that, you need a zero copy for sure. as
> you said, kernel guy maybe dislike both.
> 
> 
> _______________________________________________
> Stgt-devel mailing list
> Stgt-devel at lists.berlios.de
> http://bat.berlios.de/mailman/listinfo/stgt-devel
> 


From mingz at ele.uri.edu  Thu Aug  3 15:12:59 2006
From: mingz at ele.uri.edu (Ming Zhang)
Date: Thu, 03 Aug 2006 09:12:59 -0400
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <D4F8F0B3820E754C887699BEF26A8940014CF63A@taurus.voltaire.com>
References: <D4F8F0B3820E754C887699BEF26A8940014CF63A@taurus.voltaire.com>
Message-ID: <1154610779.2679.9.camel@localhost.localdomain>

On Thu, 2006-08-03 at 11:34 +0300, Dan Bar Dov wrote:
>  
> > -----Original Message-----
> > From: stgt-devel-bounces at lists.berlios.de 
> > [mailto:stgt-devel-bounces at lists.berlios.de] On Behalf Of Ming Zhang
> > Sent: Wednesday, August 02, 2006 5:20 PM
> > To: Tom Tucker
> > Cc: FUJITA Tomonori; stgt-devel at lists.berlios.de
> > Subject: Re: [Stgt-devel] User-mode iSER
> > 
> > On Wed, 2006-08-02 at 09:01 -0500, Tom Tucker wrote:
> > > [...snip...]
> > > > > 
> > > > > I think this is the area where we will need to get 
> > fancy if we want
> > > > > higher performance. To avoid the copy, we would have to 
> > migrate to
> > > > > netchannels (if they every happen) or implement our own 
> > simple tear-away
> > > > > buffer scheme on top of a socket. I think this is 
> > phase-ii, however. 
> > > > 
> > > > ok, otherwise copy to user space and copy back to kernel 
> > for disk = low
> > > > performance. yes, direct io can be used here, but then u 
> > lose whole
> > > > cache benefits.
> > > 
> > > Can you elaborate on the loss of "whole cache benefits". 
> > 
> > if you use a Linux box as a storage server, it will be desired to use
> > page cache as storage cache. though this will bring data integrity
> > issues, but so many people still want to have it for specific
> > applications.
> > 
> 
> I don't think page cache as storage cache makes sense. If you look
> at the networked storage, you have caching on the initiator (client) side
> and you have caching on the target (storage server) side. Storage
> servers usually have write-behind cache, and the better ones, have
> it battery backed up for data integrity's sake. Storage admins know to
> shutd down write behind caching if it is not backed up.
> 
> In linux box as storage server, write-behind implies sending a success 
> response before that data is actually on the storage, and write-through 
> means you don't reply until the actual storage wrote the data.
> 
> So for a write behind - the target simply needs to send a success when it 
> received all the data - befor it is actually written - the page cache is not 
> going to change anything regarding the timing of that respones.
> 
> If the target we plan needs to be reliable, it must support a write-through
> policy since backing up the memory does not seem feasible for a home-grown 
> setup. For write-through we must "really" write the data - and that means the
> page cache does not give us any advantages.
> 
> For reads, a read-ahead policy can be implemented quite easy without the 
> page-cache.

so even we do not use page cache as storage cache, we still have chances
that need a read ahead buffer and write behind buffer. this question can
leave to specific target device driver developers.

for example, in IET originally only write through is provided. and later
people will find the need to use write back and propose patch for it.

ming


> 
> > 
> > > 
> > > 
> > > > you need an in-kernel target mode driver for FCP HBA. and 
> > i t shink this
> > > > are one type of transports.
> > > 
> > > One possibility is to move up the kernel/user line to just above the
> > > network provider layer and make this a zero-copy interface. 
> > This would
> > > support zcopy for TCP, FC and RDMA. 
> > > 
> > > I don't think you would want this to be a netlink based interface,
> > > however, I think you would want it to be a syscall (or ioctl)
> > > interface...and this makes me worry that the Linux kernel 
> > guys wouldn't
> > > like that.
> > 
> > i could be wrong, in previous stgt design, the data need not to be
> > copied to user space. but there are needs that 
> > process/transforming data
> > before writing it to disk. for that, you need a zero copy for sure. as
> > you said, kernel guy maybe dislike both.
> > 
> > 
> > _______________________________________________
> > Stgt-devel mailing list
> > Stgt-devel at lists.berlios.de
> > http://bat.berlios.de/mailman/listinfo/stgt-devel
> > 
> _______________________________________________
> Stgt-devel mailing list
> Stgt-devel at lists.berlios.de
> http://bat.berlios.de/mailman/listinfo/stgt-devel



From tom at opengridcomputing.com  Thu Aug  3 16:35:45 2006
From: tom at opengridcomputing.com (Tom Tucker)
Date: Thu, 03 Aug 2006 09:35:45 -0500
Subject: [Stgt-devel] project status
In-Reply-To: <20060803101918D.fujita.tomonori@lab.ntt.co.jp>
References: <20060803101918D.fujita.tomonori@lab.ntt.co.jp>
Message-ID: <1154615745.16121.27.camel@trinity.ogc.int>

[...snip...]
> It turned out that we used netlink wrongly so we replaced netlink. We
> need bi-directional, high-speed interface between user and kernel
> space. Currently, there isn't such interface in mainline. So we use
> mapped ring buffer between kernel and user spaces by using own
> character device (I need to replace the very old way to create a
> character device). If we find something better, we will replace the
> current code (netdev guys seems to bring something promising for
> network AIO).

I just looked at this code and am somewhat confused. I understand that
the write handler in the kernel has the user mode process context and
therefore understands any uspace pointer contained in the event. 

What puzzles me is that the write handler in the kernel doesn't use the
passed in buffer, but instead takes the event from an mmaped ring
buffer. It then passes the various fields in the event down to the
handlers as parameters:

	...
		err = scsi_tgt_kspace_exec(ev->u.cmd_rsp.host_no,
					   ev->u.cmd_rsp.cid,
					   ev->u.cmd_rsp.result,
					   ev->u.cmd_rsp.len,
					   ev->u.cmd_rsp.uaddr,
					   ev->u.cmd_rsp.rw);
	...
At this point, you don't need 'ev' anymore (the contents have been
copied into registers as parameters), so I don't understand the need for
the ring buffer. The user space caller could just as well have passed
you a pointer to a local variable in the write system call. Wouldn't
this avoid the complexity of the ring buffer altogether?
	
Are you just trying to avoid the copy_to_user of the ~32 bytes of the
event itself? I'd be surprised if avoiding this copy beats the time
spent managing the ring buffer. 

Sorry if these are a dumb questions...

Tom





From fujita.tomonori at lab.ntt.co.jp  Thu Aug  3 17:20:08 2006
From: fujita.tomonori at lab.ntt.co.jp (FUJITA Tomonori)
Date: Fri, 04 Aug 2006 00:20:08 +0900
Subject: [Stgt-devel] project status
In-Reply-To: <1154615745.16121.27.camel@trinity.ogc.int>
References: <20060803101918D.fujita.tomonori@lab.ntt.co.jp>
	<1154615745.16121.27.camel@trinity.ogc.int>
Message-ID: <200608031520.k73FK8Tv005931@r-dd.iij4u.or.jp>

From: Tom Tucker <tom at opengridcomputing.com>
Subject: Re: [Stgt-devel] project status
Date: Thu, 03 Aug 2006 09:35:45 -0500

> [...snip...]
> > It turned out that we used netlink wrongly so we replaced netlink. We
> > need bi-directional, high-speed interface between user and kernel
> > space. Currently, there isn't such interface in mainline. So we use
> > mapped ring buffer between kernel and user spaces by using own
> > character device (I need to replace the very old way to create a
> > character device). If we find something better, we will replace the
> > current code (netdev guys seems to bring something promising for
> > network AIO).
> 
> I just looked at this code and am somewhat confused. I understand that
> the write handler in the kernel has the user mode process context and
> therefore understands any uspace pointer contained in the event. 
> 
> What puzzles me is that the write handler in the kernel doesn't use the
> passed in buffer, but instead takes the event from an mmaped ring
> buffer. It then passes the various fields in the event down to the
> handlers as parameters:
> 
> 	...
> 		err = scsi_tgt_kspace_exec(ev->u.cmd_rsp.host_no,
> 					   ev->u.cmd_rsp.cid,
> 					   ev->u.cmd_rsp.result,
> 					   ev->u.cmd_rsp.len,
> 					   ev->u.cmd_rsp.uaddr,
> 					   ev->u.cmd_rsp.rw);
> 	...
> At this point, you don't need 'ev' anymore (the contents have been
> copied into registers as parameters), so I don't understand the need for
> the ring buffer. The user space caller could just as well have passed
> you a pointer to a local variable in the write system call. Wouldn't
> this avoid the complexity of the ring buffer altogether?

I guess that there are some reasons.

1. We are still not sure what interface we will use in the future. We
might use a different interface. So I prefered less changes.

2. As you said, we need a process context due to bio_map_user. We use
a user-space single process so this might be bottleneck. Maybe we will
need to find a way to use workqueue (kernel threads) for I/O after
performance experiments.


From fujita.tomonori at lab.ntt.co.jp  Thu Aug  3 17:20:09 2006
From: fujita.tomonori at lab.ntt.co.jp (FUJITA Tomonori)
Date: Fri, 04 Aug 2006 00:20:09 +0900
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <D4F8F0B3820E754C887699BEF26A8940014CF63A@taurus.voltaire.com>
References: <D4F8F0B3820E754C887699BEF26A8940014CF63A@taurus.voltaire.com>
Message-ID: <200608031520.k73FK9q9005936@r-dd.iij4u.or.jp>

From: "Dan Bar Dov" <danb at voltaire.com>
Subject: Re: [Stgt-devel] User-mode iSER
Date: Thu, 3 Aug 2006 11:34:33 +0300

>  
> 
> > -----Original Message-----
> > From: stgt-devel-bounces at lists.berlios.de 
> > [mailto:stgt-devel-bounces at lists.berlios.de] On Behalf Of Ming Zhang
> > Sent: Wednesday, August 02, 2006 5:20 PM
> > To: Tom Tucker
> > Cc: FUJITA Tomonori; stgt-devel at lists.berlios.de
> > Subject: Re: [Stgt-devel] User-mode iSER
> > 
> > On Wed, 2006-08-02 at 09:01 -0500, Tom Tucker wrote:
> > > [...snip...]
> > > > > 
> > > > > I think this is the area where we will need to get 
> > fancy if we want
> > > > > higher performance. To avoid the copy, we would have to 
> > migrate to
> > > > > netchannels (if they every happen) or implement our own 
> > simple tear-away
> > > > > buffer scheme on top of a socket. I think this is 
> > phase-ii, however. 
> > > > 
> > > > ok, otherwise copy to user space and copy back to kernel 
> > for disk = low
> > > > performance. yes, direct io can be used here, but then u 
> > lose whole
> > > > cache benefits.
> > > 
> > > Can you elaborate on the loss of "whole cache benefits". 
> > 
> > if you use a Linux box as a storage server, it will be desired to use
> > page cache as storage cache. though this will bring data integrity
> > issues, but so many people still want to have it for specific
> > applications.
> > 
> 
> I don't think page cache as storage cache makes sense. If you look
> at the networked storage, you have caching on the initiator (client) side
> and you have caching on the target (storage server) side. Storage
> servers usually have write-behind cache, and the better ones, have
> it battery backed up for data integrity's sake. Storage admins know to
> shutd down write behind caching if it is not backed up.

Modern operating systems and applications (like file systems) does not
need help from battery-backed memory to enjoy write-behind cache on
SAN target devices for better performance without data corruption
risks. So page cache is always useful.

Of cource, we can implement own read-ahead or more clever cache
algorithms, however we can use page cache for free.


From tom at opengridcomputing.com  Thu Aug  3 17:29:37 2006
From: tom at opengridcomputing.com (Tom Tucker)
Date: Thu, 03 Aug 2006 10:29:37 -0500
Subject: [Stgt-devel] project status
In-Reply-To: <200608031520.k73FK8Tv005931@r-dd.iij4u.or.jp>
References: <20060803101918D.fujita.tomonori@lab.ntt.co.jp>
	<1154615745.16121.27.camel@trinity.ogc.int>
	<200608031520.k73FK8Tv005931@r-dd.iij4u.or.jp>
Message-ID: <1154618977.16121.43.camel@trinity.ogc.int>

On Fri, 2006-08-04 at 00:20 +0900, FUJITA Tomonori wrote:
> From: Tom Tucker <tom at opengridcomputing.com>
> Subject: Re: [Stgt-devel] project status
> Date: Thu, 03 Aug 2006 09:35:45 -0500
> 
> > [...snip...]
> > > It turned out that we used netlink wrongly so we replaced netlink. We
> > > need bi-directional, high-speed interface between user and kernel
> > > space. Currently, there isn't such interface in mainline. So we use
> > > mapped ring buffer between kernel and user spaces by using own
> > > character device (I need to replace the very old way to create a
> > > character device). If we find something better, we will replace the
> > > current code (netdev guys seems to bring something promising for
> > > network AIO).
> > 
> > I just looked at this code and am somewhat confused. I understand that
> > the write handler in the kernel has the user mode process context and
> > therefore understands any uspace pointer contained in the event. 
> > 
> > What puzzles me is that the write handler in the kernel doesn't use the
> > passed in buffer, but instead takes the event from an mmaped ring
> > buffer. It then passes the various fields in the event down to the
> > handlers as parameters:
> > 
> > 	...
> > 		err = scsi_tgt_kspace_exec(ev->u.cmd_rsp.host_no,
> > 					   ev->u.cmd_rsp.cid,
> > 					   ev->u.cmd_rsp.result,
> > 					   ev->u.cmd_rsp.len,
> > 					   ev->u.cmd_rsp.uaddr,
> > 					   ev->u.cmd_rsp.rw);
> > 	...
> > At this point, you don't need 'ev' anymore (the contents have been
> > copied into registers as parameters), so I don't understand the need for
> > the ring buffer. The user space caller could just as well have passed
> > you a pointer to a local variable in the write system call. Wouldn't
> > this avoid the complexity of the ring buffer altogether?
> 
> I guess that there are some reasons.
> 
> 1. We are still not sure what interface we will use in the future. We
> might use a different interface. So I prefered less changes.
> 
> 2. As you said, we need a process context due to bio_map_user. We use
> a user-space single process so this might be bottleneck. Maybe we will
> need to find a way to use workqueue (kernel threads) for I/O after
> performance experiments.

Ok, thanks for the insight...







From fujita.tomonori at lab.ntt.co.jp  Thu Aug  3 19:02:28 2006
From: fujita.tomonori at lab.ntt.co.jp (FUJITA Tomonori)
Date: Fri, 04 Aug 2006 02:02:28 +0900
Subject: [Stgt-devel] project status
In-Reply-To: <200608031520.k73FK8Tv005931@r-dd.iij4u.or.jp>
References: <20060803101918D.fujita.tomonori@lab.ntt.co.jp>
	<1154615745.16121.27.camel@trinity.ogc.int>
	<200608031520.k73FK8Tv005931@r-dd.iij4u.or.jp>
Message-ID: <200608031702.k73H2Sed013026@r-dd.iij4u.or.jp>

From: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
Subject: Re: [Stgt-devel] project status
Date: Fri, 04 Aug 2006 00:20:08 +0900

> From: Tom Tucker <tom at opengridcomputing.com>
> Subject: Re: [Stgt-devel] project status
> Date: Thu, 03 Aug 2006 09:35:45 -0500
> 
> > [...snip...]
> > > It turned out that we used netlink wrongly so we replaced netlink. We
> > > need bi-directional, high-speed interface between user and kernel
> > > space. Currently, there isn't such interface in mainline. So we use
> > > mapped ring buffer between kernel and user spaces by using own
> > > character device (I need to replace the very old way to create a
> > > character device). If we find something better, we will replace the
> > > current code (netdev guys seems to bring something promising for
> > > network AIO).
> > 
> > I just looked at this code and am somewhat confused. I understand that
> > the write handler in the kernel has the user mode process context and
> > therefore understands any uspace pointer contained in the event. 
> > 
> > What puzzles me is that the write handler in the kernel doesn't use the
> > passed in buffer, but instead takes the event from an mmaped ring
> > buffer. It then passes the various fields in the event down to the
> > handlers as parameters:
> > 
> > 	...
> > 		err = scsi_tgt_kspace_exec(ev->u.cmd_rsp.host_no,
> > 					   ev->u.cmd_rsp.cid,
> > 					   ev->u.cmd_rsp.result,
> > 					   ev->u.cmd_rsp.len,
> > 					   ev->u.cmd_rsp.uaddr,
> > 					   ev->u.cmd_rsp.rw);
> > 	...
> > At this point, you don't need 'ev' anymore (the contents have been
> > copied into registers as parameters), so I don't understand the need for
> > the ring buffer. The user space caller could just as well have passed
> > you a pointer to a local variable in the write system call. Wouldn't
> > this avoid the complexity of the ring buffer altogether?
> 
> I guess that there are some reasons.
> 
> 1. We are still not sure what interface we will use in the future. We
> might use a different interface. So I prefered less changes.

This might not be clear.

What I wanted to say is that we prefer a simple and generic approach
(so that we might replace it with a possible future generic
interface). So we chose to use ring buffer in both directions. But we
are happy to move to a new interface any time as long as it is
accepted into mainline.

There is one issue related with ring buffer. Now we use a single ring
and if the ring is full (that is, the user-space daemon is too slow),
we return an error to LLDs and expect LLDs to throw away SCSI
commands. In this case, an initiator sends TMF, then if everything
goes well, we can be back to normal. However, queueing some commands
or resizing rings (at least up to the number that transport layers
accpet) would be nice. And using ring per target entity might be an
interesting approach worth considering.


> 2. As you said, we need a process context due to bio_map_user. We use
> a user-space single process so this might be bottleneck. Maybe we will
> need to find a way to use workqueue (kernel threads) for I/O after
> performance experiments.
> _______________________________________________
> Stgt-devel mailing list
> Stgt-devel at lists.berlios.de
> http://bat.berlios.de/mailman/listinfo/stgt-devel


From takiha_sabri at she.com  Fri Aug  4 10:56:26 2006
From: takiha_sabri at she.com (Mrs. Al-Takiha Sabri)
Date: Fri, 4 Aug 2006 15:56:26 +0700
Subject: [Stgt-devel] Investment assistance / Help ( From Mrs. Al-Takiha
	Sabri )
Message-ID: <20060804085629.899EA60178@bat.berlios.de>


From danb at voltaire.com  Sun Aug  6 09:59:36 2006
From: danb at voltaire.com (Dan Bar Dov)
Date: Sun, 6 Aug 2006 10:59:36 +0300
Subject: [Stgt-devel] User-mode iSER
Message-ID: <D4F8F0B3820E754C887699BEF26A8940014CF85A@taurus.voltaire.com>

 

> -----Original Message-----
> From: stgt-devel-bounces at lists.berlios.de 
> [mailto:stgt-devel-bounces at lists.berlios.de] On Behalf Of 
> FUJITA Tomonori
> Sent: Thursday, August 03, 2006 6:20 PM
> To: Dan Bar Dov
> Cc: mingz at ele.uri.edu; fujita.tomonori at lab.ntt.co.jp; 
> stgt-devel at lists.berlios.de; tom at opengridcomputing.com
> Subject: Re: [Stgt-devel] User-mode iSER
> 
> From: "Dan Bar Dov" <danb at voltaire.com>
> Subject: Re: [Stgt-devel] User-mode iSER
> Date: Thu, 3 Aug 2006 11:34:33 +0300
> 
> >  
> > 
> > > -----Original Message-----
> > > From: stgt-devel-bounces at lists.berlios.de 
> > > [mailto:stgt-devel-bounces at lists.berlios.de] On Behalf Of 
> Ming Zhang
> > > Sent: Wednesday, August 02, 2006 5:20 PM
> > > To: Tom Tucker
> > > Cc: FUJITA Tomonori; stgt-devel at lists.berlios.de
> > > Subject: Re: [Stgt-devel] User-mode iSER
> > > 
> > > On Wed, 2006-08-02 at 09:01 -0500, Tom Tucker wrote:
> > > > [...snip...]
> > > > > > 
> > > > > > I think this is the area where we will need to get 
> > > fancy if we want
> > > > > > higher performance. To avoid the copy, we would have to 
> > > migrate to
> > > > > > netchannels (if they every happen) or implement our own 
> > > simple tear-away
> > > > > > buffer scheme on top of a socket. I think this is 
> > > phase-ii, however. 
> > > > > 
> > > > > ok, otherwise copy to user space and copy back to kernel 
> > > for disk = low
> > > > > performance. yes, direct io can be used here, but then u 
> > > lose whole
> > > > > cache benefits.
> > > > 
> > > > Can you elaborate on the loss of "whole cache benefits". 
> > > 
> > > if you use a Linux box as a storage server, it will be 
> desired to use
> > > page cache as storage cache. though this will bring data integrity
> > > issues, but so many people still want to have it for specific
> > > applications.
> > > 
> > 
> > I don't think page cache as storage cache makes sense. If you look
> > at the networked storage, you have caching on the initiator 
> (client) side
> > and you have caching on the target (storage server) side. Storage
> > servers usually have write-behind cache, and the better ones, have
> > it battery backed up for data integrity's sake. Storage 
> admins know to
> > shutd down write behind caching if it is not backed up.
> 
> Modern operating systems and applications (like file systems) does not
> need help from battery-backed memory to enjoy write-behind cache on
> SAN target devices for better performance without data corruption
> risks. So page cache is always useful.

Since we are working on the SAN target, my point is we need to know if
this serving target is write-behind or not. If our code relies on page cache, 
it can not operate in any mode except write behind, however, this is
an implicit write behind. We could provide a faster response with an explicit 
write behind.

> 
> Of cource, we can implement own read-ahead or more clever cache
> algorithms, however we can use page cache for free.
> _______________________________________________
> Stgt-devel mailing list
> Stgt-devel at lists.berlios.de
> http://bat.berlios.de/mailman/listinfo/stgt-devel
> 


From fujita.tomonori at lab.ntt.co.jp  Sun Aug  6 10:05:15 2006
From: fujita.tomonori at lab.ntt.co.jp (FUJITA Tomonori)
Date: Sun, 06 Aug 2006 17:05:15 +0900
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <D4F8F0B3820E754C887699BEF26A8940014CF85A@taurus.voltaire.com>
References: <D4F8F0B3820E754C887699BEF26A8940014CF85A@taurus.voltaire.com>
Message-ID: <20060806170515S.fujita.tomonori@lab.ntt.co.jp>

From: "Dan Bar Dov" <danb at voltaire.com>
Subject: Re: [Stgt-devel] User-mode iSER
Date: Sun, 6 Aug 2006 10:59:36 +0300

>  
> 
> > -----Original Message-----
> > From: stgt-devel-bounces at lists.berlios.de 
> > [mailto:stgt-devel-bounces at lists.berlios.de] On Behalf Of 
> > FUJITA Tomonori
> > Sent: Thursday, August 03, 2006 6:20 PM
> > To: Dan Bar Dov
> > Cc: mingz at ele.uri.edu; fujita.tomonori at lab.ntt.co.jp; 
> > stgt-devel at lists.berlios.de; tom at opengridcomputing.com
> > Subject: Re: [Stgt-devel] User-mode iSER
> > 
> > From: "Dan Bar Dov" <danb at voltaire.com>
> > Subject: Re: [Stgt-devel] User-mode iSER
> > Date: Thu, 3 Aug 2006 11:34:33 +0300
> > 
> > >  
> > > 
> > > > -----Original Message-----
> > > > From: stgt-devel-bounces at lists.berlios.de 
> > > > [mailto:stgt-devel-bounces at lists.berlios.de] On Behalf Of 
> > Ming Zhang
> > > > Sent: Wednesday, August 02, 2006 5:20 PM
> > > > To: Tom Tucker
> > > > Cc: FUJITA Tomonori; stgt-devel at lists.berlios.de
> > > > Subject: Re: [Stgt-devel] User-mode iSER
> > > > 
> > > > On Wed, 2006-08-02 at 09:01 -0500, Tom Tucker wrote:
> > > > > [...snip...]
> > > > > > > 
> > > > > > > I think this is the area where we will need to get 
> > > > fancy if we want
> > > > > > > higher performance. To avoid the copy, we would have to 
> > > > migrate to
> > > > > > > netchannels (if they every happen) or implement our own 
> > > > simple tear-away
> > > > > > > buffer scheme on top of a socket. I think this is 
> > > > phase-ii, however. 
> > > > > > 
> > > > > > ok, otherwise copy to user space and copy back to kernel 
> > > > for disk = low
> > > > > > performance. yes, direct io can be used here, but then u 
> > > > lose whole
> > > > > > cache benefits.
> > > > > 
> > > > > Can you elaborate on the loss of "whole cache benefits". 
> > > > 
> > > > if you use a Linux box as a storage server, it will be 
> > desired to use
> > > > page cache as storage cache. though this will bring data integrity
> > > > issues, but so many people still want to have it for specific
> > > > applications.
> > > > 
> > > 
> > > I don't think page cache as storage cache makes sense. If you look
> > > at the networked storage, you have caching on the initiator 
> > (client) side
> > > and you have caching on the target (storage server) side. Storage
> > > servers usually have write-behind cache, and the better ones, have
> > > it battery backed up for data integrity's sake. Storage 
> > admins know to
> > > shutd down write behind caching if it is not backed up.
> > 
> > Modern operating systems and applications (like file systems) does not
> > need help from battery-backed memory to enjoy write-behind cache on
> > SAN target devices for better performance without data corruption
> > risks. So page cache is always useful.
> 
> Since we are working on the SAN target, my point is we need to know if
> this serving target is write-behind or not. If our code relies on page cache, 
> it can not operate in any mode except write behind, however, this is
> an implicit write behind. We could provide a faster response with an explicit 
> write behind.

Sorry, I'm not sure what you mean. What does 'an implicit write
behind' mean?


From danb at voltaire.com  Sun Aug  6 10:44:31 2006
From: danb at voltaire.com (Dan Bar Dov)
Date: Sun, 6 Aug 2006 11:44:31 +0300
Subject: [Stgt-devel] User-mode iSER
Message-ID: <D4F8F0B3820E754C887699BEF26A8940014CF87F@taurus.voltaire.com>

 

> -----Original Message-----
> From: stgt-devel-bounces at lists.berlios.de 
> [mailto:stgt-devel-bounces at lists.berlios.de] On Behalf Of 
> FUJITA Tomonori
> Sent: Sunday, August 06, 2006 11:05 AM
> To: Dan Bar Dov
> Cc: fujita.tomonori at lab.ntt.co.jp; mingz at ele.uri.edu; 
> stgt-devel at lists.berlios.de; tom at opengridcomputing.com
> Subject: Re: [Stgt-devel] User-mode iSER
> 
> From: "Dan Bar Dov" <danb at voltaire.com>
> Subject: Re: [Stgt-devel] User-mode iSER
> Date: Sun, 6 Aug 2006 10:59:36 +0300
> 
> >  
> > 
> > > -----Original Message-----
> > > From: stgt-devel-bounces at lists.berlios.de 
> > > [mailto:stgt-devel-bounces at lists.berlios.de] On Behalf Of 
> > > FUJITA Tomonori
> > > Sent: Thursday, August 03, 2006 6:20 PM
> > > To: Dan Bar Dov
> > > Cc: mingz at ele.uri.edu; fujita.tomonori at lab.ntt.co.jp; 
> > > stgt-devel at lists.berlios.de; tom at opengridcomputing.com
> > > Subject: Re: [Stgt-devel] User-mode iSER
> > > 
> > > From: "Dan Bar Dov" <danb at voltaire.com>
> > > Subject: Re: [Stgt-devel] User-mode iSER
> > > Date: Thu, 3 Aug 2006 11:34:33 +0300
> > > 
> > > >  
> > > > 
> > > > > -----Original Message-----
> > > > > From: stgt-devel-bounces at lists.berlios.de 
> > > > > [mailto:stgt-devel-bounces at lists.berlios.de] On Behalf Of 
> > > Ming Zhang
> > > > > Sent: Wednesday, August 02, 2006 5:20 PM
> > > > > To: Tom Tucker
> > > > > Cc: FUJITA Tomonori; stgt-devel at lists.berlios.de
> > > > > Subject: Re: [Stgt-devel] User-mode iSER
> > > > > 
> > > > > On Wed, 2006-08-02 at 09:01 -0500, Tom Tucker wrote:
> > > > > > [...snip...]
> > > > > > > > 
> > > > > > > > I think this is the area where we will need to get 
> > > > > fancy if we want
> > > > > > > > higher performance. To avoid the copy, we would have to 
> > > > > migrate to
> > > > > > > > netchannels (if they every happen) or implement our own 
> > > > > simple tear-away
> > > > > > > > buffer scheme on top of a socket. I think this is 
> > > > > phase-ii, however. 
> > > > > > > 
> > > > > > > ok, otherwise copy to user space and copy back to kernel 
> > > > > for disk = low
> > > > > > > performance. yes, direct io can be used here, but then u 
> > > > > lose whole
> > > > > > > cache benefits.
> > > > > > 
> > > > > > Can you elaborate on the loss of "whole cache benefits". 
> > > > > 
> > > > > if you use a Linux box as a storage server, it will be 
> > > desired to use
> > > > > page cache as storage cache. though this will bring 
> data integrity
> > > > > issues, but so many people still want to have it for specific
> > > > > applications.
> > > > > 
> > > > 
> > > > I don't think page cache as storage cache makes sense. 
> If you look
> > > > at the networked storage, you have caching on the initiator 
> > > (client) side
> > > > and you have caching on the target (storage server) 
> side. Storage
> > > > servers usually have write-behind cache, and the better 
> ones, have
> > > > it battery backed up for data integrity's sake. Storage 
> > > admins know to
> > > > shutd down write behind caching if it is not backed up.
> > > 
> > > Modern operating systems and applications (like file 
> systems) does not
> > > need help from battery-backed memory to enjoy 
> write-behind cache on
> > > SAN target devices for better performance without data corruption
> > > risks. So page cache is always useful.
> > 
> > Since we are working on the SAN target, my point is we need 
> to know if
> > this serving target is write-behind or not. If our code 
> relies on page cache, 
> > it can not operate in any mode except write behind, however, this is
> > an implicit write behind. We could provide a faster 
> response with an explicit 
> > write behind.
> 
> Sorry, I'm not sure what you mean. What does 'an implicit write
> behind' mean?

It means that the target sends a response because from the target's code
point of view it wrote the data to storage, but since you use page cache, 
the data didn't actually get to storage.  The target code thinks it did a write-
through, but it actually got a write behind. 
An explicit write-behind would let the target send a response *before* it
wrote the data anywhere (even buffer cache). This explicit write behind is 
therefore faster.


> _______________________________________________
> Stgt-devel mailing list
> Stgt-devel at lists.berlios.de
> http://bat.berlios.de/mailman/listinfo/stgt-devel
> 


From fujita.tomonori at lab.ntt.co.jp  Sun Aug  6 10:58:19 2006
From: fujita.tomonori at lab.ntt.co.jp (FUJITA Tomonori)
Date: Sun, 06 Aug 2006 17:58:19 +0900
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <D4F8F0B3820E754C887699BEF26A8940014CF87F@taurus.voltaire.com>
References: <D4F8F0B3820E754C887699BEF26A8940014CF87F@taurus.voltaire.com>
Message-ID: <20060806175819I.fujita.tomonori@lab.ntt.co.jp>

From: "Dan Bar Dov" <danb at voltaire.com>
Subject: RE: [Stgt-devel] User-mode iSER
Date: Sun, 6 Aug 2006 11:44:31 +0300

>  
> 
> > -----Original Message-----
> > From: stgt-devel-bounces at lists.berlios.de 
> > [mailto:stgt-devel-bounces at lists.berlios.de] On Behalf Of 
> > FUJITA Tomonori
> > Sent: Sunday, August 06, 2006 11:05 AM
> > To: Dan Bar Dov
> > Cc: fujita.tomonori at lab.ntt.co.jp; mingz at ele.uri.edu; 
> > stgt-devel at lists.berlios.de; tom at opengridcomputing.com
> > Subject: Re: [Stgt-devel] User-mode iSER
> > 
> > From: "Dan Bar Dov" <danb at voltaire.com>
> > Subject: Re: [Stgt-devel] User-mode iSER
> > Date: Sun, 6 Aug 2006 10:59:36 +0300
> > 
> > >  
> > > 
> > > > -----Original Message-----
> > > > From: stgt-devel-bounces at lists.berlios.de 
> > > > [mailto:stgt-devel-bounces at lists.berlios.de] On Behalf Of 
> > > > FUJITA Tomonori
> > > > Sent: Thursday, August 03, 2006 6:20 PM
> > > > To: Dan Bar Dov
> > > > Cc: mingz at ele.uri.edu; fujita.tomonori at lab.ntt.co.jp; 
> > > > stgt-devel at lists.berlios.de; tom at opengridcomputing.com
> > > > Subject: Re: [Stgt-devel] User-mode iSER
> > > > 
> > > > From: "Dan Bar Dov" <danb at voltaire.com>
> > > > Subject: Re: [Stgt-devel] User-mode iSER
> > > > Date: Thu, 3 Aug 2006 11:34:33 +0300
> > > > 
> > > > >  
> > > > > 
> > > > > > -----Original Message-----
> > > > > > From: stgt-devel-bounces at lists.berlios.de 
> > > > > > [mailto:stgt-devel-bounces at lists.berlios.de] On Behalf Of 
> > > > Ming Zhang
> > > > > > Sent: Wednesday, August 02, 2006 5:20 PM
> > > > > > To: Tom Tucker
> > > > > > Cc: FUJITA Tomonori; stgt-devel at lists.berlios.de
> > > > > > Subject: Re: [Stgt-devel] User-mode iSER
> > > > > > 
> > > > > > On Wed, 2006-08-02 at 09:01 -0500, Tom Tucker wrote:
> > > > > > > [...snip...]
> > > > > > > > > 
> > > > > > > > > I think this is the area where we will need to get 
> > > > > > fancy if we want
> > > > > > > > > higher performance. To avoid the copy, we would have to 
> > > > > > migrate to
> > > > > > > > > netchannels (if they every happen) or implement our own 
> > > > > > simple tear-away
> > > > > > > > > buffer scheme on top of a socket. I think this is 
> > > > > > phase-ii, however. 
> > > > > > > > 
> > > > > > > > ok, otherwise copy to user space and copy back to kernel 
> > > > > > for disk = low
> > > > > > > > performance. yes, direct io can be used here, but then u 
> > > > > > lose whole
> > > > > > > > cache benefits.
> > > > > > > 
> > > > > > > Can you elaborate on the loss of "whole cache benefits". 
> > > > > > 
> > > > > > if you use a Linux box as a storage server, it will be 
> > > > desired to use
> > > > > > page cache as storage cache. though this will bring 
> > data integrity
> > > > > > issues, but so many people still want to have it for specific
> > > > > > applications.
> > > > > > 
> > > > > 
> > > > > I don't think page cache as storage cache makes sense. 
> > If you look
> > > > > at the networked storage, you have caching on the initiator 
> > > > (client) side
> > > > > and you have caching on the target (storage server) 
> > side. Storage
> > > > > servers usually have write-behind cache, and the better 
> > ones, have
> > > > > it battery backed up for data integrity's sake. Storage 
> > > > admins know to
> > > > > shutd down write behind caching if it is not backed up.
> > > > 
> > > > Modern operating systems and applications (like file 
> > systems) does not
> > > > need help from battery-backed memory to enjoy 
> > write-behind cache on
> > > > SAN target devices for better performance without data corruption
> > > > risks. So page cache is always useful.
> > > 
> > > Since we are working on the SAN target, my point is we need 
> > to know if
> > > this serving target is write-behind or not. If our code 
> > relies on page cache, 
> > > it can not operate in any mode except write behind, however, this is
> > > an implicit write behind. We could provide a faster 
> > response with an explicit 
> > > write behind.
> > 
> > Sorry, I'm not sure what you mean. What does 'an implicit write
> > behind' mean?
>
> It means that the target sends a response because from the target's
> code point of view it wrote the data to storage, but since you use
> page cache, the data didn't actually get to storage.  The target
> code thinks it did a write- through, but it actually got a write
> behind.

Why does the target code think that it did a write-though?

tgt thinks that it does a write-back. The initiators can use
SYNCHRONIZE_CACHE, ordering write, etc for data integrity. And when
the target code is asked to write the data to storage permanently, we
can use fsync, msync, etc.


> An explicit write-behind would let the target send a response
> *before* it wrote the data anywhere (even buffer cache). This
> explicit write behind is therefore faster.


From danb at voltaire.com  Sun Aug  6 11:02:00 2006
From: danb at voltaire.com (Dan Bar Dov)
Date: Sun, 6 Aug 2006 12:02:00 +0300
Subject: [Stgt-devel] User-mode iSER
Message-ID: <D4F8F0B3820E754C887699BEF26A8940014CF8A9@taurus.voltaire.com>

 

> -----Original Message-----
> From: FUJITA Tomonori [mailto:fujita.tomonori at lab.ntt.co.jp] 
> Sent: Sunday, August 06, 2006 11:58 AM
> To: Dan Bar Dov
> Cc: fujita.tomonori at lab.ntt.co.jp; mingz at ele.uri.edu; 
> stgt-devel at lists.berlios.de; tom at opengridcomputing.com
> Subject: RE: [Stgt-devel] User-mode iSER
> 
> From: "Dan Bar Dov" <danb at voltaire.com>
> Subject: RE: [Stgt-devel] User-mode iSER
> Date: Sun, 6 Aug 2006 11:44:31 +0300
> 
> >  
> > 
> > > -----Original Message-----
> > > From: stgt-devel-bounces at lists.berlios.de 
> > > [mailto:stgt-devel-bounces at lists.berlios.de] On Behalf Of 
> > > FUJITA Tomonori
> > > Sent: Sunday, August 06, 2006 11:05 AM
> > > To: Dan Bar Dov
> > > Cc: fujita.tomonori at lab.ntt.co.jp; mingz at ele.uri.edu; 
> > > stgt-devel at lists.berlios.de; tom at opengridcomputing.com
> > > Subject: Re: [Stgt-devel] User-mode iSER
> > > 
> > > From: "Dan Bar Dov" <danb at voltaire.com>
> > > Subject: Re: [Stgt-devel] User-mode iSER
> > > Date: Sun, 6 Aug 2006 10:59:36 +0300
> > > 
> > > >  
> > > > 
> > > > > -----Original Message-----
> > > > > From: stgt-devel-bounces at lists.berlios.de 
> > > > > [mailto:stgt-devel-bounces at lists.berlios.de] On Behalf Of 
> > > > > FUJITA Tomonori
> > > > > Sent: Thursday, August 03, 2006 6:20 PM
> > > > > To: Dan Bar Dov
> > > > > Cc: mingz at ele.uri.edu; fujita.tomonori at lab.ntt.co.jp; 
> > > > > stgt-devel at lists.berlios.de; tom at opengridcomputing.com
> > > > > Subject: Re: [Stgt-devel] User-mode iSER
> > > > > 
> > > > > From: "Dan Bar Dov" <danb at voltaire.com>
> > > > > Subject: Re: [Stgt-devel] User-mode iSER
> > > > > Date: Thu, 3 Aug 2006 11:34:33 +0300
> > > > > 
> > > > > >  
> > > > > > 
> > > > > > > -----Original Message-----
> > > > > > > From: stgt-devel-bounces at lists.berlios.de 
> > > > > > > [mailto:stgt-devel-bounces at lists.berlios.de] On Behalf Of 
> > > > > Ming Zhang
> > > > > > > Sent: Wednesday, August 02, 2006 5:20 PM
> > > > > > > To: Tom Tucker
> > > > > > > Cc: FUJITA Tomonori; stgt-devel at lists.berlios.de
> > > > > > > Subject: Re: [Stgt-devel] User-mode iSER
> > > > > > > 
> > > > > > > On Wed, 2006-08-02 at 09:01 -0500, Tom Tucker wrote:
> > > > > > > > [...snip...]
> > > > > > > > > > 
> > > > > > > > > > I think this is the area where we will need to get 
> > > > > > > fancy if we want
> > > > > > > > > > higher performance. To avoid the copy, we 
> would have to 
> > > > > > > migrate to
> > > > > > > > > > netchannels (if they every happen) or 
> implement our own 
> > > > > > > simple tear-away
> > > > > > > > > > buffer scheme on top of a socket. I think this is 
> > > > > > > phase-ii, however. 
> > > > > > > > > 
> > > > > > > > > ok, otherwise copy to user space and copy 
> back to kernel 
> > > > > > > for disk = low
> > > > > > > > > performance. yes, direct io can be used here, 
> but then u 
> > > > > > > lose whole
> > > > > > > > > cache benefits.
> > > > > > > > 
> > > > > > > > Can you elaborate on the loss of "whole cache 
> benefits". 
> > > > > > > 
> > > > > > > if you use a Linux box as a storage server, it will be 
> > > > > desired to use
> > > > > > > page cache as storage cache. though this will bring 
> > > data integrity
> > > > > > > issues, but so many people still want to have it 
> for specific
> > > > > > > applications.
> > > > > > > 
> > > > > > 
> > > > > > I don't think page cache as storage cache makes sense. 
> > > If you look
> > > > > > at the networked storage, you have caching on the initiator 
> > > > > (client) side
> > > > > > and you have caching on the target (storage server) 
> > > side. Storage
> > > > > > servers usually have write-behind cache, and the better 
> > > ones, have
> > > > > > it battery backed up for data integrity's sake. Storage 
> > > > > admins know to
> > > > > > shutd down write behind caching if it is not backed up.
> > > > > 
> > > > > Modern operating systems and applications (like file 
> > > systems) does not
> > > > > need help from battery-backed memory to enjoy 
> > > write-behind cache on
> > > > > SAN target devices for better performance without 
> data corruption
> > > > > risks. So page cache is always useful.
> > > > 
> > > > Since we are working on the SAN target, my point is we need 
> > > to know if
> > > > this serving target is write-behind or not. If our code 
> > > relies on page cache, 
> > > > it can not operate in any mode except write behind, 
> however, this is
> > > > an implicit write behind. We could provide a faster 
> > > response with an explicit 
> > > > write behind.
> > > 
> > > Sorry, I'm not sure what you mean. What does 'an implicit write
> > > behind' mean?
> >
> > It means that the target sends a response because from the target's
> > code point of view it wrote the data to storage, but since you use
> > page cache, the data didn't actually get to storage.  The target
> > code thinks it did a write- through, but it actually got a write
> > behind.
> 
> Why does the target code think that it did a write-though?
> 
> tgt thinks that it does a write-back. The initiators can use
> SYNCHRONIZE_CACHE, ordering write, etc for data integrity. And when
> the target code is asked to write the data to storage permanently, we
> can use fsync, msync, etc.

That would work.

Dan

> 
> 
> > An explicit write-behind would let the target send a response
> > *before* it wrote the data anywhere (even buffer cache). This
> > explicit write behind is therefore faster.
> 


From nezhinsky at gmail.com  Sun Aug  6 13:00:02 2006
From: nezhinsky at gmail.com (Alexander Nezhinsky)
Date: Sun, 6 Aug 2006 14:00:02 +0300
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <20060806175819I.fujita.tomonori@lab.ntt.co.jp>
References: <D4F8F0B3820E754C887699BEF26A8940014CF87F@taurus.voltaire.com>
	<20060806175819I.fujita.tomonori@lab.ntt.co.jp>
Message-ID: <5eb093080608060400m1ab5934ajf884f12e16341ad6@mail.gmail.com>

> tgt thinks that it does a write-back. The initiators can use
> SYNCHRONIZE_CACHE, ordering write, etc for data integrity. And when
> the target code is asked to write the data to storage permanently, we
> can use fsync, msync, etc.


As far as I understand, SYNCHRONIZE_CACHE command is not intended as a tool
to be used by the initiators to avoid possible cache-related data
corruption. It rather should be used "to ensure that the data was written
and any detected errors reported" (citation from SBC-2 spec).
In case of power-off, h/w failures etc. the target should guarantee that all
cached data are written to the medium (or backed up, saved etc.)  regardless
of the initiator's actions.
At some points (presumably related to application semantics) initiator may
be interested to receive either success status or all possible errors
resulting from the actual I/O, but this command should not be used to
guarantee data integrity.


> > > > > Modern operating systems and applications

> > (like file systems) does not
> > > > > need help from battery-backed memory to enjoy
> > > write-behind cache on
> > > > > SAN target devices for better performance without data corruption
> > > > > risks. So page cache is always useful.
> > > >


How does linux cope with this? I never saw anything that "funky" in the scsi
command logs sent by a linux initiator.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://lists.berlios.de/pipermail/stgt-devel/attachments/20060806/f5c2a21b/attachment.html>

From fujita.tomonori at lab.ntt.co.jp  Sun Aug  6 15:48:50 2006
From: fujita.tomonori at lab.ntt.co.jp (FUJITA Tomonori)
Date: Sun, 06 Aug 2006 22:48:50 +0900
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <5eb093080608060400m1ab5934ajf884f12e16341ad6@mail.gmail.com>
References: <D4F8F0B3820E754C887699BEF26A8940014CF87F@taurus.voltaire.com>
	<20060806175819I.fujita.tomonori@lab.ntt.co.jp>
	<5eb093080608060400m1ab5934ajf884f12e16341ad6@mail.gmail.com>
Message-ID: <200608061348.k76DmphJ010336@r-dd.iij4u.or.jp>

From: "Alexander Nezhinsky" <nezhinsky at gmail.com>
Subject: Re: [Stgt-devel] User-mode iSER
Date: Sun, 6 Aug 2006 14:00:02 +0300

> > tgt thinks that it does a write-back. The initiators can use
> > SYNCHRONIZE_CACHE, ordering write, etc for data integrity. And when
> > the target code is asked to write the data to storage permanently, we
> > can use fsync, msync, etc.
> 
> 
> As far as I understand, SYNCHRONIZE_CACHE command is not intended as a tool
> to be used by the initiators to avoid possible cache-related data
> corruption. It rather should be used "to ensure that the data was written
> and any detected errors reported" (citation from SBC-2 spec).
> In case of power-off, h/w failures etc. the target should guarantee that all
> cached data are written to the medium (or backed up, saved etc.)  regardless
> of the initiator's actions.
> At some points (presumably related to application semantics) initiator may
> be interested to receive either success status or all possible errors
> resulting from the actual I/O, but this command should not be used to
> guarantee data integrity.
> 
> 
> > > > > > Modern operating systems and applications
> 
> > > (like file systems) does not
> > > > > > need help from battery-backed memory to enjoy
> > > > write-behind cache on
> > > > > > SAN target devices for better performance without data corruption
> > > > > > risks. So page cache is always useful.
> > > > >
> 
> 
> How does linux cope with this? I never saw anything that "funky" in the scsi
> command logs sent by a linux initiator.

Interesting. I just created one file on ext3 with iSCSI and saw
several SYNCHRONIZE_CACHE commands. :)

For your convenience, I've put the tcpdump log.

http://zaal.org/cache.cap


For further information, see:

Documentation/block/barrier.txt


From nezhinsky at gmail.com  Sun Aug  6 19:41:16 2006
From: nezhinsky at gmail.com (Alexander Nezhinsky)
Date: Sun, 6 Aug 2006 20:41:16 +0300
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <200608061348.k76DmphJ010336@r-dd.iij4u.or.jp>
References: <D4F8F0B3820E754C887699BEF26A8940014CF87F@taurus.voltaire.com>
	<20060806175819I.fujita.tomonori@lab.ntt.co.jp>
	<5eb093080608060400m1ab5934ajf884f12e16341ad6@mail.gmail.com>
	<200608061348.k76DmphJ010336@r-dd.iij4u.or.jp>
Message-ID: <5eb093080608061041r2d824819i989027d93b73dcd6@mail.gmail.com>

 Fujita,



> For further information, see:
> Documentation/block/barrier.txt


 First of all, thanx for the reference.


> As far as I understand, SYNCHRONIZE_CACHE command is not intended as a
> tool
> > to be used by the initiators to avoid possible cache-related data
> > corruption. It rather should be used "to ensure that the data was
> written
> > and any detected errors reported" (citation from SBC-2 spec).
> > In case of power-off, h/w failures etc. the target should guarantee that
> all
> > cached data are written to the medium (or backed up, saved
> etc.)  regardless
> > of the initiator's actions.
> > At some points (presumably related to application semantics) initiator
> may
> > be interested to receive either success status or all possible errors
> > resulting from the actual I/O, but this command should not be used to
> > guarantee data integrity.
> >
> >
> > > > > > > Modern operating systems and applications
> >
> > > > (like file systems) does not
> > > > > > > need help from battery-backed memory to enjoy
> > > > > write-behind cache on
> > > > > > > SAN target devices for better performance without data
> corruption
> > > > > > > risks. So page cache is always useful.
> > > > > >
> >
> >
> > How does linux cope with this? I never saw anything that "funky" in the
> scsi
> > command logs sent by a linux initiator.
>
> Interesting. I just created one file on ext3 with iSCSI and saw
> several SYNCHRONIZE_CACHE commands. :)
>
> For your convenience, I've put the tcpdump log.
>
> http://zaal.org/cache.cap


After playing a bit with our system i understood why we don't see
SYNCHRONIZE_CACHE
commnds. All our disks are reported "write-through". So there is no need to
sync cache.

But anyway, I meant primarily the modes of operation that are not
file-system related.
For example, with etx3 sync'ing the journal is clearly  the kind of
"application-related" operation that needs an explicit flush/barrier.
My question was mainly related to the cases when no such need occurs
naturally.
What if the user works with the raw unpartitioned device -- does he still
get a guarantee of correct operation under failures? And if it is done
through sg driver (not through the block device subsystem)?
Do you imply that if the devices are reported as write-back (plus capable of
performing flushes etc) then the problem is solved even if the cache is
de-facto volatile?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://lists.berlios.de/pipermail/stgt-devel/attachments/20060806/bcc2f64b/attachment.html>

From fujita.tomonori at lab.ntt.co.jp  Mon Aug  7 00:25:50 2006
From: fujita.tomonori at lab.ntt.co.jp (FUJITA Tomonori)
Date: Mon, 07 Aug 2006 07:25:50 +0900
Subject: [Stgt-devel] User-mode iSER
In-Reply-To: <5eb093080608061041r2d824819i989027d93b73dcd6@mail.gmail.com>
References: <5eb093080608060400m1ab5934ajf884f12e16341ad6@mail.gmail.com>
	<200608061348.k76DmphJ010336@r-dd.iij4u.or.jp>
	<5eb093080608061041r2d824819i989027d93b73dcd6@mail.gmail.com>
Message-ID: <20060807072550R.fujita.tomonori@lab.ntt.co.jp>

From: "Alexander Nezhinsky" <nezhinsky at gmail.com>
Subject: Re: [Stgt-devel] User-mode iSER
Date: Sun, 6 Aug 2006 20:41:16 +0300

> But anyway, I meant primarily the modes of operation that are not
> file-system related.
> For example, with etx3 sync'ing the journal is clearly  the kind of
> "application-related" operation that needs an explicit flush/barrier.
> My question was mainly related to the cases when no such need occurs
> naturally.
> What if the user works with the raw unpartitioned device -- does he still
> get a guarantee of correct operation under failures? And if it is done
> through sg driver (not through the block device subsystem)?
> Do you imply that if the devices are reported as write-back (plus capable of
> performing flushes etc) then the problem is solved even if the cache is
> de-facto volatile?

As I said in the first mail, modern applications can enjoy writeback
cache. If your applications are not modern, that is, does not know a
proper way to use writeback cache, just configure your disc drive to
use write-through.


By the way, please don't use html mails. I will not reply next time.


From tom at opengridcomputing.com  Fri Aug 18 17:06:43 2006
From: tom at opengridcomputing.com (Tom Tucker)
Date: Fri, 18 Aug 2006 10:06:43 -0500
Subject: [Stgt-devel] Current SVN
Message-ID: <1155913603.22828.27.camel@trinity.ogc.int>

Tomo:

It looks like in the most recent svn repo (532) you moved all of the
core changes from the svn tree to the patchset against the git tree.
This is cool, but the makefile still attempts to build ./kernel from the
svn tree which contains old code -- and not unexpectedly breaks. I think
you need to remove the "make -C kernel" from the root Makefile.

Thanks,
Tom




From fujita.tomonori at lab.ntt.co.jp  Sun Aug 20 21:03:36 2006
From: fujita.tomonori at lab.ntt.co.jp (FUJITA Tomonori)
Date: Mon, 21 Aug 2006 04:03:36 +0900
Subject: [Stgt-devel] Current SVN
In-Reply-To: <1155913603.22828.27.camel@trinity.ogc.int>
References: <1155913603.22828.27.camel@trinity.ogc.int>
Message-ID: <200608201903.k7KJ3cGT016589@r-dd.iij4u.or.jp>

From: Tom Tucker <tom at opengridcomputing.com>
Subject: [Stgt-devel] Current SVN
Date: Fri, 18 Aug 2006 10:06:43 -0500

> Tomo:
> 
> It looks like in the most recent svn repo (532) you moved all of the
> core changes from the svn tree to the patchset against the git tree.
> This is cool, but the makefile still attempts to build ./kernel from the
> svn tree which contains old code -- and not unexpectedly breaks. I think
> you need to remove the "make -C kernel" from the root Makefile.

Yep. I fixed it. Thanks.

Maybe it would be better to remove kernel code in svn to avoid
confusion. Probabaly, we will do when the git tree is ready.


By the way, I've tried the user-space iSCSI target code exploiting
user-space tgt code. I can make an ext2 file system with open-iscsi,
however, It's far from completion. I just wanted to see how things
work. We are still not sure where the Linux iSCSI target code lives
(user or kernel).

svn+ssh://svn.berlios.de/svnroot/repos/stgt/branches/user-iscsi


From tom at opengridcomputing.com  Mon Aug 21 08:39:44 2006
From: tom at opengridcomputing.com (Tom Tucker)
Date: Mon, 21 Aug 2006 01:39:44 -0500
Subject: [Stgt-devel] Current SVN
In-Reply-To: <200608201903.k7KJ3cGT016589@r-dd.iij4u.or.jp>
References: <1155913603.22828.27.camel@trinity.ogc.int>
	<200608201903.k7KJ3cGT016589@r-dd.iij4u.or.jp>
Message-ID: <1156142384.4844.6.camel@bigtime.es335.com>

On Mon, 2006-08-21 at 04:03 +0900, FUJITA Tomonori wrote:
> From: Tom Tucker <tom at opengridcomputing.com>
> Subject: [Stgt-devel] Current SVN
> Date: Fri, 18 Aug 2006 10:06:43 -0500
> 
> > Tomo:
> > 
> > It looks like in the most recent svn repo (532) you moved all of the
> > core changes from the svn tree to the patchset against the git tree.
> > This is cool, but the makefile still attempts to build ./kernel from the
> > svn tree which contains old code -- and not unexpectedly breaks. I think
> > you need to remove the "make -C kernel" from the root Makefile.
> 
> Yep. I fixed it. Thanks.
> 
No problem.

> Maybe it would be better to remove kernel code in svn to avoid
> confusion. Probabaly, we will do when the git tree is ready.
> 

Yeah, this would be great.

> 
> By the way, I've tried the user-space iSCSI target code exploiting
> user-space tgt code. I can make an ext2 file system with open-iscsi,
> however, It's far from completion. I just wanted to see how things
> work. We are still not sure where the Linux iSCSI target code lives
> (user or kernel).

BTW, I'll send an updated patch tomorrow that allows multiple transports
under iSCSI. If you could take a look and comment, that would be great.
It's basically all user-mode code that abstracts out listen/accept/poll
so we can put in separate implementations for TCP vs. RDMA. Unlike the
first patch, it will allow the sockets implementation to be in user-mode
for login just like it is now.


> 
> svn+ssh://svn.berlios.de/svnroot/repos/stgt/branches/user-iscsi


From fujita.tomonori at lab.ntt.co.jp  Mon Aug 21 04:01:06 2006
From: fujita.tomonori at lab.ntt.co.jp (FUJITA Tomonori)
Date: Mon, 21 Aug 2006 11:01:06 +0900
Subject: [Stgt-devel] Current SVN
In-Reply-To: <1156142384.4844.6.camel@bigtime.es335.com>
References: <1155913603.22828.27.camel@trinity.ogc.int>
	<200608201903.k7KJ3cGT016589@r-dd.iij4u.or.jp>
	<1156142384.4844.6.camel@bigtime.es335.com>
Message-ID: <20060821110106U.fujita.tomonori@lab.ntt.co.jp>

From: Tom Tucker <tom at opengridcomputing.com>
Subject: Re: [Stgt-devel] Current SVN
Date: Mon, 21 Aug 2006 01:39:44 -0500

> > By the way, I've tried the user-space iSCSI target code exploiting
> > user-space tgt code. I can make an ext2 file system with open-iscsi,
> > however, It's far from completion. I just wanted to see how things
> > work. We are still not sure where the Linux iSCSI target code lives
> > (user or kernel).
> 
> BTW, I'll send an updated patch tomorrow that allows multiple transports
> under iSCSI. If you could take a look and comment, that would be great.

I will. Thanks in advance.


> It's basically all user-mode code that abstracts out listen/accept/poll
> so we can put in separate implementations for TCP vs. RDMA. Unlike the
> first patch, it will allow the sockets implementation to be in user-mode
> for login just like it is now.

Sounds nice.


From fujita.tomonori at lab.ntt.co.jp  Mon Aug 21 06:48:39 2006
From: fujita.tomonori at lab.ntt.co.jp (FUJITA Tomonori)
Date: Mon, 21 Aug 2006 13:48:39 +0900
Subject: [Stgt-devel] Current SVN
In-Reply-To: <20060821110106U.fujita.tomonori@lab.ntt.co.jp>
References: <200608201903.k7KJ3cGT016589@r-dd.iij4u.or.jp>
	<1156142384.4844.6.camel@bigtime.es335.com>
	<20060821110106U.fujita.tomonori@lab.ntt.co.jp>
Message-ID: <200608210448.k7L4mdwp027427@r-dd.iij4u.or.jp>

From: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
Subject: Re: [Stgt-devel] Current SVN
Date: Mon, 21 Aug 2006 11:01:06 +0900

> > It's basically all user-mode code that abstracts out listen/accept/poll
> > so we can put in separate implementations for TCP vs. RDMA. Unlike the
> > first patch, it will allow the sockets implementation to be in user-mode
> > for login just like it is now.
> 
> Sounds nice.

Oh, does this mean that the new patch is designed to run only with the
user-space iSCSI target implementation?


From tom at opengridcomputing.com  Mon Aug 21 15:13:45 2006
From: tom at opengridcomputing.com (Tom Tucker)
Date: Mon, 21 Aug 2006 08:13:45 -0500
Subject: [Stgt-devel] Current SVN
In-Reply-To: <200608210448.k7L4mdwp027427@r-dd.iij4u.or.jp>
References: <200608201903.k7KJ3cGT016589@r-dd.iij4u.or.jp>
	<1156142384.4844.6.camel@bigtime.es335.com>
	<20060821110106U.fujita.tomonori@lab.ntt.co.jp>
	<200608210448.k7L4mdwp027427@r-dd.iij4u.or.jp>
Message-ID: <1156166025.11432.1.camel@trinity.ogc.int>

On Mon, 2006-08-21 at 13:48 +0900, FUJITA Tomonori wrote:
> From: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
> Subject: Re: [Stgt-devel] Current SVN
> Date: Mon, 21 Aug 2006 11:01:06 +0900
> 
> > > It's basically all user-mode code that abstracts out listen/accept/poll
> > > so we can put in separate implementations for TCP vs. RDMA. Unlike the
> > > first patch, it will allow the sockets implementation to be in user-mode
> > > for login just like it is now.
> > 
> > Sounds nice.
> 
> Oh, does this mean that the new patch is designed to run only with the
> user-space iSCSI target implementation?

No, it is meant to work with the current implementation. I am trying to
follow the current design and architecture. Although, it should work if
you ultimately go with a user-mode only design.





From tom at opengridcomputing.com  Mon Aug 21 19:32:11 2006
From: tom at opengridcomputing.com (Tom Tucker)
Date: Mon, 21 Aug 2006 12:32:11 -0500
Subject: [Stgt-devel] session tsih
In-Reply-To: <200608210448.k7L4mdwp027427@r-dd.iij4u.or.jp>
References: <200608201903.k7KJ3cGT016589@r-dd.iij4u.or.jp>
	<1156142384.4844.6.camel@bigtime.es335.com>
	<20060821110106U.fujita.tomonori@lab.ntt.co.jp>
	<200608210448.k7L4mdwp027427@r-dd.iij4u.or.jp>
Message-ID: <1156181531.11567.36.camel@trinity.ogc.int>

Tomo:

The session data structure contains a tsih value which is the transport
session id. In session destroy it looks like it takes the global thandle
(points to tcp's handle currently) and passes this down to
ki->destroy_session. 

Since a session may have multiple connections and these connections may
be on different transports, don't we have to destroy this session on
each transport for which there a connection?

I think this also means that there needs to be a tsih value for each
transport since they could be different.

Do I understand this all correctly?

Thanks,
Tom



From tom at opengridcomputing.com  Mon Aug 21 23:29:40 2006
From: tom at opengridcomputing.com (Tom Tucker)
Date: Mon, 21 Aug 2006 16:29:40 -0500
Subject: [Stgt-devel] uSpace Transport Patch
In-Reply-To: <200608201903.k7KJ3cGT016589@r-dd.iij4u.or.jp>
References: <1155913603.22828.27.camel@trinity.ogc.int>
	<200608201903.k7KJ3cGT016589@r-dd.iij4u.or.jp>
Message-ID: <1156195780.7484.16.camel@trinity.ogc.int>

Tomo:

Enclosed is a patch that allows you to plug in multiple transports. It
has a few benefits over the last approach:

1. The TCP side can remain exactly the same. i.e. user-mode connection
management and login send/recv.

2. The stgtd implementation still uses pollfd to receive I/O events. The
   iser side will provide an fd that can be polled.


I have built and run this patch with the current code and connected with
a iscsi initiator over TCP. I did encounter problems, however, trying to
do disk i/o.

This is not done, it is a proof-of-concept/design proposal. The netlink
stuff will obviously change as I flesh out the iSER side. Please let me
know what you think, I'd like your opinion before I get to far down this
road.

Thanks, 
Tom

Index: usr/iscsi/session.c
===================================================================
--- usr/iscsi/session.c	(revision 532)
+++ usr/iscsi/session.c	(working copy)
@@ -112,12 +112,13 @@
 
 	log_debug("session_create: %#" PRIx64, sid);
 
-	ki->create_session(thandle, conn->exp_cmd_sn, &session->ksid,
+	ki->create_session(conn->kth, conn->exp_cmd_sn, &session->ksid,
 			   &session->hostno);
 
 	list_add(&session->hlist, &sessions_list);
 }
 
+#if 0
 void session_remove(struct session *session)
 {
 	uint64_t sid = sid64(session->isid, session->tsih);
@@ -140,3 +141,4 @@
 	free(session->initiator);
 	free(session);
 }
+#endif
Index: usr/iscsi/iscsid.h
===================================================================
--- usr/iscsi/iscsid.h	(revision 532)
+++ usr/iscsi/iscsid.h	(working copy)
@@ -9,13 +9,14 @@
 
 #include <sys/types.h>
 #include <linux/types.h>
-
+#include <sys/socket.h>
+#include <linux/socket.h>
 #include "types.h"
 #include "iscsi_if.h"
 #include "list.h"
 #include "param.h"
 #include "log.h"
-
+#include "iscsi_uspace_transport.h"
 #include <scsi/iscsi_proto.h>
 
 #define ISCSI_NAME_LEN 255
@@ -25,7 +26,6 @@
 #define DIGEST_NONE		(1 << 0)
 #define DIGEST_CRC32C           (1 << 1)
 
-extern uint64_t thandle;
 extern int nl_fd;
 
 #define sid64(isid, tsih)					\
@@ -69,6 +69,7 @@
 	int state;
 	int iostate;
 	int fd;
+	uint64_t kth;
 
 	struct list_head clist;
 	struct session *session;
Index: usr/iscsi/iscsi_uspace_transport.c
===================================================================
--- usr/iscsi/iscsi_uspace_transport.c	(revision 0)
+++ usr/iscsi/iscsi_uspace_transport.c	(revision 0)
@@ -0,0 +1,118 @@
+#include <stdio.h>
+#include <stdint.h>
+#include <stddef.h>
+#include <stdlib.h>
+#include <errno.h>
+
+#include "list.h"
+#include "iscsi_uspace_transport.h"
+
+struct iut_el {
+	struct list_head list;
+	struct iut *transport;
+};
+
+static LIST_HEAD(iscsi_transport_list);
+
+extern struct iut iscsi_tcp;
+
+#if 0
+struct iut iscsi_iser = {
+	.name = "iser",
+	.rdma = 1,
+	.init = iser_transport_init,
+	.poll_init = iser_poll_init,
+	.ep_accept = iser_ep_accept,
+	.ep_close = iser_ep_close,
+};
+#endif
+
+void iut_init(void)
+{
+	struct iut_el *el;
+
+	el = malloc(sizeof(*el));
+	el->transport = &iscsi_tcp;
+	list_add(&(el->list),  &iscsi_transport_list);
+#if 0
+	el = malloc(sizeof(*el));
+	el->transport = &iscsi_iser;
+	list_add(&(el->list),  &iscsi_transport_list);
+#endif
+	list_for_each_entry(el, &iscsi_transport_list, list)
+		el->transport->init(el->transport);
+}
+
+int iut_lookup_handles(int fd, 
+		       iut_handle_t *pth,
+		       iut_ep_handle_t* peh)
+{
+	struct iut_el *el;
+	iut_ep_handle_t eh;
+	int found = 0;
+
+	list_for_each_entry(el, &iscsi_transport_list, list) {
+		eh = iut_ep_lookup(el->transport, fd);
+		if (eh) {
+			dprintf("found handle = %p for fd = %d\n", 
+				eh, fd);
+			*pth = el->transport;
+			*peh = eh;
+			found = 1;
+			break;
+		}
+	}
+
+	return found;
+}
+
+int iut_poll_init(struct pollfd *pfds, int listen_max)
+{
+	struct iut_el *el;
+	int listen_count = 0;
+
+	list_for_each_entry(el, &iscsi_transport_list, list) 
+		listen_count += el->transport->poll_init(el->transport, 
+							 pfds + listen_count, 
+							 listen_max - listen_count);
+
+	return listen_count;
+}
+
+int iut_ep_close(iut_handle_t th, iut_ep_handle_t ep_h)
+{
+	return th->ep_close(th, ep_h);
+}
+
+int iut_ep_accept(iut_handle_t th, iut_ep_handle_t ep_h,
+			 iut_ep_handle_t *new_ep_h,
+			 struct sockaddr *addr, socklen_t *addrlen)
+{
+	return th->ep_accept(th, ep_h, new_ep_h, addr, addrlen);
+}
+
+iut_ep_handle_t iut_ep_lookup(iut_handle_t th, int fd)
+{
+	return th->ep_lookup(th, fd);
+}
+
+int iut_fd_write(int fd, const void *buf, int buflen, int cork)
+{
+	iut_handle_t th;
+	iut_ep_handle_t ep_h;
+	if (iut_lookup_handles(fd, &th, &ep_h))
+		return th->ep_write(th, ep_h, buf, buflen, cork);
+
+	return -ENOENT;
+}
+
+int iut_fd_read(int fd, void *buf, int buflen)
+{
+	iut_handle_t th;
+	iut_ep_handle_t ep_h;
+	if (iut_lookup_handles(fd, &th, &ep_h))
+		return th->ep_read(th, ep_h, buf, buflen);
+
+	return -ENOENT;
+}
+
Index: usr/iscsi/istgt.c
===================================================================
--- usr/iscsi/istgt.c	(revision 532)
+++ usr/iscsi/istgt.c	(working copy)
@@ -33,9 +33,8 @@
 #include <arpa/inet.h>
 
 #include "iscsid.h"
+#include "iscsi_uspace_transport.h"
 
-#define ISCSI_LISTEN_PORT	3260
-
 #define LISTEN_MAX	4
 #define INCOMING_MAX	32
 
@@ -47,92 +46,29 @@
 };
 
 static struct connection *incoming[INCOMING_MAX];
-uint64_t thandle;
 int nl_fd;
 
-static void set_non_blocking(int fd)
-{
-	int res = fcntl(fd, F_GETFL);
-
-	if (res != -1) {
-		res = fcntl(fd, F_SETFL, res | O_NONBLOCK);
-		if (res)
-			dprintf("unable to set fd flags (%s)!\n", strerror(errno));
-	} else
-		dprintf("unable to get fd flags (%s)!\n", strerror(errno));
-}
-
-static void listen_socket_create(struct pollfd *pfds)
-{
-	struct addrinfo hints, *res, *res0;
-	char servname[64];
-	int i, sock, opt;
-
-	memset(servname, 0, sizeof(servname));
-	snprintf(servname, sizeof(servname), "%d", ISCSI_LISTEN_PORT);
-
-	memset(&hints, 0, sizeof(hints));
-	hints.ai_socktype = SOCK_STREAM;
-	hints.ai_flags = AI_PASSIVE;
-
-	if (getaddrinfo(NULL, servname, &hints, &res0)) {
-		eprintf("unable to get address info (%s)!\n", strerror(errno));
-		exit(1);
-	}
-
-	for (i = 0, res = res0; res && i < LISTEN_MAX; i++, res = res->ai_next) {
-		sock = socket(res->ai_family, res->ai_socktype, res->ai_protocol);
-		if (sock < 0) {
-			eprintf("unable to create server socket (%s) %d %d %d!\n",
-				  strerror(errno), res->ai_family,
-				  res->ai_socktype, res->ai_protocol);
-			continue;
-		}
-
-		opt = 1;
-		if (setsockopt(sock, SOL_SOCKET, SO_REUSEADDR, &opt, sizeof(opt)))
-			dprintf("unable to set SO_REUSEADDR on server socket (%s)!\n",
-				    strerror(errno));
-		opt = 1;
-		if (res->ai_family == AF_INET6 &&
-		    setsockopt(sock, IPPROTO_IPV6, IPV6_V6ONLY, &opt, sizeof(opt)))
-			continue;
-
-		if (bind(sock, res->ai_addr, res->ai_addrlen)) {
-			eprintf("unable to bind server socket (%s)!\n", strerror(errno));
-			continue;
-		}
-
-		if (listen(sock, INCOMING_MAX)) {
-			eprintf("unable to listen to server socket (%s)!\n", strerror(errno));
-			continue;
-		}
-
-		set_non_blocking(sock);
-
-		pfds[i].fd = sock;
-		pfds[i].events = POLLIN;
-	}
-
-	freeaddrinfo(res0);
-}
-
 static void accept_connection(struct pollfd *pfds, int afd)
 {
-	struct sockaddr_storage from;
-	socklen_t namesize;
-	struct pollfd *pfd;
+	struct sockaddr addr;
+	socklen_t addrlen;
+	iut_handle_t th;
+	iut_ep_handle_t l_eh;
+	iut_ep_handle_t new_eh;
 	struct connection *conn;
-	int fd, i;
+	struct pollfd *pfd;
+	int i, fd;
+	
+	if (!iut_lookup_handles(afd, &th, &l_eh)) {
+		eprintf("could not find transport handles "
+			"for specified fd=%d\n",
+		       afd);
+		return;
+	}
 
-	eprintf("%d\n", afd);
-
-	namesize = sizeof(from);
-	if ((fd = accept(afd, (struct sockaddr *) &from, &namesize)) < 0) {
-		if (errno != EINTR && errno != EAGAIN) {
-			eprintf("accept(incoming_socket)\n");
-			exit(1);
-		}
+	fd = iut_ep_accept(th, l_eh, &new_eh, &addr, &addrlen); 
+	if (fd < 0) {
+		printf("failed to accept incoming connection request\n");
 		return;
 	}
 
@@ -150,11 +86,11 @@
 		eprintf("fail to allocate conn\n");
 		goto out;
 	}
+	conn->kth = th->kernel_handle;
 	conn->fd = fd;
 	incoming[i] = conn;
 	conn_read_pdu(conn);
 
-	set_non_blocking(fd);
 	pfd = &pfds[POLL_INCOMING + i];
 	pfd->fd = fd;
 	pfd->events = POLLIN;
@@ -162,7 +98,7 @@
 
 	return;
 out:
-	close(fd);
+	iut_ep_close(th, new_eh);
 	return;
 }
 
@@ -170,7 +106,7 @@
 {
 	struct connection *conn;
 	struct pollfd *pfd;
-	int i, res, opt;
+	int i, res;
 
 	for (i = 0; i < LISTEN_MAX; i++) {
 		if (pfds[POLL_LISTEN + i].revents)
@@ -189,14 +125,15 @@
 		case IOSTATE_READ_BHS:
 		case IOSTATE_READ_AHS_DATA:
 		read_again:
-			res = read(pfd->fd, conn->buffer, conn->rwsize);
+			res = iut_fd_read(pfd->fd, conn->buffer, conn->rwsize);
 			if (res <= 0) {
 				if (res == 0 || (errno != EINTR && errno != EAGAIN))
 					conn->state = STATE_CLOSE;
 				else if (errno == EINTR)
 					goto read_again;
 				break;
-			}
+			} else
+				printf("read %d bytes: \"%s\"\n", res, conn->buffer);
 			conn->rwsize -= res;
 			conn->buffer += res;
 			if (conn->rwsize)
@@ -233,9 +170,8 @@
 		case IOSTATE_WRITE_AHS:
 		case IOSTATE_WRITE_DATA:
 		write_again:
-			opt = 1;
-			setsockopt(pfd->fd, SOL_TCP, TCP_CORK, &opt, sizeof(opt));
-			res = write(pfd->fd, conn->buffer, conn->rwsize);
+			res = iut_fd_write(pfd->fd, conn->buffer, conn->rwsize, 1);
+			printf("wrote %d bytes: \"%s\"\n", conn->rwsize, conn->buffer);
 			if (res < 0) {
 				if (errno != EINTR && errno != EAGAIN)
 					conn->state = STATE_CLOSE;
@@ -272,8 +208,7 @@
 					goto write_again;
 				}
 			case IOSTATE_WRITE_DATA:
-				opt = 0;
-				setsockopt(pfd->fd, SOL_TCP, TCP_CORK, &opt, sizeof(opt));
+				iut_fd_write(pfd->fd, NULL, 0, 0);
 				cmnd_finish(conn);
 
 				switch (conn->state) {
@@ -312,11 +247,13 @@
 int iscsi_poll_init(struct pollfd *pfd)
 {
 	int i;
+	int listeners;
 
 	pfd[POLL_NL].fd = nl_fd;
 	pfd[POLL_NL].events = POLLIN;
 
-	listen_socket_create(pfd + POLL_LISTEN);
+	listeners = iut_poll_init(pfd + POLL_LISTEN, LISTEN_MAX);
+	dprintf("%d listeners\n", listeners);
 
 	for (i = 0; i < INCOMING_MAX; i++) {
 		pfd[POLL_INCOMING + i].fd = -1;
@@ -332,5 +269,7 @@
 	iscsi_nl_init();
 	*npfd = POLL_MAX;
 
+	iut_init();
+
 	return 0;
 }
Index: usr/iscsi/iscsi_uspace_transport.h
===================================================================
--- usr/iscsi/iscsi_uspace_transport.h	(revision 0)
+++ usr/iscsi/iscsi_uspace_transport.h	(revision 0)
@@ -0,0 +1,60 @@
+#ifndef __ISCSI_USPACE_TRANSPORT_H
+#define __ISCSI_USPACE_TRANSPORT_H
+
+#include <sys/poll.h>
+#include <sys/socket.h>
+#include "list.h"
+
+#define ISCSI_LISTEN_PORT	3260
+
+typedef struct iut_ep_handle {
+	uint64_t kernel_handle;
+	struct iut *transport;
+} *iut_ep_handle_t;
+
+typedef struct iut *iut_handle_t;
+struct iut {
+	uint64_t kernel_handle;
+	const char *name;
+	int rdma;
+
+	int (*init)(iut_handle_t);
+	int (*poll_init)(iut_handle_t th, struct pollfd *, int listen_max);
+	int (*ep_close)(iut_handle_t th, iut_ep_handle_t ep_h);
+	int (*ep_accept)(iut_handle_t th, iut_ep_handle_t ep_h,
+			 iut_ep_handle_t *new_ep_h,
+			 struct sockaddr *addr, socklen_t *addrlen);
+	iut_ep_handle_t (*ep_lookup)(iut_handle_t th, int fd);
+	int (*ep_write)(iut_handle_t th, iut_ep_handle_t ep_h,
+			const void *buf, int buflen, int cork);
+	int (*ep_read)(iut_handle_t th, iut_ep_handle_t ep_h,
+		       void *buf, int buflen);
+};
+
+/* Transport independent functions */
+extern int iut_poll_init(struct pollfd *pfds, int);
+extern void iut_init(void);
+extern int iut_lookup_handles(int fd, iut_handle_t *th, iut_ep_handle_t *eh);
+extern int iut_ep_close(iut_handle_t th, iut_ep_handle_t ep_h);
+extern int iut_ep_accept(iut_handle_t th, iut_ep_handle_t ep_h,
+			 iut_ep_handle_t *new_ep_h,
+			 struct sockaddr *addr, socklen_t *addrlen);
+extern iut_ep_handle_t iut_ep_lookup(iut_handle_t th, int fd);
+extern int iut_fd_write(int fd, const void *buf, int buflen, int cork);
+extern int iut_fd_read(int fd, void *buf, int buflen);
+
+/* TCP Transport Functions */
+int tcp_transport_init(iut_handle_t th);
+int tcp_poll_init(iut_handle_t, struct pollfd *, int listen_max);
+int tcp_get_poll_fd(iut_handle_t th, iut_ep_handle_t ep_h);
+int tcp_ep_close(iut_handle_t th, iut_ep_handle_t ep_h);
+int tcp_ep_accept(iut_handle_t th, iut_ep_handle_t ep_h,
+		  iut_ep_handle_t *new_ep_h,
+		  struct sockaddr *addr, socklen_t *addrlen);
+iut_ep_handle_t tcp_ep_lookup(iut_handle_t th, int fd);
+int tcp_ep_write(iut_handle_t th, iut_ep_handle_t ep_h,
+		 const void *buf, int buflen, int cork);
+int tcp_ep_read(iut_handle_t th, iut_ep_handle_t ep_h,
+		void *buf, int buflen);
+
+#endif
Index: usr/iscsi/iscsi_transport_tcp.c
===================================================================
--- usr/iscsi/iscsi_transport_tcp.c	(revision 0)
+++ usr/iscsi/iscsi_transport_tcp.c	(revision 0)
@@ -0,0 +1,281 @@
+#include <ctype.h>
+#include <errno.h>
+#include <fcntl.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <unistd.h>
+#include <getopt.h>
+#include <netdb.h>
+
+#include <sys/poll.h>
+#include <sys/socket.h>
+#include <sys/stat.h>
+#include <sys/types.h>
+#include <sys/un.h>
+
+#include <netinet/in.h>
+#include <netinet/tcp.h>
+#include <netinet/ip.h>
+#include <arpa/inet.h>
+
+#include "iscsid.h"
+#include "list.h"
+#include "iscsi_uspace_transport.h"
+
+struct iut iscsi_tcp = {
+	.name = "tcp",
+	.rdma = 0,
+	.init = tcp_transport_init,
+	.poll_init = tcp_poll_init,
+	.ep_lookup = tcp_ep_lookup,
+	.ep_accept = tcp_ep_accept,
+	.ep_close = tcp_ep_close,
+	.ep_write = tcp_ep_write,
+	.ep_read = tcp_ep_read,
+};
+
+struct tcp_ep_dir {
+	int size;
+	iut_ep_handle_t dir[0];
+};
+static struct tcp_ep_dir *tcp_ep_dir;
+
+static iut_ep_handle_t tcp_ep_create(int fd);
+static void tcp_ep_destroy(iut_ep_handle_t ep);
+
+#define TCP_EP_DIR_INITIAL_SIZE 256
+#define TCP_EP_DIR_BUMP		16
+static struct tcp_ep_dir* tcp_create_ep_dir(int size)
+{
+	struct tcp_ep_dir* dir;
+	int i;
+
+	dir = malloc(sizeof(struct tcp_ep_dir) + (sizeof(iut_ep_handle_t)*size));
+	if (!dir)
+		return NULL;
+
+	dir->size = size;
+	for (i=0; i < size; i++)
+		dir->dir[i] = NULL;
+
+	return dir;
+}		
+
+static void tcp_copy_ep_dir(struct tcp_ep_dir *src, struct tcp_ep_dir *dest)
+{
+	int i;
+	for (i=0; i < dest->size; i++)
+		if (i < src->size)
+			dest->dir[i] = src->dir[i];
+}		
+
+static void tcp_destroy_ep_dir(struct tcp_ep_dir *dir)
+{
+	free(dir);
+}		
+
+static struct tcp_ep_dir* tcp_resize_ep_dir(struct tcp_ep_dir* old_dir, int size)
+{
+	struct tcp_ep_dir* new_dir;
+
+	new_dir = tcp_create_ep_dir(size);
+	if (!new_dir)
+		return NULL;
+
+	tcp_copy_ep_dir(old_dir, new_dir);
+	tcp_destroy_ep_dir(old_dir);
+	return new_dir;
+}		
+
+int tcp_transport_init(iut_handle_t t)
+{
+	int fd, err;
+	char buf[64];
+	uint64_t thandle;
+
+	/* Initialize the endpoint mapping cache */
+	tcp_ep_dir = tcp_create_ep_dir(TCP_EP_DIR_INITIAL_SIZE);
+
+	/* Get the tcp kernel driver's handle */
+	fd = open("/sys/class/iscsi_transport/iscsi_tcp_tgt/handle", O_RDONLY);
+	if (fd < 0)
+		return fd;
+	err = read(fd, buf, sizeof(buf));
+	if (err < 0)
+		goto out;
+	thandle = strtoull(buf, NULL, 10);
+	iscsi_tcp.kernel_handle = thandle;
+	printf("%s: transport handle = %" PRIx64 "\n", __FUNCTION__, thandle);
+	err = 0;
+out:
+	close(fd);
+	return err;
+}
+
+static void set_non_blocking(int fd)
+{
+	int res = fcntl(fd, F_GETFL);
+
+	if (res != -1) {
+		res = fcntl(fd, F_SETFL, res | O_NONBLOCK);
+		if (res)
+			dprintf("unable to set fd flags (%s)!\n", strerror(errno));
+	} else
+		dprintf("unable to get fd flags (%s)!\n", strerror(errno));
+}
+
+int tcp_poll_init(iut_handle_t th, struct pollfd *pfds, int listen_max)
+{
+	struct addrinfo hints, *res, *res0;
+	char servname[64];
+	int i, sock, opt;
+
+	memset(servname, 0, sizeof(servname));
+	snprintf(servname, sizeof(servname), "%d", ISCSI_LISTEN_PORT);
+
+	memset(&hints, 0, sizeof(hints));
+	hints.ai_socktype = SOCK_STREAM;
+	hints.ai_flags = AI_PASSIVE;
+
+	if (getaddrinfo(NULL, servname, &hints, &res0)) {
+		eprintf("unable to get address info (%s)!\n", strerror(errno));
+		exit(1);
+	}
+
+	for (i = 0, res = res0; res && i < listen_max; res = res->ai_next) {
+		sock = socket(res->ai_family, res->ai_socktype, res->ai_protocol);
+		if (sock < 0) {
+			eprintf("unable to create server socket (%s) %d %d %d!\n",
+				  strerror(errno), res->ai_family,
+				  res->ai_socktype, res->ai_protocol);
+			continue;
+		}
+
+		opt = 1;
+		if (setsockopt(sock, SOL_SOCKET, SO_REUSEADDR, &opt, sizeof(opt)))
+			dprintf("unable to set SO_REUSEADDR on server socket (%s)!\n",
+				    strerror(errno));
+		opt = 1;
+		if (res->ai_family == AF_INET6 &&
+		    setsockopt(sock, IPPROTO_IPV6, IPV6_V6ONLY, &opt, sizeof(opt)))
+			continue;
+
+		if (bind(sock, res->ai_addr, res->ai_addrlen)) {
+			eprintf("unable to bind server socket (%s)!\n", strerror(errno));
+			continue;
+		}
+
+		if (listen(sock, 10)) {
+			eprintf("unable to listen to server socket (%s)!\n", strerror(errno));
+			continue;
+		}
+
+		set_non_blocking(sock);
+
+		(void)tcp_ep_create(sock);
+
+		pfds[i].fd = sock;
+		pfds[i].events = POLLIN;
+		i++;
+	}
+
+	freeaddrinfo(res0);
+	return i;
+}
+
+int tcp_get_poll_fd(iut_handle_t th, 
+			   iut_ep_handle_t ep_h)
+{
+	return (int)(ep_h->kernel_handle);
+}
+
+int tcp_ep_close(iut_handle_t th, iut_ep_handle_t ep_h)
+{
+	int fd = (int)ep_h->kernel_handle;
+	tcp_ep_destroy(ep_h);
+	return close(fd);
+}
+
+int tcp_ep_write(iut_handle_t th, iut_ep_handle_t ep_h, const void *buf, int len, int cork)
+{
+	int rc = 0;
+	int opt = cork;
+	setsockopt((int)ep_h->kernel_handle, SOL_TCP, TCP_CORK, 
+		   &opt, sizeof(opt));
+
+	if (len)
+		rc = write((int)ep_h->kernel_handle, buf, len);
+
+	return rc;
+}
+
+int tcp_ep_read(iut_handle_t th, iut_ep_handle_t ep_h, void *buf, int len)
+{
+	return read((int)ep_h->kernel_handle, buf, len);
+}
+
+iut_ep_handle_t tcp_ep_lookup(iut_handle_t th, int fd)
+{
+	iut_ep_handle_t eh;
+	if (fd > tcp_ep_dir->size)
+		return NULL;
+
+	eh = tcp_ep_dir->dir[fd];
+	return eh;
+}
+
+static iut_ep_handle_t tcp_ep_create(int fd)
+{
+	iut_ep_handle_t ep = malloc(sizeof(*ep));
+	if (!ep)
+		return NULL;
+
+	if (fd >= tcp_ep_dir->size) {
+		struct tcp_ep_dir* new_dir;
+		new_dir = tcp_resize_ep_dir(tcp_ep_dir, 
+					    tcp_ep_dir->size+TCP_EP_DIR_BUMP);
+		if (new_dir == NULL) {
+			printf("Failure expanding size of TCP endpoint directory\n");
+			free(ep);
+			return NULL;
+		}
+		tcp_ep_dir = new_dir;
+	}
+
+	ep->kernel_handle = (uint64_t)fd;
+	ep->transport = &iscsi_tcp;
+	tcp_ep_dir->dir[fd] = ep;
+
+	return ep;
+}
+
+static void tcp_ep_destroy(iut_ep_handle_t ep)
+{
+	tcp_ep_dir->dir[(int)ep->kernel_handle] = NULL;
+	free(ep);
+}
+
+int tcp_ep_accept(iut_handle_t th, iut_ep_handle_t ep_h, 
+		  iut_ep_handle_t *new_ep_h,
+		  struct sockaddr *addr, socklen_t *addrlen)
+{
+	iut_ep_handle_t new_h;
+	int new_fd = accept((int)ep_h->kernel_handle, 
+			    addr, addrlen);
+
+	if (new_fd < 0) 
+		return new_fd;
+
+	new_h = tcp_ep_create(new_fd);
+	if (!new_h) {
+		close(new_fd);
+		return -ENOMEM;
+	}
+			
+	*new_ep_h = new_h;
+	return new_fd;
+}
+
+
+
Index: usr/iscsi/Makefile
===================================================================
--- usr/iscsi/Makefile	(revision 532)
+++ usr/iscsi/Makefile	(working copy)
@@ -2,7 +2,7 @@
 LIBS = -lcrypto
 DAEMON = iscsi.o
 
-$(DAEMON): istgt.o conn.o param.o session.o iscsid.o target.o chap.o netlink.o
+$(DAEMON): istgt.o conn.o param.o session.o iscsid.o target.o chap.o netlink.o iscsi_uspace_transport.o iscsi_transport_tcp.o 
 	$(CC) -o $@ $^ $(LIBS)
 
 clean:
Index: usr/iscsi/conn.c
===================================================================
--- usr/iscsi/conn.c	(revision 532)
+++ usr/iscsi/conn.c	(working copy)
@@ -11,7 +11,6 @@
 #include <string.h>
 #include <errno.h>
 #include <sys/stat.h>
-
 #include "iscsid.h"
 
 #define ISCSI_CONN_NEW		1
@@ -74,7 +73,7 @@
 
 	conn->session->conn_cnt++;
 
-	err = ki->create_conn(thandle, conn->session->ksid, conn->kcid,
+	err = ki->create_conn(conn->kth, conn->session->ksid, conn->kcid,
 			      &conn->kcid);
 	if (err) {
 		eprintf("%d %d %u %u %u %" PRIx64,
@@ -86,20 +85,20 @@
 		/* FIXME */
 		if (i == ISCSI_PARAM_DATADGST_EN || i == ISCSI_PARAM_HDRDGST_EN)
 			continue;
-		if (ki->set_param(thandle, conn->session->ksid, conn->kcid, i,
+		if (ki->set_param(conn->kth, conn->session->ksid, conn->kcid, i,
 				  &conn->session_param[i].val,
 				  sizeof(uint32_t), &err) || err) {
 			break;
 		}
 	}
 
-	if (ki->bind_conn(thandle, conn->session->ksid, conn->kcid, fd, 1, &err) || err) {
+	if (ki->bind_conn(conn->kth, conn->session->ksid, conn->kcid, fd, 1, &err) || err) {
 		eprintf("%d %d %u %u %u %" PRIx64,
 			fd, err, conn->cid, conn->stat_sn, conn->exp_stat_sn, sid);
 		goto out;
 	}
 
-	if (ki->start_conn(thandle, conn->session->ksid, conn->kcid, &err) || err) {
+	if (ki->start_conn(conn->kth, conn->session->ksid, conn->kcid, &err) || err) {
 		eprintf("%d %d %u %u %u %" PRIx64,
 			fd, err, conn->cid, conn->stat_sn, conn->exp_stat_sn, sid);
 		goto out;
Index: usr/Makefile
===================================================================
--- usr/Makefile	(revision 532)
+++ usr/Makefile	(working copy)
@@ -1,4 +1,4 @@
-CFLAGS += -O2 -fno-inline -Wall -Wstrict-prototypes -fPIC -I$(KERNELSRC)/include -I../istgt/include -I../include -I. -D_LARGEFILE64_SOURCE
+CFLAGS += -g -fno-inline -Wall -Wstrict-prototypes -fPIC -I$(KERNELSRC)/include -I../istgt/include -I../include -I. -D_LARGEFILE64_SOURCE
 PROGRAMS = tgtd tgtadm
 TGTD_OBJS = tgtd.o tgtif.o mgmt.o target.o scsi.o log.o driver.o util.o
 
@@ -9,7 +9,7 @@
 
 ifneq ($(ISCSI),)
 CFLAGS += -DISCSI
-TGTD_OBJS += $(addprefix iscsi/, istgt.o conn.o param.o session.o iscsid.o target.o chap.o netlink.o)
+TGTD_OBJS += $(addprefix iscsi/, istgt.o conn.o param.o session.o iscsid.o target.o chap.o netlink.o iscsi_uspace_transport.o iscsi_transport_tcp.o)
 LIBS = -lcrypto
 endif
 
Index: istgt/include/iscsi_if.h
===================================================================
--- istgt/include/iscsi_if.h	(revision 532)
+++ istgt/include/iscsi_if.h	(working copy)
@@ -46,11 +46,14 @@
 	ISCSI_UEVENT_TRANSPORT_EP_CONNECT	= UEVENT_BASE + 12,
 	ISCSI_UEVENT_TRANSPORT_EP_POLL		= UEVENT_BASE + 13,
 	ISCSI_UEVENT_TRANSPORT_EP_DISCONNECT	= UEVENT_BASE + 14,
+	ISCSI_UEVENT_TRANSPORT_CREATE_LISTEN	= UEVENT_BASE + 15,
+	ISCSI_UEVENT_TRANSPORT_DESTROY_LISTEN	= UEVENT_BASE + 16,
 
 	/* up events */
 	ISCSI_KEVENT_RECV_PDU		= KEVENT_BASE + 1,
 	ISCSI_KEVENT_CONN_ERROR		= KEVENT_BASE + 2,
 	ISCSI_KEVENT_IF_ERROR		= KEVENT_BASE + 3,
+	ISCSI_KEVENT_NEW_CONN		= KEVENT_BASE + 4,
 };
 
 struct iscsi_uevent {
@@ -116,6 +119,14 @@
 		struct msg_transport_disconnect {
 			uint64_t	ep_handle;
 		} ep_disconnect;
+		struct msg_create_listen {
+			uint32_t	backlog;
+			struct sockaddr local_addr;
+			int		local_addr_len;
+		} c_listen;
+		struct msg_destroy_listen {
+			uint32_t	ep_handle;
+		} d_listen;
 	} u;
 	union {
 		/* messages k -> u */
@@ -141,6 +152,16 @@
 		struct msg_transport_connect_ret {
 			uint64_t	handle;
 		} ep_connect_ret;
+		struct msg_ep_new_conn {
+			uint64_t	ep_handle;
+			struct sockaddr	local_addr;
+			int local_addr_len;
+			struct sockaddr	remote_addr;
+			int remote_addr_len;
+		} ep_new_conn;
+		struct msg_create_listen_ret {
+			uint64_t	ep_handle;
+		} c_listen_ret;
 	} r;
 } __attribute__ ((aligned (sizeof(uint64_t))));
 
Index: usr/iscsi/netlink.c
===================================================================
--- usr/iscsi/netlink.c	(revision 532)
+++ usr/iscsi/netlink.c	(working copy)
@@ -298,6 +298,7 @@
 	return 0;
 }
 
+#if 0
 static int transport_handle_init(void)
 {
 	int fd, err;
@@ -316,15 +317,17 @@
 	close(fd);
 	return err;
 }
+#endif
 
 int iscsi_nl_init(void)
 {
 	int err, rsize = 256 * 1024;
 
+#if 0
 	err = transport_handle_init();
 	if (err)
 		return err;
-
+#endif
 	nl_fd = socket(PF_NETLINK, SOCK_RAW, NETLINK_ISCSI);
 	if (nl_fd < 0) {
 		eprintf("Fail to create the netlink socket %d\n", errno);
@@ -358,6 +361,93 @@
 	return err;
 }
 
+int ktransport_create_listen(uint64_t transport_handle, 
+			     uint64_t user_context,
+			     struct sockaddr *sa, int backlog,
+			     uint64_t *out_ep_handle)
+{
+	int rc;
+	struct iscsi_uevent ev;
+
+	dprintf("%"PRIx64 " %p %p %d\n",
+		transport_handle, out_ep_handle, sa, backlog);
+
+	ev.type = ISCSI_UEVENT_TRANSPORT_CREATE_LISTEN;
+	ev.transport_handle = transport_handle;
+	// ev.u.c_listen.user_context = user_context;
+	ev.u.c_listen.backlog = backlog;
+	ev.u.c_listen.local_addr = *sa;
+
+	if ((rc = __kipc_call(&ev, sizeof(ev))) < 0) {
+		return rc;
+	}
+
+	*out_ep_handle = ev.r.c_listen_ret.ep_handle;
+
+	return ev.r.retcode;
+}
+
+int ktransport_destroy_listen(uint64_t transport_handle, uint64_t ep_handle)
+{
+	int rc;
+	struct iscsi_uevent ev;
+
+	dprintf("%" PRIx64 " %" PRIx64 "\n",
+		transport_handle, ep_handle);
+
+	ev.type = ISCSI_UEVENT_TRANSPORT_DESTROY_LISTEN;
+	ev.transport_handle = transport_handle;
+	ev.u.d_listen.ep_handle = ep_handle;
+
+	if ((rc = __kipc_call(&ev, sizeof(ev))) < 0) {
+		return rc;
+	}
+
+	return ev.r.retcode;
+}
+
+#if 0
+static int ktransport_accept(uint64_t transport_handle, 
+		   uint64_t ep_handle, uint64_t ep_context)
+{
+	int rc;
+	struct iscsi_uevent ev;
+
+	dprintf("%" PRIx64 " %" PRIx64 " %" PRIx64 "\n",
+		transport_handle, ep_handle, ep_context);
+
+	ev.type = ISCSI_UEVENT_EP_ACCEPT;
+	ev.transport_handle = transport_handle;
+	ev.u.ep_accept.ep_handle = ep_handle;
+	ev.u.ep_accept.ep_context = ep_context;
+
+	if ((rc = __kipc_call(&ev, sizeof(ev))) < 0) {
+		return rc;
+	}
+
+	return ev.r.retcode;
+}
+
+static int ktransport_reject(uint64_t transport_handle, uint64_t ep_handle)
+{
+	int rc;
+	struct iscsi_uevent ev;
+
+	dprintf("%" PRIx64 " %" PRIx64 "\n",
+		transport_handle, ep_handle);
+
+	ev.type = ISCSI_UEVENT_EP_REJECT;
+	ev.transport_handle = transport_handle;
+	ev.u.ep_reject.ep_handle = ep_handle;
+
+	if ((rc = __kipc_call(&ev, sizeof(ev))) < 0) {
+		return rc;
+	}
+
+	return ev.r.retcode;
+}
+#endif
+
 struct iscsi_kernel_interface nl_ki = {
 	.create_session		= kcreate_session,
 	.destroy_session	= kdestroy_session,




From fujita.tomonori at lab.ntt.co.jp  Tue Aug 22 01:02:15 2006
From: fujita.tomonori at lab.ntt.co.jp (FUJITA Tomonori)
Date: Tue, 22 Aug 2006 08:02:15 +0900
Subject: [Stgt-devel] session tsih
In-Reply-To: <1156181531.11567.36.camel@trinity.ogc.int>
References: <20060821110106U.fujita.tomonori@lab.ntt.co.jp>
	<200608210448.k7L4mdwp027427@r-dd.iij4u.or.jp>
	<1156181531.11567.36.camel@trinity.ogc.int>
Message-ID: <20060822080215Q.fujita.tomonori@lab.ntt.co.jp>

From: Tom Tucker <tom at opengridcomputing.com>
Subject: [Stgt-devel] session tsih
Date: Mon, 21 Aug 2006 12:32:11 -0500

> Tomo:
> 
> The session data structure contains a tsih value which is the transport
> session id. In session destroy it looks like it takes the global thandle
> (points to tcp's handle currently) and passes this down to
> ki->destroy_session. 
> 
> Since a session may have multiple connections and these connections may
> be on different transports, don't we have to destroy this session on
> each transport for which there a connection?

I'm not sure what you mean. You cannot have iser and tcp connections
in a session, can you?


From fujita.tomonori at lab.ntt.co.jp  Tue Aug 22 01:11:29 2006
From: fujita.tomonori at lab.ntt.co.jp (FUJITA Tomonori)
Date: Tue, 22 Aug 2006 08:11:29 +0900
Subject: [Stgt-devel] uSpace Transport Patch
In-Reply-To: <1156195780.7484.16.camel@trinity.ogc.int>
References: <1155913603.22828.27.camel@trinity.ogc.int>
	<200608201903.k7KJ3cGT016589@r-dd.iij4u.or.jp>
	<1156195780.7484.16.camel@trinity.ogc.int>
Message-ID: <20060822081129C.fujita.tomonori@lab.ntt.co.jp>

From: Tom Tucker <tom at opengridcomputing.com>
Subject: [Stgt-devel] uSpace Transport Patch
Date: Mon, 21 Aug 2006 16:29:40 -0500

> Tomo:
> 
> Enclosed is a patch that allows you to plug in multiple transports. It
> has a few benefits over the last approach:

Thanks.


> 1. The TCP side can remain exactly the same. i.e. user-mode connection
> management and login send/recv.
> 
> 2. The stgtd implementation still uses pollfd to receive I/O events. The
>    iser side will provide an fd that can be polled.
> 
> 
> I have built and run this patch with the current code and connected with
> a iscsi initiator over TCP. I did encounter problems, however, trying to
> do disk i/o.

The write path code is broken. I will fix it if the kernel-mode
approach would likely be accepted into mainline.

The user-space mode code should work better. As I said in the previous
mail, I can do mkfs, extract linux kernel tar, etc with the open-iscsi
default configuration.


> This is not done, it is a proof-of-concept/design proposal. The netlink
> stuff will obviously change as I flesh out the iSER side. Please let me
> know what you think, I'd like your opinion before I get to far down this
> road.

I see. I will read this soon. Can you post iSER part code too?


> Thanks, 
> Tom
> 
> Index: usr/iscsi/session.c
> ===================================================================
> --- usr/iscsi/session.c	(revision 532)
> +++ usr/iscsi/session.c	(working copy)
> @@ -112,12 +112,13 @@
>  
>  	log_debug("session_create: %#" PRIx64, sid);
>  
> -	ki->create_session(thandle, conn->exp_cmd_sn, &session->ksid,
> +	ki->create_session(conn->kth, conn->exp_cmd_sn, &session->ksid,
>  			   &session->hostno);
>  
>  	list_add(&session->hlist, &sessions_list);
>  }
>  
> +#if 0
>  void session_remove(struct session *session)
>  {
>  	uint64_t sid = sid64(session->isid, session->tsih);
> @@ -140,3 +141,4 @@
>  	free(session->initiator);
>  	free(session);
>  }
> +#endif
> Index: usr/iscsi/iscsid.h
> ===================================================================
> --- usr/iscsi/iscsid.h	(revision 532)
> +++ usr/iscsi/iscsid.h	(working copy)
> @@ -9,13 +9,14 @@
>  
>  #include <sys/types.h>
>  #include <linux/types.h>
> -
> +#include <sys/socket.h>
> +#include <linux/socket.h>
>  #include "types.h"
>  #include "iscsi_if.h"
>  #include "list.h"
>  #include "param.h"
>  #include "log.h"
> -
> +#include "iscsi_uspace_transport.h"
>  #include <scsi/iscsi_proto.h>
>  
>  #define ISCSI_NAME_LEN 255
> @@ -25,7 +26,6 @@
>  #define DIGEST_NONE		(1 << 0)
>  #define DIGEST_CRC32C           (1 << 1)
>  
> -extern uint64_t thandle;
>  extern int nl_fd;
>  
>  #define sid64(isid, tsih)					\
> @@ -69,6 +69,7 @@
>  	int state;
>  	int iostate;
>  	int fd;
> +	uint64_t kth;
>  
>  	struct list_head clist;
>  	struct session *session;
> Index: usr/iscsi/iscsi_uspace_transport.c
> ===================================================================
> --- usr/iscsi/iscsi_uspace_transport.c	(revision 0)
> +++ usr/iscsi/iscsi_uspace_transport.c	(revision 0)
> @@ -0,0 +1,118 @@
> +#include <stdio.h>
> +#include <stdint.h>
> +#include <stddef.h>
> +#include <stdlib.h>
> +#include <errno.h>
> +
> +#include "list.h"
> +#include "iscsi_uspace_transport.h"
> +
> +struct iut_el {
> +	struct list_head list;
> +	struct iut *transport;
> +};
> +
> +static LIST_HEAD(iscsi_transport_list);
> +
> +extern struct iut iscsi_tcp;
> +
> +#if 0
> +struct iut iscsi_iser = {
> +	.name = "iser",
> +	.rdma = 1,
> +	.init = iser_transport_init,
> +	.poll_init = iser_poll_init,
> +	.ep_accept = iser_ep_accept,
> +	.ep_close = iser_ep_close,
> +};
> +#endif
> +
> +void iut_init(void)
> +{
> +	struct iut_el *el;
> +
> +	el = malloc(sizeof(*el));
> +	el->transport = &iscsi_tcp;
> +	list_add(&(el->list),  &iscsi_transport_list);
> +#if 0
> +	el = malloc(sizeof(*el));
> +	el->transport = &iscsi_iser;
> +	list_add(&(el->list),  &iscsi_transport_list);
> +#endif
> +	list_for_each_entry(el, &iscsi_transport_list, list)
> +		el->transport->init(el->transport);
> +}
> +
> +int iut_lookup_handles(int fd, 
> +		       iut_handle_t *pth,
> +		       iut_ep_handle_t* peh)
> +{
> +	struct iut_el *el;
> +	iut_ep_handle_t eh;
> +	int found = 0;
> +
> +	list_for_each_entry(el, &iscsi_transport_list, list) {
> +		eh = iut_ep_lookup(el->transport, fd);
> +		if (eh) {
> +			dprintf("found handle = %p for fd = %d\n", 
> +				eh, fd);
> +			*pth = el->transport;
> +			*peh = eh;
> +			found = 1;
> +			break;
> +		}
> +	}
> +
> +	return found;
> +}
> +
> +int iut_poll_init(struct pollfd *pfds, int listen_max)
> +{
> +	struct iut_el *el;
> +	int listen_count = 0;
> +
> +	list_for_each_entry(el, &iscsi_transport_list, list) 
> +		listen_count += el->transport->poll_init(el->transport, 
> +							 pfds + listen_count, 
> +							 listen_max - listen_count);
> +
> +	return listen_count;
> +}
> +
> +int iut_ep_close(iut_handle_t th, iut_ep_handle_t ep_h)
> +{
> +	return th->ep_close(th, ep_h);
> +}
> +
> +int iut_ep_accept(iut_handle_t th, iut_ep_handle_t ep_h,
> +			 iut_ep_handle_t *new_ep_h,
> +			 struct sockaddr *addr, socklen_t *addrlen)
> +{
> +	return th->ep_accept(th, ep_h, new_ep_h, addr, addrlen);
> +}
> +
> +iut_ep_handle_t iut_ep_lookup(iut_handle_t th, int fd)
> +{
> +	return th->ep_lookup(th, fd);
> +}
> +
> +int iut_fd_write(int fd, const void *buf, int buflen, int cork)
> +{
> +	iut_handle_t th;
> +	iut_ep_handle_t ep_h;
> +	if (iut_lookup_handles(fd, &th, &ep_h))
> +		return th->ep_write(th, ep_h, buf, buflen, cork);
> +
> +	return -ENOENT;
> +}
> +
> +int iut_fd_read(int fd, void *buf, int buflen)
> +{
> +	iut_handle_t th;
> +	iut_ep_handle_t ep_h;
> +	if (iut_lookup_handles(fd, &th, &ep_h))
> +		return th->ep_read(th, ep_h, buf, buflen);
> +
> +	return -ENOENT;
> +}
> +
> Index: usr/iscsi/istgt.c
> ===================================================================
> --- usr/iscsi/istgt.c	(revision 532)
> +++ usr/iscsi/istgt.c	(working copy)
> @@ -33,9 +33,8 @@
>  #include <arpa/inet.h>
>  
>  #include "iscsid.h"
> +#include "iscsi_uspace_transport.h"
>  
> -#define ISCSI_LISTEN_PORT	3260
> -
>  #define LISTEN_MAX	4
>  #define INCOMING_MAX	32
>  
> @@ -47,92 +46,29 @@
>  };
>  
>  static struct connection *incoming[INCOMING_MAX];
> -uint64_t thandle;
>  int nl_fd;
>  
> -static void set_non_blocking(int fd)
> -{
> -	int res = fcntl(fd, F_GETFL);
> -
> -	if (res != -1) {
> -		res = fcntl(fd, F_SETFL, res | O_NONBLOCK);
> -		if (res)
> -			dprintf("unable to set fd flags (%s)!\n", strerror(errno));
> -	} else
> -		dprintf("unable to get fd flags (%s)!\n", strerror(errno));
> -}
> -
> -static void listen_socket_create(struct pollfd *pfds)
> -{
> -	struct addrinfo hints, *res, *res0;
> -	char servname[64];
> -	int i, sock, opt;
> -
> -	memset(servname, 0, sizeof(servname));
> -	snprintf(servname, sizeof(servname), "%d", ISCSI_LISTEN_PORT);
> -
> -	memset(&hints, 0, sizeof(hints));
> -	hints.ai_socktype = SOCK_STREAM;
> -	hints.ai_flags = AI_PASSIVE;
> -
> -	if (getaddrinfo(NULL, servname, &hints, &res0)) {
> -		eprintf("unable to get address info (%s)!\n", strerror(errno));
> -		exit(1);
> -	}
> -
> -	for (i = 0, res = res0; res && i < LISTEN_MAX; i++, res = res->ai_next) {
> -		sock = socket(res->ai_family, res->ai_socktype, res->ai_protocol);
> -		if (sock < 0) {
> -			eprintf("unable to create server socket (%s) %d %d %d!\n",
> -				  strerror(errno), res->ai_family,
> -				  res->ai_socktype, res->ai_protocol);
> -			continue;
> -		}
> -
> -		opt = 1;
> -		if (setsockopt(sock, SOL_SOCKET, SO_REUSEADDR, &opt, sizeof(opt)))
> -			dprintf("unable to set SO_REUSEADDR on server socket (%s)!\n",
> -				    strerror(errno));
> -		opt = 1;
> -		if (res->ai_family == AF_INET6 &&
> -		    setsockopt(sock, IPPROTO_IPV6, IPV6_V6ONLY, &opt, sizeof(opt)))
> -			continue;
> -
> -		if (bind(sock, res->ai_addr, res->ai_addrlen)) {
> -			eprintf("unable to bind server socket (%s)!\n", strerror(errno));
> -			continue;
> -		}
> -
> -		if (listen(sock, INCOMING_MAX)) {
> -			eprintf("unable to listen to server socket (%s)!\n", strerror(errno));
> -			continue;
> -		}
> -
> -		set_non_blocking(sock);
> -
> -		pfds[i].fd = sock;
> -		pfds[i].events = POLLIN;
> -	}
> -
> -	freeaddrinfo(res0);
> -}
> -
>  static void accept_connection(struct pollfd *pfds, int afd)
>  {
> -	struct sockaddr_storage from;
> -	socklen_t namesize;
> -	struct pollfd *pfd;
> +	struct sockaddr addr;
> +	socklen_t addrlen;
> +	iut_handle_t th;
> +	iut_ep_handle_t l_eh;
> +	iut_ep_handle_t new_eh;
>  	struct connection *conn;
> -	int fd, i;
> +	struct pollfd *pfd;
> +	int i, fd;
> +	
> +	if (!iut_lookup_handles(afd, &th, &l_eh)) {
> +		eprintf("could not find transport handles "
> +			"for specified fd=%d\n",
> +		       afd);
> +		return;
> +	}
>  
> -	eprintf("%d\n", afd);
> -
> -	namesize = sizeof(from);
> -	if ((fd = accept(afd, (struct sockaddr *) &from, &namesize)) < 0) {
> -		if (errno != EINTR && errno != EAGAIN) {
> -			eprintf("accept(incoming_socket)\n");
> -			exit(1);
> -		}
> +	fd = iut_ep_accept(th, l_eh, &new_eh, &addr, &addrlen); 
> +	if (fd < 0) {
> +		printf("failed to accept incoming connection request\n");
>  		return;
>  	}
>  
> @@ -150,11 +86,11 @@
>  		eprintf("fail to allocate conn\n");
>  		goto out;
>  	}
> +	conn->kth = th->kernel_handle;
>  	conn->fd = fd;
>  	incoming[i] = conn;
>  	conn_read_pdu(conn);
>  
> -	set_non_blocking(fd);
>  	pfd = &pfds[POLL_INCOMING + i];
>  	pfd->fd = fd;
>  	pfd->events = POLLIN;
> @@ -162,7 +98,7 @@
>  
>  	return;
>  out:
> -	close(fd);
> +	iut_ep_close(th, new_eh);
>  	return;
>  }
>  
> @@ -170,7 +106,7 @@
>  {
>  	struct connection *conn;
>  	struct pollfd *pfd;
> -	int i, res, opt;
> +	int i, res;
>  
>  	for (i = 0; i < LISTEN_MAX; i++) {
>  		if (pfds[POLL_LISTEN + i].revents)
> @@ -189,14 +125,15 @@
>  		case IOSTATE_READ_BHS:
>  		case IOSTATE_READ_AHS_DATA:
>  		read_again:
> -			res = read(pfd->fd, conn->buffer, conn->rwsize);
> +			res = iut_fd_read(pfd->fd, conn->buffer, conn->rwsize);
>  			if (res <= 0) {
>  				if (res == 0 || (errno != EINTR && errno != EAGAIN))
>  					conn->state = STATE_CLOSE;
>  				else if (errno == EINTR)
>  					goto read_again;
>  				break;
> -			}
> +			} else
> +				printf("read %d bytes: \"%s\"\n", res, conn->buffer);
>  			conn->rwsize -= res;
>  			conn->buffer += res;
>  			if (conn->rwsize)
> @@ -233,9 +170,8 @@
>  		case IOSTATE_WRITE_AHS:
>  		case IOSTATE_WRITE_DATA:
>  		write_again:
> -			opt = 1;
> -			setsockopt(pfd->fd, SOL_TCP, TCP_CORK, &opt, sizeof(opt));
> -			res = write(pfd->fd, conn->buffer, conn->rwsize);
> +			res = iut_fd_write(pfd->fd, conn->buffer, conn->rwsize, 1);
> +			printf("wrote %d bytes: \"%s\"\n", conn->rwsize, conn->buffer);
>  			if (res < 0) {
>  				if (errno != EINTR && errno != EAGAIN)
>  					conn->state = STATE_CLOSE;
> @@ -272,8 +208,7 @@
>  					goto write_again;
>  				}
>  			case IOSTATE_WRITE_DATA:
> -				opt = 0;
> -				setsockopt(pfd->fd, SOL_TCP, TCP_CORK, &opt, sizeof(opt));
> +				iut_fd_write(pfd->fd, NULL, 0, 0);
>  				cmnd_finish(conn);
>  
>  				switch (conn->state) {
> @@ -312,11 +247,13 @@
>  int iscsi_poll_init(struct pollfd *pfd)
>  {
>  	int i;
> +	int listeners;
>  
>  	pfd[POLL_NL].fd = nl_fd;
>  	pfd[POLL_NL].events = POLLIN;
>  
> -	listen_socket_create(pfd + POLL_LISTEN);
> +	listeners = iut_poll_init(pfd + POLL_LISTEN, LISTEN_MAX);
> +	dprintf("%d listeners\n", listeners);
>  
>  	for (i = 0; i < INCOMING_MAX; i++) {
>  		pfd[POLL_INCOMING + i].fd = -1;
> @@ -332,5 +269,7 @@
>  	iscsi_nl_init();
>  	*npfd = POLL_MAX;
>  
> +	iut_init();
> +
>  	return 0;
>  }
> Index: usr/iscsi/iscsi_uspace_transport.h
> ===================================================================
> --- usr/iscsi/iscsi_uspace_transport.h	(revision 0)
> +++ usr/iscsi/iscsi_uspace_transport.h	(revision 0)
> @@ -0,0 +1,60 @@
> +#ifndef __ISCSI_USPACE_TRANSPORT_H
> +#define __ISCSI_USPACE_TRANSPORT_H
> +
> +#include <sys/poll.h>
> +#include <sys/socket.h>
> +#include "list.h"
> +
> +#define ISCSI_LISTEN_PORT	3260
> +
> +typedef struct iut_ep_handle {
> +	uint64_t kernel_handle;
> +	struct iut *transport;
> +} *iut_ep_handle_t;
> +
> +typedef struct iut *iut_handle_t;
> +struct iut {
> +	uint64_t kernel_handle;
> +	const char *name;
> +	int rdma;
> +
> +	int (*init)(iut_handle_t);
> +	int (*poll_init)(iut_handle_t th, struct pollfd *, int listen_max);
> +	int (*ep_close)(iut_handle_t th, iut_ep_handle_t ep_h);
> +	int (*ep_accept)(iut_handle_t th, iut_ep_handle_t ep_h,
> +			 iut_ep_handle_t *new_ep_h,
> +			 struct sockaddr *addr, socklen_t *addrlen);
> +	iut_ep_handle_t (*ep_lookup)(iut_handle_t th, int fd);
> +	int (*ep_write)(iut_handle_t th, iut_ep_handle_t ep_h,
> +			const void *buf, int buflen, int cork);
> +	int (*ep_read)(iut_handle_t th, iut_ep_handle_t ep_h,
> +		       void *buf, int buflen);
> +};
> +
> +/* Transport independent functions */
> +extern int iut_poll_init(struct pollfd *pfds, int);
> +extern void iut_init(void);
> +extern int iut_lookup_handles(int fd, iut_handle_t *th, iut_ep_handle_t *eh);
> +extern int iut_ep_close(iut_handle_t th, iut_ep_handle_t ep_h);
> +extern int iut_ep_accept(iut_handle_t th, iut_ep_handle_t ep_h,
> +			 iut_ep_handle_t *new_ep_h,
> +			 struct sockaddr *addr, socklen_t *addrlen);
> +extern iut_ep_handle_t iut_ep_lookup(iut_handle_t th, int fd);
> +extern int iut_fd_write(int fd, const void *buf, int buflen, int cork);
> +extern int iut_fd_read(int fd, void *buf, int buflen);
> +
> +/* TCP Transport Functions */
> +int tcp_transport_init(iut_handle_t th);
> +int tcp_poll_init(iut_handle_t, struct pollfd *, int listen_max);
> +int tcp_get_poll_fd(iut_handle_t th, iut_ep_handle_t ep_h);
> +int tcp_ep_close(iut_handle_t th, iut_ep_handle_t ep_h);
> +int tcp_ep_accept(iut_handle_t th, iut_ep_handle_t ep_h,
> +		  iut_ep_handle_t *new_ep_h,
> +		  struct sockaddr *addr, socklen_t *addrlen);
> +iut_ep_handle_t tcp_ep_lookup(iut_handle_t th, int fd);
> +int tcp_ep_write(iut_handle_t th, iut_ep_handle_t ep_h,
> +		 const void *buf, int buflen, int cork);
> +int tcp_ep_read(iut_handle_t th, iut_ep_handle_t ep_h,
> +		void *buf, int buflen);
> +
> +#endif
> Index: usr/iscsi/iscsi_transport_tcp.c
> ===================================================================
> --- usr/iscsi/iscsi_transport_tcp.c	(revision 0)
> +++ usr/iscsi/iscsi_transport_tcp.c	(revision 0)
> @@ -0,0 +1,281 @@
> +#include <ctype.h>
> +#include <errno.h>
> +#include <fcntl.h>
> +#include <stdio.h>
> +#include <stdlib.h>
> +#include <string.h>
> +#include <unistd.h>
> +#include <getopt.h>
> +#include <netdb.h>
> +
> +#include <sys/poll.h>
> +#include <sys/socket.h>
> +#include <sys/stat.h>
> +#include <sys/types.h>
> +#include <sys/un.h>
> +
> +#include <netinet/in.h>
> +#include <netinet/tcp.h>
> +#include <netinet/ip.h>
> +#include <arpa/inet.h>
> +
> +#include "iscsid.h"
> +#include "list.h"
> +#include "iscsi_uspace_transport.h"
> +
> +struct iut iscsi_tcp = {
> +	.name = "tcp",
> +	.rdma = 0,
> +	.init = tcp_transport_init,
> +	.poll_init = tcp_poll_init,
> +	.ep_lookup = tcp_ep_lookup,
> +	.ep_accept = tcp_ep_accept,
> +	.ep_close = tcp_ep_close,
> +	.ep_write = tcp_ep_write,
> +	.ep_read = tcp_ep_read,
> +};
> +
> +struct tcp_ep_dir {
> +	int size;
> +	iut_ep_handle_t dir[0];
> +};
> +static struct tcp_ep_dir *tcp_ep_dir;
> +
> +static iut_ep_handle_t tcp_ep_create(int fd);
> +static void tcp_ep_destroy(iut_ep_handle_t ep);
> +
> +#define TCP_EP_DIR_INITIAL_SIZE 256
> +#define TCP_EP_DIR_BUMP		16
> +static struct tcp_ep_dir* tcp_create_ep_dir(int size)
> +{
> +	struct tcp_ep_dir* dir;
> +	int i;
> +
> +	dir = malloc(sizeof(struct tcp_ep_dir) + (sizeof(iut_ep_handle_t)*size));
> +	if (!dir)
> +		return NULL;
> +
> +	dir->size = size;
> +	for (i=0; i < size; i++)
> +		dir->dir[i] = NULL;
> +
> +	return dir;
> +}		
> +
> +static void tcp_copy_ep_dir(struct tcp_ep_dir *src, struct tcp_ep_dir *dest)
> +{
> +	int i;
> +	for (i=0; i < dest->size; i++)
> +		if (i < src->size)
> +			dest->dir[i] = src->dir[i];
> +}		
> +
> +static void tcp_destroy_ep_dir(struct tcp_ep_dir *dir)
> +{
> +	free(dir);
> +}		
> +
> +static struct tcp_ep_dir* tcp_resize_ep_dir(struct tcp_ep_dir* old_dir, int size)
> +{
> +	struct tcp_ep_dir* new_dir;
> +
> +	new_dir = tcp_create_ep_dir(size);
> +	if (!new_dir)
> +		return NULL;
> +
> +	tcp_copy_ep_dir(old_dir, new_dir);
> +	tcp_destroy_ep_dir(old_dir);
> +	return new_dir;
> +}		
> +
> +int tcp_transport_init(iut_handle_t t)
> +{
> +	int fd, err;
> +	char buf[64];
> +	uint64_t thandle;
> +
> +	/* Initialize the endpoint mapping cache */
> +	tcp_ep_dir = tcp_create_ep_dir(TCP_EP_DIR_INITIAL_SIZE);
> +
> +	/* Get the tcp kernel driver's handle */
> +	fd = open("/sys/class/iscsi_transport/iscsi_tcp_tgt/handle", O_RDONLY);
> +	if (fd < 0)
> +		return fd;
> +	err = read(fd, buf, sizeof(buf));
> +	if (err < 0)
> +		goto out;
> +	thandle = strtoull(buf, NULL, 10);
> +	iscsi_tcp.kernel_handle = thandle;
> +	printf("%s: transport handle = %" PRIx64 "\n", __FUNCTION__, thandle);
> +	err = 0;
> +out:
> +	close(fd);
> +	return err;
> +}
> +
> +static void set_non_blocking(int fd)
> +{
> +	int res = fcntl(fd, F_GETFL);
> +
> +	if (res != -1) {
> +		res = fcntl(fd, F_SETFL, res | O_NONBLOCK);
> +		if (res)
> +			dprintf("unable to set fd flags (%s)!\n", strerror(errno));
> +	} else
> +		dprintf("unable to get fd flags (%s)!\n", strerror(errno));
> +}
> +
> +int tcp_poll_init(iut_handle_t th, struct pollfd *pfds, int listen_max)
> +{
> +	struct addrinfo hints, *res, *res0;
> +	char servname[64];
> +	int i, sock, opt;
> +
> +	memset(servname, 0, sizeof(servname));
> +	snprintf(servname, sizeof(servname), "%d", ISCSI_LISTEN_PORT);
> +
> +	memset(&hints, 0, sizeof(hints));
> +	hints.ai_socktype = SOCK_STREAM;
> +	hints.ai_flags = AI_PASSIVE;
> +
> +	if (getaddrinfo(NULL, servname, &hints, &res0)) {
> +		eprintf("unable to get address info (%s)!\n", strerror(errno));
> +		exit(1);
> +	}
> +
> +	for (i = 0, res = res0; res && i < listen_max; res = res->ai_next) {
> +		sock = socket(res->ai_family, res->ai_socktype, res->ai_protocol);
> +		if (sock < 0) {
> +			eprintf("unable to create server socket (%s) %d %d %d!\n",
> +				  strerror(errno), res->ai_family,
> +				  res->ai_socktype, res->ai_protocol);
> +			continue;
> +		}
> +
> +		opt = 1;
> +		if (setsockopt(sock, SOL_SOCKET, SO_REUSEADDR, &opt, sizeof(opt)))
> +			dprintf("unable to set SO_REUSEADDR on server socket (%s)!\n",
> +				    strerror(errno));
> +		opt = 1;
> +		if (res->ai_family == AF_INET6 &&
> +		    setsockopt(sock, IPPROTO_IPV6, IPV6_V6ONLY, &opt, sizeof(opt)))
> +			continue;
> +
> +		if (bind(sock, res->ai_addr, res->ai_addrlen)) {
> +			eprintf("unable to bind server socket (%s)!\n", strerror(errno));
> +			continue;
> +		}
> +
> +		if (listen(sock, 10)) {
> +			eprintf("unable to listen to server socket (%s)!\n", strerror(errno));
> +			continue;
> +		}
> +
> +		set_non_blocking(sock);
> +
> +		(void)tcp_ep_create(sock);
> +
> +		pfds[i].fd = sock;
> +		pfds[i].events = POLLIN;
> +		i++;
> +	}
> +
> +	freeaddrinfo(res0);
> +	return i;
> +}
> +
> +int tcp_get_poll_fd(iut_handle_t th, 
> +			   iut_ep_handle_t ep_h)
> +{
> +	return (int)(ep_h->kernel_handle);
> +}
> +
> +int tcp_ep_close(iut_handle_t th, iut_ep_handle_t ep_h)
> +{
> +	int fd = (int)ep_h->kernel_handle;
> +	tcp_ep_destroy(ep_h);
> +	return close(fd);
> +}
> +
> +int tcp_ep_write(iut_handle_t th, iut_ep_handle_t ep_h, const void *buf, int len, int cork)
> +{
> +	int rc = 0;
> +	int opt = cork;
> +	setsockopt((int)ep_h->kernel_handle, SOL_TCP, TCP_CORK, 
> +		   &opt, sizeof(opt));
> +
> +	if (len)
> +		rc = write((int)ep_h->kernel_handle, buf, len);
> +
> +	return rc;
> +}
> +
> +int tcp_ep_read(iut_handle_t th, iut_ep_handle_t ep_h, void *buf, int len)
> +{
> +	return read((int)ep_h->kernel_handle, buf, len);
> +}
> +
> +iut_ep_handle_t tcp_ep_lookup(iut_handle_t th, int fd)
> +{
> +	iut_ep_handle_t eh;
> +	if (fd > tcp_ep_dir->size)
> +		return NULL;
> +
> +	eh = tcp_ep_dir->dir[fd];
> +	return eh;
> +}
> +
> +static iut_ep_handle_t tcp_ep_create(int fd)
> +{
> +	iut_ep_handle_t ep = malloc(sizeof(*ep));
> +	if (!ep)
> +		return NULL;
> +
> +	if (fd >= tcp_ep_dir->size) {
> +		struct tcp_ep_dir* new_dir;
> +		new_dir = tcp_resize_ep_dir(tcp_ep_dir, 
> +					    tcp_ep_dir->size+TCP_EP_DIR_BUMP);
> +		if (new_dir == NULL) {
> +			printf("Failure expanding size of TCP endpoint directory\n");
> +			free(ep);
> +			return NULL;
> +		}
> +		tcp_ep_dir = new_dir;
> +	}
> +
> +	ep->kernel_handle = (uint64_t)fd;
> +	ep->transport = &iscsi_tcp;
> +	tcp_ep_dir->dir[fd] = ep;
> +
> +	return ep;
> +}
> +
> +static void tcp_ep_destroy(iut_ep_handle_t ep)
> +{
> +	tcp_ep_dir->dir[(int)ep->kernel_handle] = NULL;
> +	free(ep);
> +}
> +
> +int tcp_ep_accept(iut_handle_t th, iut_ep_handle_t ep_h, 
> +		  iut_ep_handle_t *new_ep_h,
> +		  struct sockaddr *addr, socklen_t *addrlen)
> +{
> +	iut_ep_handle_t new_h;
> +	int new_fd = accept((int)ep_h->kernel_handle, 
> +			    addr, addrlen);
> +
> +	if (new_fd < 0) 
> +		return new_fd;
> +
> +	new_h = tcp_ep_create(new_fd);
> +	if (!new_h) {
> +		close(new_fd);
> +		return -ENOMEM;
> +	}
> +			
> +	*new_ep_h = new_h;
> +	return new_fd;
> +}
> +
> +
> +
> Index: usr/iscsi/Makefile
> ===================================================================
> --- usr/iscsi/Makefile	(revision 532)
> +++ usr/iscsi/Makefile	(working copy)
> @@ -2,7 +2,7 @@
>  LIBS = -lcrypto
>  DAEMON = iscsi.o
>  
> -$(DAEMON): istgt.o conn.o param.o session.o iscsid.o target.o chap.o netlink.o
> +$(DAEMON): istgt.o conn.o param.o session.o iscsid.o target.o chap.o netlink.o iscsi_uspace_transport.o iscsi_transport_tcp.o 
>  	$(CC) -o $@ $^ $(LIBS)
>  
>  clean:
> Index: usr/iscsi/conn.c
> ===================================================================
> --- usr/iscsi/conn.c	(revision 532)
> +++ usr/iscsi/conn.c	(working copy)
> @@ -11,7 +11,6 @@
>  #include <string.h>
>  #include <errno.h>
>  #include <sys/stat.h>
> -
>  #include "iscsid.h"
>  
>  #define ISCSI_CONN_NEW		1
> @@ -74,7 +73,7 @@
>  
>  	conn->session->conn_cnt++;
>  
> -	err = ki->create_conn(thandle, conn->session->ksid, conn->kcid,
> +	err = ki->create_conn(conn->kth, conn->session->ksid, conn->kcid,
>  			      &conn->kcid);
>  	if (err) {
>  		eprintf("%d %d %u %u %u %" PRIx64,
> @@ -86,20 +85,20 @@
>  		/* FIXME */
>  		if (i == ISCSI_PARAM_DATADGST_EN || i == ISCSI_PARAM_HDRDGST_EN)
>  			continue;
> -		if (ki->set_param(thandle, conn->session->ksid, conn->kcid, i,
> +		if (ki->set_param(conn->kth, conn->session->ksid, conn->kcid, i,
>  				  &conn->session_param[i].val,
>  				  sizeof(uint32_t), &err) || err) {
>  			break;
>  		}
>  	}
>  
> -	if (ki->bind_conn(thandle, conn->session->ksid, conn->kcid, fd, 1, &err) || err) {
> +	if (ki->bind_conn(conn->kth, conn->session->ksid, conn->kcid, fd, 1, &err) || err) {
>  		eprintf("%d %d %u %u %u %" PRIx64,
>  			fd, err, conn->cid, conn->stat_sn, conn->exp_stat_sn, sid);
>  		goto out;
>  	}
>  
> -	if (ki->start_conn(thandle, conn->session->ksid, conn->kcid, &err) || err) {
> +	if (ki->start_conn(conn->kth, conn->session->ksid, conn->kcid, &err) || err) {
>  		eprintf("%d %d %u %u %u %" PRIx64,
>  			fd, err, conn->cid, conn->stat_sn, conn->exp_stat_sn, sid);
>  		goto out;
> Index: usr/Makefile
> ===================================================================
> --- usr/Makefile	(revision 532)
> +++ usr/Makefile	(working copy)
> @@ -1,4 +1,4 @@
> -CFLAGS += -O2 -fno-inline -Wall -Wstrict-prototypes -fPIC -I$(KERNELSRC)/include -I../istgt/include -I../include -I. -D_LARGEFILE64_SOURCE
> +CFLAGS += -g -fno-inline -Wall -Wstrict-prototypes -fPIC -I$(KERNELSRC)/include -I../istgt/include -I../include -I. -D_LARGEFILE64_SOURCE
>  PROGRAMS = tgtd tgtadm
>  TGTD_OBJS = tgtd.o tgtif.o mgmt.o target.o scsi.o log.o driver.o util.o
>  
> @@ -9,7 +9,7 @@
>  
>  ifneq ($(ISCSI),)
>  CFLAGS += -DISCSI
> -TGTD_OBJS += $(addprefix iscsi/, istgt.o conn.o param.o session.o iscsid.o target.o chap.o netlink.o)
> +TGTD_OBJS += $(addprefix iscsi/, istgt.o conn.o param.o session.o iscsid.o target.o chap.o netlink.o iscsi_uspace_transport.o iscsi_transport_tcp.o)
>  LIBS = -lcrypto
>  endif
>  
> Index: istgt/include/iscsi_if.h
> ===================================================================
> --- istgt/include/iscsi_if.h	(revision 532)
> +++ istgt/include/iscsi_if.h	(working copy)
> @@ -46,11 +46,14 @@
>  	ISCSI_UEVENT_TRANSPORT_EP_CONNECT	= UEVENT_BASE + 12,
>  	ISCSI_UEVENT_TRANSPORT_EP_POLL		= UEVENT_BASE + 13,
>  	ISCSI_UEVENT_TRANSPORT_EP_DISCONNECT	= UEVENT_BASE + 14,
> +	ISCSI_UEVENT_TRANSPORT_CREATE_LISTEN	= UEVENT_BASE + 15,
> +	ISCSI_UEVENT_TRANSPORT_DESTROY_LISTEN	= UEVENT_BASE + 16,
>  
>  	/* up events */
>  	ISCSI_KEVENT_RECV_PDU		= KEVENT_BASE + 1,
>  	ISCSI_KEVENT_CONN_ERROR		= KEVENT_BASE + 2,
>  	ISCSI_KEVENT_IF_ERROR		= KEVENT_BASE + 3,
> +	ISCSI_KEVENT_NEW_CONN		= KEVENT_BASE + 4,
>  };
>  
>  struct iscsi_uevent {
> @@ -116,6 +119,14 @@
>  		struct msg_transport_disconnect {
>  			uint64_t	ep_handle;
>  		} ep_disconnect;
> +		struct msg_create_listen {
> +			uint32_t	backlog;
> +			struct sockaddr local_addr;
> +			int		local_addr_len;
> +		} c_listen;
> +		struct msg_destroy_listen {
> +			uint32_t	ep_handle;
> +		} d_listen;
>  	} u;
>  	union {
>  		/* messages k -> u */
> @@ -141,6 +152,16 @@
>  		struct msg_transport_connect_ret {
>  			uint64_t	handle;
>  		} ep_connect_ret;
> +		struct msg_ep_new_conn {
> +			uint64_t	ep_handle;
> +			struct sockaddr	local_addr;
> +			int local_addr_len;
> +			struct sockaddr	remote_addr;
> +			int remote_addr_len;
> +		} ep_new_conn;
> +		struct msg_create_listen_ret {
> +			uint64_t	ep_handle;
> +		} c_listen_ret;
>  	} r;
>  } __attribute__ ((aligned (sizeof(uint64_t))));
>  
> Index: usr/iscsi/netlink.c
> ===================================================================
> --- usr/iscsi/netlink.c	(revision 532)
> +++ usr/iscsi/netlink.c	(working copy)
> @@ -298,6 +298,7 @@
>  	return 0;
>  }
>  
> +#if 0
>  static int transport_handle_init(void)
>  {
>  	int fd, err;
> @@ -316,15 +317,17 @@
>  	close(fd);
>  	return err;
>  }
> +#endif
>  
>  int iscsi_nl_init(void)
>  {
>  	int err, rsize = 256 * 1024;
>  
> +#if 0
>  	err = transport_handle_init();
>  	if (err)
>  		return err;
> -
> +#endif
>  	nl_fd = socket(PF_NETLINK, SOCK_RAW, NETLINK_ISCSI);
>  	if (nl_fd < 0) {
>  		eprintf("Fail to create the netlink socket %d\n", errno);
> @@ -358,6 +361,93 @@
>  	return err;
>  }
>  
> +int ktransport_create_listen(uint64_t transport_handle, 
> +			     uint64_t user_context,
> +			     struct sockaddr *sa, int backlog,
> +			     uint64_t *out_ep_handle)
> +{
> +	int rc;
> +	struct iscsi_uevent ev;
> +
> +	dprintf("%"PRIx64 " %p %p %d\n",
> +		transport_handle, out_ep_handle, sa, backlog);
> +
> +	ev.type = ISCSI_UEVENT_TRANSPORT_CREATE_LISTEN;
> +	ev.transport_handle = transport_handle;
> +	// ev.u.c_listen.user_context = user_context;
> +	ev.u.c_listen.backlog = backlog;
> +	ev.u.c_listen.local_addr = *sa;
> +
> +	if ((rc = __kipc_call(&ev, sizeof(ev))) < 0) {
> +		return rc;
> +	}
> +
> +	*out_ep_handle = ev.r.c_listen_ret.ep_handle;
> +
> +	return ev.r.retcode;
> +}
> +
> +int ktransport_destroy_listen(uint64_t transport_handle, uint64_t ep_handle)
> +{
> +	int rc;
> +	struct iscsi_uevent ev;
> +
> +	dprintf("%" PRIx64 " %" PRIx64 "\n",
> +		transport_handle, ep_handle);
> +
> +	ev.type = ISCSI_UEVENT_TRANSPORT_DESTROY_LISTEN;
> +	ev.transport_handle = transport_handle;
> +	ev.u.d_listen.ep_handle = ep_handle;
> +
> +	if ((rc = __kipc_call(&ev, sizeof(ev))) < 0) {
> +		return rc;
> +	}
> +
> +	return ev.r.retcode;
> +}
> +
> +#if 0
> +static int ktransport_accept(uint64_t transport_handle, 
> +		   uint64_t ep_handle, uint64_t ep_context)
> +{
> +	int rc;
> +	struct iscsi_uevent ev;
> +
> +	dprintf("%" PRIx64 " %" PRIx64 " %" PRIx64 "\n",
> +		transport_handle, ep_handle, ep_context);
> +
> +	ev.type = ISCSI_UEVENT_EP_ACCEPT;
> +	ev.transport_handle = transport_handle;
> +	ev.u.ep_accept.ep_handle = ep_handle;
> +	ev.u.ep_accept.ep_context = ep_context;
> +
> +	if ((rc = __kipc_call(&ev, sizeof(ev))) < 0) {
> +		return rc;
> +	}
> +
> +	return ev.r.retcode;
> +}
> +
> +static int ktransport_reject(uint64_t transport_handle, uint64_t ep_handle)
> +{
> +	int rc;
> +	struct iscsi_uevent ev;
> +
> +	dprintf("%" PRIx64 " %" PRIx64 "\n",
> +		transport_handle, ep_handle);
> +
> +	ev.type = ISCSI_UEVENT_EP_REJECT;
> +	ev.transport_handle = transport_handle;
> +	ev.u.ep_reject.ep_handle = ep_handle;
> +
> +	if ((rc = __kipc_call(&ev, sizeof(ev))) < 0) {
> +		return rc;
> +	}
> +
> +	return ev.r.retcode;
> +}
> +#endif
> +
>  struct iscsi_kernel_interface nl_ki = {
>  	.create_session		= kcreate_session,
>  	.destroy_session	= kdestroy_session,
> 
> 
> _______________________________________________
> Stgt-devel mailing list
> Stgt-devel at lists.berlios.de
> https://lists.berlios.de/mailman/listinfo/stgt-devel
> 


From tom at opengridcomputing.com  Tue Aug 22 14:31:05 2006
From: tom at opengridcomputing.com (Tom Tucker)
Date: Tue, 22 Aug 2006 07:31:05 -0500
Subject: [Stgt-devel] session tsih
In-Reply-To: <20060822080215Q.fujita.tomonori@lab.ntt.co.jp>
References: <20060821110106U.fujita.tomonori@lab.ntt.co.jp>
	<200608210448.k7L4mdwp027427@r-dd.iij4u.or.jp>
	<1156181531.11567.36.camel@trinity.ogc.int>
	<20060822080215Q.fujita.tomonori@lab.ntt.co.jp>
Message-ID: <1156249865.31370.1.camel@trinity.ogc.int>

On Tue, 2006-08-22 at 08:02 +0900, FUJITA Tomonori wrote:
> From: Tom Tucker <tom at opengridcomputing.com>
> Subject: [Stgt-devel] session tsih
> Date: Mon, 21 Aug 2006 12:32:11 -0500
> 
> > Tomo:
> > 
> > The session data structure contains a tsih value which is the transport
> > session id. In session destroy it looks like it takes the global thandle
> > (points to tcp's handle currently) and passes this down to
> > ki->destroy_session. 
> > 
> > Since a session may have multiple connections and these connections may
> > be on different transports, don't we have to destroy this session on
> > each transport for which there a connection?
> 
> I'm not sure what you mean. You cannot have iser and tcp connections
> in a session, can you?

Er...actually you "can" with a converged NIC (does both TCP/IP and
RDMA), but I guess the question is really -- "should you". If you say
no, then our life gets easier.





From tom at opengridcomputing.com  Tue Aug 22 14:39:53 2006
From: tom at opengridcomputing.com (Tom Tucker)
Date: Tue, 22 Aug 2006 07:39:53 -0500
Subject: [Stgt-devel] uSpace Transport Patch
In-Reply-To: <20060822081129C.fujita.tomonori@lab.ntt.co.jp>
References: <1155913603.22828.27.camel@trinity.ogc.int>
	<200608201903.k7KJ3cGT016589@r-dd.iij4u.or.jp>
	<1156195780.7484.16.camel@trinity.ogc.int>
	<20060822081129C.fujita.tomonori@lab.ntt.co.jp>
Message-ID: <1156250393.31370.5.camel@trinity.ogc.int>

On Tue, 2006-08-22 at 08:11 +0900, FUJITA Tomonori wrote:
> From: Tom Tucker <tom at opengridcomputing.com>
> Subject: [Stgt-devel] uSpace Transport Patch
> Date: Mon, 21 Aug 2006 16:29:40 -0500
> 
> > Tomo:
> > 
> > Enclosed is a patch that allows you to plug in multiple transports. It
> > has a few benefits over the last approach:
> 
> Thanks.
> 
> 
> > 1. The TCP side can remain exactly the same. i.e. user-mode connection
> > management and login send/recv.
> > 
> > 2. The stgtd implementation still uses pollfd to receive I/O events. The
> >    iser side will provide an fd that can be polled.
> > 
> > 
> > I have built and run this patch with the current code and connected with
> > a iscsi initiator over TCP. I did encounter problems, however, trying to
> > do disk i/o.
> 
> The write path code is broken. I will fix it if the kernel-mode
> approach would likely be accepted into mainline.
> 
> The user-space mode code should work better. As I said in the previous
> mail, I can do mkfs, extract linux kernel tar, etc with the open-iscsi
> default configuration.
> 
> 
> > This is not done, it is a proof-of-concept/design proposal. The netlink
> > stuff will obviously change as I flesh out the iSER side. Please let me
> > know what you think, I'd like your opinion before I get to far down this
> > road.

> I see. I will read this soon. Can you post iSER part code too?

Yes, I'm working on that now, I just didn't want to get too far down a
road that lead somewhere we didn't want to go. Basically, the iSER code
is implemented in the kernel. The user-mode interface is a file
descriptor (used for polling), and a either a) set of methods
implemented via read/write for listening for, accepting and
send/receiving, or b) using the netlink interface. I'm leaning towards
the former actually.

Tom

> 
> 
> > Thanks, 
> > Tom
> > 
> > Index: usr/iscsi/session.c
> > ===================================================================
> > --- usr/iscsi/session.c	(revision 532)
> > +++ usr/iscsi/session.c	(working copy)
> > @@ -112,12 +112,13 @@
> >  
> >  	log_debug("session_create: %#" PRIx64, sid);
> >  
> > -	ki->create_session(thandle, conn->exp_cmd_sn, &session->ksid,
> > +	ki->create_session(conn->kth, conn->exp_cmd_sn, &session->ksid,
> >  			   &session->hostno);
> >  
> >  	list_add(&session->hlist, &sessions_list);
> >  }
> >  
> > +#if 0
> >  void session_remove(struct session *session)
> >  {
> >  	uint64_t sid = sid64(session->isid, session->tsih);
> > @@ -140,3 +141,4 @@
> >  	free(session->initiator);
> >  	free(session);
> >  }
> > +#endif
> > Index: usr/iscsi/iscsid.h
> > ===================================================================
> > --- usr/iscsi/iscsid.h	(revision 532)
> > +++ usr/iscsi/iscsid.h	(working copy)
> > @@ -9,13 +9,14 @@
> >  
> >  #include <sys/types.h>
> >  #include <linux/types.h>
> > -
> > +#include <sys/socket.h>
> > +#include <linux/socket.h>
> >  #include "types.h"
> >  #include "iscsi_if.h"
> >  #include "list.h"
> >  #include "param.h"
> >  #include "log.h"
> > -
> > +#include "iscsi_uspace_transport.h"
> >  #include <scsi/iscsi_proto.h>
> >  
> >  #define ISCSI_NAME_LEN 255
> > @@ -25,7 +26,6 @@
> >  #define DIGEST_NONE		(1 << 0)
> >  #define DIGEST_CRC32C           (1 << 1)
> >  
> > -extern uint64_t thandle;
> >  extern int nl_fd;
> >  
> >  #define sid64(isid, tsih)					\
> > @@ -69,6 +69,7 @@
> >  	int state;
> >  	int iostate;
> >  	int fd;
> > +	uint64_t kth;
> >  
> >  	struct list_head clist;
> >  	struct session *session;
> > Index: usr/iscsi/iscsi_uspace_transport.c
> > ===================================================================
> > --- usr/iscsi/iscsi_uspace_transport.c	(revision 0)
> > +++ usr/iscsi/iscsi_uspace_transport.c	(revision 0)
> > @@ -0,0 +1,118 @@
> > +#include <stdio.h>
> > +#include <stdint.h>
> > +#include <stddef.h>
> > +#include <stdlib.h>
> > +#include <errno.h>
> > +
> > +#include "list.h"
> > +#include "iscsi_uspace_transport.h"
> > +
> > +struct iut_el {
> > +	struct list_head list;
> > +	struct iut *transport;
> > +};
> > +
> > +static LIST_HEAD(iscsi_transport_list);
> > +
> > +extern struct iut iscsi_tcp;
> > +
> > +#if 0
> > +struct iut iscsi_iser = {
> > +	.name = "iser",
> > +	.rdma = 1,
> > +	.init = iser_transport_init,
> > +	.poll_init = iser_poll_init,
> > +	.ep_accept = iser_ep_accept,
> > +	.ep_close = iser_ep_close,
> > +};
> > +#endif
> > +
> > +void iut_init(void)
> > +{
> > +	struct iut_el *el;
> > +
> > +	el = malloc(sizeof(*el));
> > +	el->transport = &iscsi_tcp;
> > +	list_add(&(el->list),  &iscsi_transport_list);
> > +#if 0
> > +	el = malloc(sizeof(*el));
> > +	el->transport = &iscsi_iser;
> > +	list_add(&(el->list),  &iscsi_transport_list);
> > +#endif
> > +	list_for_each_entry(el, &iscsi_transport_list, list)
> > +		el->transport->init(el->transport);
> > +}
> > +
> > +int iut_lookup_handles(int fd, 
> > +		       iut_handle_t *pth,
> > +		       iut_ep_handle_t* peh)
> > +{
> > +	struct iut_el *el;
> > +	iut_ep_handle_t eh;
> > +	int found = 0;
> > +
> > +	list_for_each_entry(el, &iscsi_transport_list, list) {
> > +		eh = iut_ep_lookup(el->transport, fd);
> > +		if (eh) {
> > +			dprintf("found handle = %p for fd = %d\n", 
> > +				eh, fd);
> > +			*pth = el->transport;
> > +			*peh = eh;
> > +			found = 1;
> > +			break;
> > +		}
> > +	}
> > +
> > +	return found;
> > +}
> > +
> > +int iut_poll_init(struct pollfd *pfds, int listen_max)
> > +{
> > +	struct iut_el *el;
> > +	int listen_count = 0;
> > +
> > +	list_for_each_entry(el, &iscsi_transport_list, list) 
> > +		listen_count += el->transport->poll_init(el->transport, 
> > +							 pfds + listen_count, 
> > +							 listen_max - listen_count);
> > +
> > +	return listen_count;
> > +}
> > +
> > +int iut_ep_close(iut_handle_t th, iut_ep_handle_t ep_h)
> > +{
> > +	return th->ep_close(th, ep_h);
> > +}
> > +
> > +int iut_ep_accept(iut_handle_t th, iut_ep_handle_t ep_h,
> > +			 iut_ep_handle_t *new_ep_h,
> > +			 struct sockaddr *addr, socklen_t *addrlen)
> > +{
> > +	return th->ep_accept(th, ep_h, new_ep_h, addr, addrlen);
> > +}
> > +
> > +iut_ep_handle_t iut_ep_lookup(iut_handle_t th, int fd)
> > +{
> > +	return th->ep_lookup(th, fd);
> > +}
> > +
> > +int iut_fd_write(int fd, const void *buf, int buflen, int cork)
> > +{
> > +	iut_handle_t th;
> > +	iut_ep_handle_t ep_h;
> > +	if (iut_lookup_handles(fd, &th, &ep_h))
> > +		return th->ep_write(th, ep_h, buf, buflen, cork);
> > +
> > +	return -ENOENT;
> > +}
> > +
> > +int iut_fd_read(int fd, void *buf, int buflen)
> > +{
> > +	iut_handle_t th;
> > +	iut_ep_handle_t ep_h;
> > +	if (iut_lookup_handles(fd, &th, &ep_h))
> > +		return th->ep_read(th, ep_h, buf, buflen);
> > +
> > +	return -ENOENT;
> > +}
> > +
> > Index: usr/iscsi/istgt.c
> > ===================================================================
> > --- usr/iscsi/istgt.c	(revision 532)
> > +++ usr/iscsi/istgt.c	(working copy)
> > @@ -33,9 +33,8 @@
> >  #include <arpa/inet.h>
> >  
> >  #include "iscsid.h"
> > +#include "iscsi_uspace_transport.h"
> >  
> > -#define ISCSI_LISTEN_PORT	3260
> > -
> >  #define LISTEN_MAX	4
> >  #define INCOMING_MAX	32
> >  
> > @@ -47,92 +46,29 @@
> >  };
> >  
> >  static struct connection *incoming[INCOMING_MAX];
> > -uint64_t thandle;
> >  int nl_fd;
> >  
> > -static void set_non_blocking(int fd)
> > -{
> > -	int res = fcntl(fd, F_GETFL);
> > -
> > -	if (res != -1) {
> > -		res = fcntl(fd, F_SETFL, res | O_NONBLOCK);
> > -		if (res)
> > -			dprintf("unable to set fd flags (%s)!\n", strerror(errno));
> > -	} else
> > -		dprintf("unable to get fd flags (%s)!\n", strerror(errno));
> > -}
> > -
> > -static void listen_socket_create(struct pollfd *pfds)
> > -{
> > -	struct addrinfo hints, *res, *res0;
> > -	char servname[64];
> > -	int i, sock, opt;
> > -
> > -	memset(servname, 0, sizeof(servname));
> > -	snprintf(servname, sizeof(servname), "%d", ISCSI_LISTEN_PORT);
> > -
> > -	memset(&hints, 0, sizeof(hints));
> > -	hints.ai_socktype = SOCK_STREAM;
> > -	hints.ai_flags = AI_PASSIVE;
> > -
> > -	if (getaddrinfo(NULL, servname, &hints, &res0)) {
> > -		eprintf("unable to get address info (%s)!\n", strerror(errno));
> > -		exit(1);
> > -	}
> > -
> > -	for (i = 0, res = res0; res && i < LISTEN_MAX; i++, res = res->ai_next) {
> > -		sock = socket(res->ai_family, res->ai_socktype, res->ai_protocol);
> > -		if (sock < 0) {
> > -			eprintf("unable to create server socket (%s) %d %d %d!\n",
> > -				  strerror(errno), res->ai_family,
> > -				  res->ai_socktype, res->ai_protocol);
> > -			continue;
> > -		}
> > -
> > -		opt = 1;
> > -		if (setsockopt(sock, SOL_SOCKET, SO_REUSEADDR, &opt, sizeof(opt)))
> > -			dprintf("unable to set SO_REUSEADDR on server socket (%s)!\n",
> > -				    strerror(errno));
> > -		opt = 1;
> > -		if (res->ai_family == AF_INET6 &&
> > -		    setsockopt(sock, IPPROTO_IPV6, IPV6_V6ONLY, &opt, sizeof(opt)))
> > -			continue;
> > -
> > -		if (bind(sock, res->ai_addr, res->ai_addrlen)) {
> > -			eprintf("unable to bind server socket (%s)!\n", strerror(errno));
> > -			continue;
> > -		}
> > -
> > -		if (listen(sock, INCOMING_MAX)) {
> > -			eprintf("unable to listen to server socket (%s)!\n", strerror(errno));
> > -			continue;
> > -		}
> > -
> > -		set_non_blocking(sock);
> > -
> > -		pfds[i].fd = sock;
> > -		pfds[i].events = POLLIN;
> > -	}
> > -
> > -	freeaddrinfo(res0);
> > -}
> > -
> >  static void accept_connection(struct pollfd *pfds, int afd)
> >  {
> > -	struct sockaddr_storage from;
> > -	socklen_t namesize;
> > -	struct pollfd *pfd;
> > +	struct sockaddr addr;
> > +	socklen_t addrlen;
> > +	iut_handle_t th;
> > +	iut_ep_handle_t l_eh;
> > +	iut_ep_handle_t new_eh;
> >  	struct connection *conn;
> > -	int fd, i;
> > +	struct pollfd *pfd;
> > +	int i, fd;
> > +	
> > +	if (!iut_lookup_handles(afd, &th, &l_eh)) {
> > +		eprintf("could not find transport handles "
> > +			"for specified fd=%d\n",
> > +		       afd);
> > +		return;
> > +	}
> >  
> > -	eprintf("%d\n", afd);
> > -
> > -	namesize = sizeof(from);
> > -	if ((fd = accept(afd, (struct sockaddr *) &from, &namesize)) < 0) {
> > -		if (errno != EINTR && errno != EAGAIN) {
> > -			eprintf("accept(incoming_socket)\n");
> > -			exit(1);
> > -		}
> > +	fd = iut_ep_accept(th, l_eh, &new_eh, &addr, &addrlen); 
> > +	if (fd < 0) {
> > +		printf("failed to accept incoming connection request\n");
> >  		return;
> >  	}
> >  
> > @@ -150,11 +86,11 @@
> >  		eprintf("fail to allocate conn\n");
> >  		goto out;
> >  	}
> > +	conn->kth = th->kernel_handle;
> >  	conn->fd = fd;
> >  	incoming[i] = conn;
> >  	conn_read_pdu(conn);
> >  
> > -	set_non_blocking(fd);
> >  	pfd = &pfds[POLL_INCOMING + i];
> >  	pfd->fd = fd;
> >  	pfd->events = POLLIN;
> > @@ -162,7 +98,7 @@
> >  
> >  	return;
> >  out:
> > -	close(fd);
> > +	iut_ep_close(th, new_eh);
> >  	return;
> >  }
> >  
> > @@ -170,7 +106,7 @@
> >  {
> >  	struct connection *conn;
> >  	struct pollfd *pfd;
> > -	int i, res, opt;
> > +	int i, res;
> >  
> >  	for (i = 0; i < LISTEN_MAX; i++) {
> >  		if (pfds[POLL_LISTEN + i].revents)
> > @@ -189,14 +125,15 @@
> >  		case IOSTATE_READ_BHS:
> >  		case IOSTATE_READ_AHS_DATA:
> >  		read_again:
> > -			res = read(pfd->fd, conn->buffer, conn->rwsize);
> > +			res = iut_fd_read(pfd->fd, conn->buffer, conn->rwsize);
> >  			if (res <= 0) {
> >  				if (res == 0 || (errno != EINTR && errno != EAGAIN))
> >  					conn->state = STATE_CLOSE;
> >  				else if (errno == EINTR)
> >  					goto read_again;
> >  				break;
> > -			}
> > +			} else
> > +				printf("read %d bytes: \"%s\"\n", res, conn->buffer);
> >  			conn->rwsize -= res;
> >  			conn->buffer += res;
> >  			if (conn->rwsize)
> > @@ -233,9 +170,8 @@
> >  		case IOSTATE_WRITE_AHS:
> >  		case IOSTATE_WRITE_DATA:
> >  		write_again:
> > -			opt = 1;
> > -			setsockopt(pfd->fd, SOL_TCP, TCP_CORK, &opt, sizeof(opt));
> > -			res = write(pfd->fd, conn->buffer, conn->rwsize);
> > +			res = iut_fd_write(pfd->fd, conn->buffer, conn->rwsize, 1);
> > +			printf("wrote %d bytes: \"%s\"\n", conn->rwsize, conn->buffer);
> >  			if (res < 0) {
> >  				if (errno != EINTR && errno != EAGAIN)
> >  					conn->state = STATE_CLOSE;
> > @@ -272,8 +208,7 @@
> >  					goto write_again;
> >  				}
> >  			case IOSTATE_WRITE_DATA:
> > -				opt = 0;
> > -				setsockopt(pfd->fd, SOL_TCP, TCP_CORK, &opt, sizeof(opt));
> > +				iut_fd_write(pfd->fd, NULL, 0, 0);
> >  				cmnd_finish(conn);
> >  
> >  				switch (conn->state) {
> > @@ -312,11 +247,13 @@
> >  int iscsi_poll_init(struct pollfd *pfd)
> >  {
> >  	int i;
> > +	int listeners;
> >  
> >  	pfd[POLL_NL].fd = nl_fd;
> >  	pfd[POLL_NL].events = POLLIN;
> >  
> > -	listen_socket_create(pfd + POLL_LISTEN);
> > +	listeners = iut_poll_init(pfd + POLL_LISTEN, LISTEN_MAX);
> > +	dprintf("%d listeners\n", listeners);
> >  
> >  	for (i = 0; i < INCOMING_MAX; i++) {
> >  		pfd[POLL_INCOMING + i].fd = -1;
> > @@ -332,5 +269,7 @@
> >  	iscsi_nl_init();
> >  	*npfd = POLL_MAX;
> >  
> > +	iut_init();
> > +
> >  	return 0;
> >  }
> > Index: usr/iscsi/iscsi_uspace_transport.h
> > ===================================================================
> > --- usr/iscsi/iscsi_uspace_transport.h	(revision 0)
> > +++ usr/iscsi/iscsi_uspace_transport.h	(revision 0)
> > @@ -0,0 +1,60 @@
> > +#ifndef __ISCSI_USPACE_TRANSPORT_H
> > +#define __ISCSI_USPACE_TRANSPORT_H
> > +
> > +#include <sys/poll.h>
> > +#include <sys/socket.h>
> > +#include "list.h"
> > +
> > +#define ISCSI_LISTEN_PORT	3260
> > +
> > +typedef struct iut_ep_handle {
> > +	uint64_t kernel_handle;
> > +	struct iut *transport;
> > +} *iut_ep_handle_t;
> > +
> > +typedef struct iut *iut_handle_t;
> > +struct iut {
> > +	uint64_t kernel_handle;
> > +	const char *name;
> > +	int rdma;
> > +
> > +	int (*init)(iut_handle_t);
> > +	int (*poll_init)(iut_handle_t th, struct pollfd *, int listen_max);
> > +	int (*ep_close)(iut_handle_t th, iut_ep_handle_t ep_h);
> > +	int (*ep_accept)(iut_handle_t th, iut_ep_handle_t ep_h,
> > +			 iut_ep_handle_t *new_ep_h,
> > +			 struct sockaddr *addr, socklen_t *addrlen);
> > +	iut_ep_handle_t (*ep_lookup)(iut_handle_t th, int fd);
> > +	int (*ep_write)(iut_handle_t th, iut_ep_handle_t ep_h,
> > +			const void *buf, int buflen, int cork);
> > +	int (*ep_read)(iut_handle_t th, iut_ep_handle_t ep_h,
> > +		       void *buf, int buflen);
> > +};
> > +
> > +/* Transport independent functions */
> > +extern int iut_poll_init(struct pollfd *pfds, int);
> > +extern void iut_init(void);
> > +extern int iut_lookup_handles(int fd, iut_handle_t *th, iut_ep_handle_t *eh);
> > +extern int iut_ep_close(iut_handle_t th, iut_ep_handle_t ep_h);
> > +extern int iut_ep_accept(iut_handle_t th, iut_ep_handle_t ep_h,
> > +			 iut_ep_handle_t *new_ep_h,
> > +			 struct sockaddr *addr, socklen_t *addrlen);
> > +extern iut_ep_handle_t iut_ep_lookup(iut_handle_t th, int fd);
> > +extern int iut_fd_write(int fd, const void *buf, int buflen, int cork);
> > +extern int iut_fd_read(int fd, void *buf, int buflen);
> > +
> > +/* TCP Transport Functions */
> > +int tcp_transport_init(iut_handle_t th);
> > +int tcp_poll_init(iut_handle_t, struct pollfd *, int listen_max);
> > +int tcp_get_poll_fd(iut_handle_t th, iut_ep_handle_t ep_h);
> > +int tcp_ep_close(iut_handle_t th, iut_ep_handle_t ep_h);
> > +int tcp_ep_accept(iut_handle_t th, iut_ep_handle_t ep_h,
> > +		  iut_ep_handle_t *new_ep_h,
> > +		  struct sockaddr *addr, socklen_t *addrlen);
> > +iut_ep_handle_t tcp_ep_lookup(iut_handle_t th, int fd);
> > +int tcp_ep_write(iut_handle_t th, iut_ep_handle_t ep_h,
> > +		 const void *buf, int buflen, int cork);
> > +int tcp_ep_read(iut_handle_t th, iut_ep_handle_t ep_h,
> > +		void *buf, int buflen);
> > +
> > +#endif
> > Index: usr/iscsi/iscsi_transport_tcp.c
> > ===================================================================
> > --- usr/iscsi/iscsi_transport_tcp.c	(revision 0)
> > +++ usr/iscsi/iscsi_transport_tcp.c	(revision 0)
> > @@ -0,0 +1,281 @@
> > +#include <ctype.h>
> > +#include <errno.h>
> > +#include <fcntl.h>
> > +#include <stdio.h>
> > +#include <stdlib.h>
> > +#include <string.h>
> > +#include <unistd.h>
> > +#include <getopt.h>
> > +#include <netdb.h>
> > +
> > +#include <sys/poll.h>
> > +#include <sys/socket.h>
> > +#include <sys/stat.h>
> > +#include <sys/types.h>
> > +#include <sys/un.h>
> > +
> > +#include <netinet/in.h>
> > +#include <netinet/tcp.h>
> > +#include <netinet/ip.h>
> > +#include <arpa/inet.h>
> > +
> > +#include "iscsid.h"
> > +#include "list.h"
> > +#include "iscsi_uspace_transport.h"
> > +
> > +struct iut iscsi_tcp = {
> > +	.name = "tcp",
> > +	.rdma = 0,
> > +	.init = tcp_transport_init,
> > +	.poll_init = tcp_poll_init,
> > +	.ep_lookup = tcp_ep_lookup,
> > +	.ep_accept = tcp_ep_accept,
> > +	.ep_close = tcp_ep_close,
> > +	.ep_write = tcp_ep_write,
> > +	.ep_read = tcp_ep_read,
> > +};
> > +
> > +struct tcp_ep_dir {
> > +	int size;
> > +	iut_ep_handle_t dir[0];
> > +};
> > +static struct tcp_ep_dir *tcp_ep_dir;
> > +
> > +static iut_ep_handle_t tcp_ep_create(int fd);
> > +static void tcp_ep_destroy(iut_ep_handle_t ep);
> > +
> > +#define TCP_EP_DIR_INITIAL_SIZE 256
> > +#define TCP_EP_DIR_BUMP		16
> > +static struct tcp_ep_dir* tcp_create_ep_dir(int size)
> > +{
> > +	struct tcp_ep_dir* dir;
> > +	int i;
> > +
> > +	dir = malloc(sizeof(struct tcp_ep_dir) + (sizeof(iut_ep_handle_t)*size));
> > +	if (!dir)
> > +		return NULL;
> > +
> > +	dir->size = size;
> > +	for (i=0; i < size; i++)
> > +		dir->dir[i] = NULL;
> > +
> > +	return dir;
> > +}		
> > +
> > +static void tcp_copy_ep_dir(struct tcp_ep_dir *src, struct tcp_ep_dir *dest)
> > +{
> > +	int i;
> > +	for (i=0; i < dest->size; i++)
> > +		if (i < src->size)
> > +			dest->dir[i] = src->dir[i];
> > +}		
> > +
> > +static void tcp_destroy_ep_dir(struct tcp_ep_dir *dir)
> > +{
> > +	free(dir);
> > +}		
> > +
> > +static struct tcp_ep_dir* tcp_resize_ep_dir(struct tcp_ep_dir* old_dir, int size)
> > +{
> > +	struct tcp_ep_dir* new_dir;
> > +
> > +	new_dir = tcp_create_ep_dir(size);
> > +	if (!new_dir)
> > +		return NULL;
> > +
> > +	tcp_copy_ep_dir(old_dir, new_dir);
> > +	tcp_destroy_ep_dir(old_dir);
> > +	return new_dir;
> > +}		
> > +
> > +int tcp_transport_init(iut_handle_t t)
> > +{
> > +	int fd, err;
> > +	char buf[64];
> > +	uint64_t thandle;
> > +
> > +	/* Initialize the endpoint mapping cache */
> > +	tcp_ep_dir = tcp_create_ep_dir(TCP_EP_DIR_INITIAL_SIZE);
> > +
> > +	/* Get the tcp kernel driver's handle */
> > +	fd = open("/sys/class/iscsi_transport/iscsi_tcp_tgt/handle", O_RDONLY);
> > +	if (fd < 0)
> > +		return fd;
> > +	err = read(fd, buf, sizeof(buf));
> > +	if (err < 0)
> > +		goto out;
> > +	thandle = strtoull(buf, NULL, 10);
> > +	iscsi_tcp.kernel_handle = thandle;
> > +	printf("%s: transport handle = %" PRIx64 "\n", __FUNCTION__, thandle);
> > +	err = 0;
> > +out:
> > +	close(fd);
> > +	return err;
> > +}
> > +
> > +static void set_non_blocking(int fd)
> > +{
> > +	int res = fcntl(fd, F_GETFL);
> > +
> > +	if (res != -1) {
> > +		res = fcntl(fd, F_SETFL, res | O_NONBLOCK);
> > +		if (res)
> > +			dprintf("unable to set fd flags (%s)!\n", strerror(errno));
> > +	} else
> > +		dprintf("unable to get fd flags (%s)!\n", strerror(errno));
> > +}
> > +
> > +int tcp_poll_init(iut_handle_t th, struct pollfd *pfds, int listen_max)
> > +{
> > +	struct addrinfo hints, *res, *res0;
> > +	char servname[64];
> > +	int i, sock, opt;
> > +
> > +	memset(servname, 0, sizeof(servname));
> > +	snprintf(servname, sizeof(servname), "%d", ISCSI_LISTEN_PORT);
> > +
> > +	memset(&hints, 0, sizeof(hints));
> > +	hints.ai_socktype = SOCK_STREAM;
> > +	hints.ai_flags = AI_PASSIVE;
> > +
> > +	if (getaddrinfo(NULL, servname, &hints, &res0)) {
> > +		eprintf("unable to get address info (%s)!\n", strerror(errno));
> > +		exit(1);
> > +	}
> > +
> > +	for (i = 0, res = res0; res && i < listen_max; res = res->ai_next) {
> > +		sock = socket(res->ai_family, res->ai_socktype, res->ai_protocol);
> > +		if (sock < 0) {
> > +			eprintf("unable to create server socket (%s) %d %d %d!\n",
> > +				  strerror(errno), res->ai_family,
> > +				  res->ai_socktype, res->ai_protocol);
> > +			continue;
> > +		}
> > +
> > +		opt = 1;
> > +		if (setsockopt(sock, SOL_SOCKET, SO_REUSEADDR, &opt, sizeof(opt)))
> > +			dprintf("unable to set SO_REUSEADDR on server socket (%s)!\n",
> > +				    strerror(errno));
> > +		opt = 1;
> > +		if (res->ai_family == AF_INET6 &&
> > +		    setsockopt(sock, IPPROTO_IPV6, IPV6_V6ONLY, &opt, sizeof(opt)))
> > +			continue;
> > +
> > +		if (bind(sock, res->ai_addr, res->ai_addrlen)) {
> > +			eprintf("unable to bind server socket (%s)!\n", strerror(errno));
> > +			continue;
> > +		}
> > +
> > +		if (listen(sock, 10)) {
> > +			eprintf("unable to listen to server socket (%s)!\n", strerror(errno));
> > +			continue;
> > +		}
> > +
> > +		set_non_blocking(sock);
> > +
> > +		(void)tcp_ep_create(sock);
> > +
> > +		pfds[i].fd = sock;
> > +		pfds[i].events = POLLIN;
> > +		i++;
> > +	}
> > +
> > +	freeaddrinfo(res0);
> > +	return i;
> > +}
> > +
> > +int tcp_get_poll_fd(iut_handle_t th, 
> > +			   iut_ep_handle_t ep_h)
> > +{
> > +	return (int)(ep_h->kernel_handle);
> > +}
> > +
> > +int tcp_ep_close(iut_handle_t th, iut_ep_handle_t ep_h)
> > +{
> > +	int fd = (int)ep_h->kernel_handle;
> > +	tcp_ep_destroy(ep_h);
> > +	return close(fd);
> > +}
> > +
> > +int tcp_ep_write(iut_handle_t th, iut_ep_handle_t ep_h, const void *buf, int len, int cork)
> > +{
> > +	int rc = 0;
> > +	int opt = cork;
> > +	setsockopt((int)ep_h->kernel_handle, SOL_TCP, TCP_CORK, 
> > +		   &opt, sizeof(opt));
> > +
> > +	if (len)
> > +		rc = write((int)ep_h->kernel_handle, buf, len);
> > +
> > +	return rc;
> > +}
> > +
> > +int tcp_ep_read(iut_handle_t th, iut_ep_handle_t ep_h, void *buf, int len)
> > +{
> > +	return read((int)ep_h->kernel_handle, buf, len);
> > +}
> > +
> > +iut_ep_handle_t tcp_ep_lookup(iut_handle_t th, int fd)
> > +{
> > +	iut_ep_handle_t eh;
> > +	if (fd > tcp_ep_dir->size)
> > +		return NULL;
> > +
> > +	eh = tcp_ep_dir->dir[fd];
> > +	return eh;
> > +}
> > +
> > +static iut_ep_handle_t tcp_ep_create(int fd)
> > +{
> > +	iut_ep_handle_t ep = malloc(sizeof(*ep));
> > +	if (!ep)
> > +		return NULL;
> > +
> > +	if (fd >= tcp_ep_dir->size) {
> > +		struct tcp_ep_dir* new_dir;
> > +		new_dir = tcp_resize_ep_dir(tcp_ep_dir, 
> > +					    tcp_ep_dir->size+TCP_EP_DIR_BUMP);
> > +		if (new_dir == NULL) {
> > +			printf("Failure expanding size of TCP endpoint directory\n");
> > +			free(ep);
> > +			return NULL;
> > +		}
> > +		tcp_ep_dir = new_dir;
> > +	}
> > +
> > +	ep->kernel_handle = (uint64_t)fd;
> > +	ep->transport = &iscsi_tcp;
> > +	tcp_ep_dir->dir[fd] = ep;
> > +
> > +	return ep;
> > +}
> > +
> > +static void tcp_ep_destroy(iut_ep_handle_t ep)
> > +{
> > +	tcp_ep_dir->dir[(int)ep->kernel_handle] = NULL;
> > +	free(ep);
> > +}
> > +
> > +int tcp_ep_accept(iut_handle_t th, iut_ep_handle_t ep_h, 
> > +		  iut_ep_handle_t *new_ep_h,
> > +		  struct sockaddr *addr, socklen_t *addrlen)
> > +{
> > +	iut_ep_handle_t new_h;
> > +	int new_fd = accept((int)ep_h->kernel_handle, 
> > +			    addr, addrlen);
> > +
> > +	if (new_fd < 0) 
> > +		return new_fd;
> > +
> > +	new_h = tcp_ep_create(new_fd);
> > +	if (!new_h) {
> > +		close(new_fd);
> > +		return -ENOMEM;
> > +	}
> > +			
> > +	*new_ep_h = new_h;
> > +	return new_fd;
> > +}
> > +
> > +
> > +
> > Index: usr/iscsi/Makefile
> > ===================================================================
> > --- usr/iscsi/Makefile	(revision 532)
> > +++ usr/iscsi/Makefile	(working copy)
> > @@ -2,7 +2,7 @@
> >  LIBS = -lcrypto
> >  DAEMON = iscsi.o
> >  
> > -$(DAEMON): istgt.o conn.o param.o session.o iscsid.o target.o chap.o netlink.o
> > +$(DAEMON): istgt.o conn.o param.o session.o iscsid.o target.o chap.o netlink.o iscsi_uspace_transport.o iscsi_transport_tcp.o 
> >  	$(CC) -o $@ $^ $(LIBS)
> >  
> >  clean:
> > Index: usr/iscsi/conn.c
> > ===================================================================
> > --- usr/iscsi/conn.c	(revision 532)
> > +++ usr/iscsi/conn.c	(working copy)
> > @@ -11,7 +11,6 @@
> >  #include <string.h>
> >  #include <errno.h>
> >  #include <sys/stat.h>
> > -
> >  #include "iscsid.h"
> >  
> >  #define ISCSI_CONN_NEW		1
> > @@ -74,7 +73,7 @@
> >  
> >  	conn->session->conn_cnt++;
> >  
> > -	err = ki->create_conn(thandle, conn->session->ksid, conn->kcid,
> > +	err = ki->create_conn(conn->kth, conn->session->ksid, conn->kcid,
> >  			      &conn->kcid);
> >  	if (err) {
> >  		eprintf("%d %d %u %u %u %" PRIx64,
> > @@ -86,20 +85,20 @@
> >  		/* FIXME */
> >  		if (i == ISCSI_PARAM_DATADGST_EN || i == ISCSI_PARAM_HDRDGST_EN)
> >  			continue;
> > -		if (ki->set_param(thandle, conn->session->ksid, conn->kcid, i,
> > +		if (ki->set_param(conn->kth, conn->session->ksid, conn->kcid, i,
> >  				  &conn->session_param[i].val,
> >  				  sizeof(uint32_t), &err) || err) {
> >  			break;
> >  		}
> >  	}
> >  
> > -	if (ki->bind_conn(thandle, conn->session->ksid, conn->kcid, fd, 1, &err) || err) {
> > +	if (ki->bind_conn(conn->kth, conn->session->ksid, conn->kcid, fd, 1, &err) || err) {
> >  		eprintf("%d %d %u %u %u %" PRIx64,
> >  			fd, err, conn->cid, conn->stat_sn, conn->exp_stat_sn, sid);
> >  		goto out;
> >  	}
> >  
> > -	if (ki->start_conn(thandle, conn->session->ksid, conn->kcid, &err) || err) {
> > +	if (ki->start_conn(conn->kth, conn->session->ksid, conn->kcid, &err) || err) {
> >  		eprintf("%d %d %u %u %u %" PRIx64,
> >  			fd, err, conn->cid, conn->stat_sn, conn->exp_stat_sn, sid);
> >  		goto out;
> > Index: usr/Makefile
> > ===================================================================
> > --- usr/Makefile	(revision 532)
> > +++ usr/Makefile	(working copy)
> > @@ -1,4 +1,4 @@
> > -CFLAGS += -O2 -fno-inline -Wall -Wstrict-prototypes -fPIC -I$(KERNELSRC)/include -I../istgt/include -I../include -I. -D_LARGEFILE64_SOURCE
> > +CFLAGS += -g -fno-inline -Wall -Wstrict-prototypes -fPIC -I$(KERNELSRC)/include -I../istgt/include -I../include -I. -D_LARGEFILE64_SOURCE
> >  PROGRAMS = tgtd tgtadm
> >  TGTD_OBJS = tgtd.o tgtif.o mgmt.o target.o scsi.o log.o driver.o util.o
> >  
> > @@ -9,7 +9,7 @@
> >  
> >  ifneq ($(ISCSI),)
> >  CFLAGS += -DISCSI
> > -TGTD_OBJS += $(addprefix iscsi/, istgt.o conn.o param.o session.o iscsid.o target.o chap.o netlink.o)
> > +TGTD_OBJS += $(addprefix iscsi/, istgt.o conn.o param.o session.o iscsid.o target.o chap.o netlink.o iscsi_uspace_transport.o iscsi_transport_tcp.o)
> >  LIBS = -lcrypto
> >  endif
> >  
> > Index: istgt/include/iscsi_if.h
> > ===================================================================
> > --- istgt/include/iscsi_if.h	(revision 532)
> > +++ istgt/include/iscsi_if.h	(working copy)
> > @@ -46,11 +46,14 @@
> >  	ISCSI_UEVENT_TRANSPORT_EP_CONNECT	= UEVENT_BASE + 12,
> >  	ISCSI_UEVENT_TRANSPORT_EP_POLL		= UEVENT_BASE + 13,
> >  	ISCSI_UEVENT_TRANSPORT_EP_DISCONNECT	= UEVENT_BASE + 14,
> > +	ISCSI_UEVENT_TRANSPORT_CREATE_LISTEN	= UEVENT_BASE + 15,
> > +	ISCSI_UEVENT_TRANSPORT_DESTROY_LISTEN	= UEVENT_BASE + 16,
> >  
> >  	/* up events */
> >  	ISCSI_KEVENT_RECV_PDU		= KEVENT_BASE + 1,
> >  	ISCSI_KEVENT_CONN_ERROR		= KEVENT_BASE + 2,
> >  	ISCSI_KEVENT_IF_ERROR		= KEVENT_BASE + 3,
> > +	ISCSI_KEVENT_NEW_CONN		= KEVENT_BASE + 4,
> >  };
> >  
> >  struct iscsi_uevent {
> > @@ -116,6 +119,14 @@
> >  		struct msg_transport_disconnect {
> >  			uint64_t	ep_handle;
> >  		} ep_disconnect;
> > +		struct msg_create_listen {
> > +			uint32_t	backlog;
> > +			struct sockaddr local_addr;
> > +			int		local_addr_len;
> > +		} c_listen;
> > +		struct msg_destroy_listen {
> > +			uint32_t	ep_handle;
> > +		} d_listen;
> >  	} u;
> >  	union {
> >  		/* messages k -> u */
> > @@ -141,6 +152,16 @@
> >  		struct msg_transport_connect_ret {
> >  			uint64_t	handle;
> >  		} ep_connect_ret;
> > +		struct msg_ep_new_conn {
> > +			uint64_t	ep_handle;
> > +			struct sockaddr	local_addr;
> > +			int local_addr_len;
> > +			struct sockaddr	remote_addr;
> > +			int remote_addr_len;
> > +		} ep_new_conn;
> > +		struct msg_create_listen_ret {
> > +			uint64_t	ep_handle;
> > +		} c_listen_ret;
> >  	} r;
> >  } __attribute__ ((aligned (sizeof(uint64_t))));
> >  
> > Index: usr/iscsi/netlink.c
> > ===================================================================
> > --- usr/iscsi/netlink.c	(revision 532)
> > +++ usr/iscsi/netlink.c	(working copy)
> > @@ -298,6 +298,7 @@
> >  	return 0;
> >  }
> >  
> > +#if 0
> >  static int transport_handle_init(void)
> >  {
> >  	int fd, err;
> > @@ -316,15 +317,17 @@
> >  	close(fd);
> >  	return err;
> >  }
> > +#endif
> >  
> >  int iscsi_nl_init(void)
> >  {
> >  	int err, rsize = 256 * 1024;
> >  
> > +#if 0
> >  	err = transport_handle_init();
> >  	if (err)
> >  		return err;
> > -
> > +#endif
> >  	nl_fd = socket(PF_NETLINK, SOCK_RAW, NETLINK_ISCSI);
> >  	if (nl_fd < 0) {
> >  		eprintf("Fail to create the netlink socket %d\n", errno);
> > @@ -358,6 +361,93 @@
> >  	return err;
> >  }
> >  
> > +int ktransport_create_listen(uint64_t transport_handle, 
> > +			     uint64_t user_context,
> > +			     struct sockaddr *sa, int backlog,
> > +			     uint64_t *out_ep_handle)
> > +{
> > +	int rc;
> > +	struct iscsi_uevent ev;
> > +
> > +	dprintf("%"PRIx64 " %p %p %d\n",
> > +		transport_handle, out_ep_handle, sa, backlog);
> > +
> > +	ev.type = ISCSI_UEVENT_TRANSPORT_CREATE_LISTEN;
> > +	ev.transport_handle = transport_handle;
> > +	// ev.u.c_listen.user_context = user_context;
> > +	ev.u.c_listen.backlog = backlog;
> > +	ev.u.c_listen.local_addr = *sa;
> > +
> > +	if ((rc = __kipc_call(&ev, sizeof(ev))) < 0) {
> > +		return rc;
> > +	}
> > +
> > +	*out_ep_handle = ev.r.c_listen_ret.ep_handle;
> > +
> > +	return ev.r.retcode;
> > +}
> > +
> > +int ktransport_destroy_listen(uint64_t transport_handle, uint64_t ep_handle)
> > +{
> > +	int rc;
> > +	struct iscsi_uevent ev;
> > +
> > +	dprintf("%" PRIx64 " %" PRIx64 "\n",
> > +		transport_handle, ep_handle);
> > +
> > +	ev.type = ISCSI_UEVENT_TRANSPORT_DESTROY_LISTEN;
> > +	ev.transport_handle = transport_handle;
> > +	ev.u.d_listen.ep_handle = ep_handle;
> > +
> > +	if ((rc = __kipc_call(&ev, sizeof(ev))) < 0) {
> > +		return rc;
> > +	}
> > +
> > +	return ev.r.retcode;
> > +}
> > +
> > +#if 0
> > +static int ktransport_accept(uint64_t transport_handle, 
> > +		   uint64_t ep_handle, uint64_t ep_context)
> > +{
> > +	int rc;
> > +	struct iscsi_uevent ev;
> > +
> > +	dprintf("%" PRIx64 " %" PRIx64 " %" PRIx64 "\n",
> > +		transport_handle, ep_handle, ep_context);
> > +
> > +	ev.type = ISCSI_UEVENT_EP_ACCEPT;
> > +	ev.transport_handle = transport_handle;
> > +	ev.u.ep_accept.ep_handle = ep_handle;
> > +	ev.u.ep_accept.ep_context = ep_context;
> > +
> > +	if ((rc = __kipc_call(&ev, sizeof(ev))) < 0) {
> > +		return rc;
> > +	}
> > +
> > +	return ev.r.retcode;
> > +}
> > +
> > +static int ktransport_reject(uint64_t transport_handle, uint64_t ep_handle)
> > +{
> > +	int rc;
> > +	struct iscsi_uevent ev;
> > +
> > +	dprintf("%" PRIx64 " %" PRIx64 "\n",
> > +		transport_handle, ep_handle);
> > +
> > +	ev.type = ISCSI_UEVENT_EP_REJECT;
> > +	ev.transport_handle = transport_handle;
> > +	ev.u.ep_reject.ep_handle = ep_handle;
> > +
> > +	if ((rc = __kipc_call(&ev, sizeof(ev))) < 0) {
> > +		return rc;
> > +	}
> > +
> > +	return ev.r.retcode;
> > +}
> > +#endif
> > +
> >  struct iscsi_kernel_interface nl_ki = {
> >  	.create_session		= kcreate_session,
> >  	.destroy_session	= kdestroy_session,
> > 
> > 
> > _______________________________________________
> > Stgt-devel mailing list
> > Stgt-devel at lists.berlios.de
> > https://lists.berlios.de/mailman/listinfo/stgt-devel
> > 



From fujita.tomonori at lab.ntt.co.jp  Tue Aug 22 15:56:01 2006
From: fujita.tomonori at lab.ntt.co.jp (FUJITA Tomonori)
Date: Tue, 22 Aug 2006 22:56:01 +0900
Subject: [Stgt-devel] session tsih
In-Reply-To: <1156249865.31370.1.camel@trinity.ogc.int>
References: <1156181531.11567.36.camel@trinity.ogc.int>
	<20060822080215Q.fujita.tomonori@lab.ntt.co.jp>
	<1156249865.31370.1.camel@trinity.ogc.int>
Message-ID: <20060822225601L.fujita.tomonori@lab.ntt.co.jp>

From: Tom Tucker <tom at opengridcomputing.com>
Subject: Re: [Stgt-devel] session tsih
Date: Tue, 22 Aug 2006 07:31:05 -0500

> On Tue, 2006-08-22 at 08:02 +0900, FUJITA Tomonori wrote:
> > From: Tom Tucker <tom at opengridcomputing.com>
> > Subject: [Stgt-devel] session tsih
> > Date: Mon, 21 Aug 2006 12:32:11 -0500
> > 
> > > Tomo:
> > > 
> > > The session data structure contains a tsih value which is the transport
> > > session id. In session destroy it looks like it takes the global thandle
> > > (points to tcp's handle currently) and passes this down to
> > > ki->destroy_session. 
> > > 
> > > Since a session may have multiple connections and these connections may
> > > be on different transports, don't we have to destroy this session on
> > > each transport for which there a connection?
> > 
> > I'm not sure what you mean. You cannot have iser and tcp connections
> > in a session, can you?
> 
> Er...actually you "can" with a converged NIC (does both TCP/IP and
> RDMA), but I guess the question is really -- "should you". If you say
> no, then our life gets easier.

Let me make sure that we are talking about the same thing.

Does the iSER spec (2.3 protocol overview) say that an entire iSCSI
session can only operate in one mode (i.e. a connection in a session
cannot operate in iSER-assisted mode if a different connection of the
same session is already in full feature phase in the traditional iSCSI
mode)?

So I'm not sure about your comment, 'a session may have multiple
connections and these connections may be on different transports.'


From tom at opengridcomputing.com  Tue Aug 22 15:58:12 2006
From: tom at opengridcomputing.com (Tom Tucker)
Date: Tue, 22 Aug 2006 08:58:12 -0500
Subject: [Stgt-devel] session tsih
In-Reply-To: <20060822225601L.fujita.tomonori@lab.ntt.co.jp>
References: <1156181531.11567.36.camel@trinity.ogc.int>
	<20060822080215Q.fujita.tomonori@lab.ntt.co.jp>
	<1156249865.31370.1.camel@trinity.ogc.int>
	<20060822225601L.fujita.tomonori@lab.ntt.co.jp>
Message-ID: <1156255092.31370.11.camel@trinity.ogc.int>

[...snip..]
> > 
> > Er...actually you "can" with a converged NIC (does both TCP/IP and
> > RDMA), but I guess the question is really -- "should you". If you say
> > no, then our life gets easier.
> 
> Let me make sure that we are talking about the same thing.
> 
> Does the iSER spec (2.3 protocol overview) say that an entire iSCSI
> session can only operate in one mode (i.e. a connection in a session
> cannot operate in iSER-assisted mode if a different connection of the
> same session is already in full feature phase in the traditional iSCSI
> mode)?
> 

When I said 'can', I meant it's technically possible, I didn't mean
"allowed". I'll go look at the spec and see....

> So I'm not sure about your comment, 'a session may have multiple
> connections and these connections may be on different transports.'




From fujita.tomonori at lab.ntt.co.jp  Tue Aug 22 16:42:35 2006
From: fujita.tomonori at lab.ntt.co.jp (FUJITA Tomonori)
Date: Tue, 22 Aug 2006 23:42:35 +0900
Subject: [Stgt-devel] uSpace Transport Patch
In-Reply-To: <1156250393.31370.5.camel@trinity.ogc.int>
References: <1156195780.7484.16.camel@trinity.ogc.int>
	<20060822081129C.fujita.tomonori@lab.ntt.co.jp>
	<1156250393.31370.5.camel@trinity.ogc.int>
Message-ID: <20060822234235P.fujita.tomonori@lab.ntt.co.jp>

From: Tom Tucker <tom at opengridcomputing.com>
Subject: Re: [Stgt-devel] uSpace Transport Patch
Date: Tue, 22 Aug 2006 07:39:53 -0500

> On Tue, 2006-08-22 at 08:11 +0900, FUJITA Tomonori wrote:
> > From: Tom Tucker <tom at opengridcomputing.com>
> > Subject: [Stgt-devel] uSpace Transport Patch
> > Date: Mon, 21 Aug 2006 16:29:40 -0500
> > 
> > > Tomo:
> > > 
> > > Enclosed is a patch that allows you to plug in multiple transports. It
> > > has a few benefits over the last approach:
> > 
> > Thanks.
> > 
> > 
> > > 1. The TCP side can remain exactly the same. i.e. user-mode connection
> > > management and login send/recv.
> > > 
> > > 2. The stgtd implementation still uses pollfd to receive I/O events. The
> > >    iser side will provide an fd that can be polled.
> > > 
> > > 
> > > I have built and run this patch with the current code and connected with
> > > a iscsi initiator over TCP. I did encounter problems, however, trying to
> > > do disk i/o.
> > 
> > The write path code is broken. I will fix it if the kernel-mode
> > approach would likely be accepted into mainline.
> > 
> > The user-space mode code should work better. As I said in the previous
> > mail, I can do mkfs, extract linux kernel tar, etc with the open-iscsi
> > default configuration.
> > 
> > 
> > > This is not done, it is a proof-of-concept/design proposal. The netlink
> > > stuff will obviously change as I flesh out the iSER side. Please let me
> > > know what you think, I'd like your opinion before I get to far down this
> > > road.
> 
> > I see. I will read this soon. Can you post iSER part code too?
> 
> Yes, I'm working on that now, I just didn't want to get too far down a
> road that lead somewhere we didn't want to go. Basically, the iSER code
> is implemented in the kernel. The user-mode interface is a file
> descriptor (used for polling), and a either a) set of methods
> implemented via read/write for listening for, accepting and
> send/receiving, or b) using the netlink interface. I'm leaning towards
> the former actually.

The previous patch uses the latter approach (similar to open-iscsi),
right? So, could you explain the formaer approach a bit further?


From tom at opengridcomputing.com  Tue Aug 22 17:17:09 2006
From: tom at opengridcomputing.com (Tom Tucker)
Date: Tue, 22 Aug 2006 10:17:09 -0500
Subject: [Stgt-devel] uSpace Transport Patch
In-Reply-To: <20060822234235P.fujita.tomonori@lab.ntt.co.jp>
References: <1156195780.7484.16.camel@trinity.ogc.int>
	<20060822081129C.fujita.tomonori@lab.ntt.co.jp>
	<1156250393.31370.5.camel@trinity.ogc.int>
	<20060822234235P.fujita.tomonori@lab.ntt.co.jp>
Message-ID: <1156259829.31370.34.camel@trinity.ogc.int>

> > 
[...snip...]
> > Yes, I'm working on that now, I just didn't want to get too far down a
> > road that lead somewhere we didn't want to go. Basically, the iSER code
> > is implemented in the kernel. The user-mode interface is a file
> > descriptor (used for polling), and a either a) set of methods
> > implemented via read/write for listening for, accepting and
> > send/receiving, or b) using the netlink interface. I'm leaning towards
> > the former actually.
> 
> The previous patch uses the latter approach (similar to open-iscsi),
> right? So, could you explain the formaer approach a bit further?

- The existing netlink messages stay the way they are. That is, we don't
add any new ones.

- The iSER kernel driver has a character device file in 
  /sys/class/iscsi_transport/iscsi_iser_tgt/listen. When the client
  (istgt) opens this file, it receives a file descriptor that refers 
  to an in-kernel rdma connection id. The iut binds to a specific
  address and port by write-ing the desired sockaddr and port number. 
  The return  value from the write is the result of the bind.

- A poll of this file descriptor will return an revent when there is an 
  inbound connection request.

- The iut_ reads from the listen_fd to receive the fd for the 
  new connection along with the local and remote sockaddr and len.

- The iut continues with login by calling 'read' and 'write' on the new
  fd to send and receive data login messages. Likewise, a poll of the
  fd will return an revent when there is data to read and/or can-write-more.

- The iut moves the transport to the kernel just like it does today by
  sending a netlink message to the transport.

This approach allows us to leverage the open/read/write/poll semantics of 
an fd without muxing it all over a netlink socket.

Tom




From fujita.tomonori at lab.ntt.co.jp  Tue Aug 29 16:31:27 2006
From: fujita.tomonori at lab.ntt.co.jp (FUJITA Tomonori)
Date: Tue, 29 Aug 2006 23:31:27 +0900
Subject: [Stgt-devel] uSpace Transport Patch
In-Reply-To: <20060822081129C.fujita.tomonori@lab.ntt.co.jp>
References: <200608201903.k7KJ3cGT016589@r-dd.iij4u.or.jp>
	<1156195780.7484.16.camel@trinity.ogc.int>
	<20060822081129C.fujita.tomonori@lab.ntt.co.jp>
Message-ID: <200608291431.k7TEVSRv006660@r-dd.iij4u.or.jp>

From: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
Subject: Re: [Stgt-devel] uSpace Transport Patch
Date: Tue, 22 Aug 2006 08:11:29 +0900

> From: Tom Tucker <tom at opengridcomputing.com>
> Subject: [Stgt-devel] uSpace Transport Patch
> Date: Mon, 21 Aug 2006 16:29:40 -0500
> 
> > Tomo:
> > 
> > Enclosed is a patch that allows you to plug in multiple transports. It
> > has a few benefits over the last approach:
> 
> Thanks.
> 
> 
> > 1. The TCP side can remain exactly the same. i.e. user-mode connection
> > management and login send/recv.
> > 
> > 2. The stgtd implementation still uses pollfd to receive I/O events. The
> >    iser side will provide an fd that can be polled.
> > 
> > 
> > I have built and run this patch with the current code and connected with
> > a iscsi initiator over TCP. I did encounter problems, however, trying to
> > do disk i/o.
> 
> The write path code is broken. I will fix it if the kernel-mode
> approach would likely be accepted into mainline.

Mike posted the kernel-mode iSCSI target patch to scsi-ml several days
ago.

http://marc.theaimsgroup.com/?l=linux-scsi&m=115639258024577&w=2

We've got any responses so far. It means that we might get a refusal
later on after some effort on the kernel-mode approach. That inclines
me to go with the user-space approach...


From tom at opengridcomputing.com  Tue Aug 29 16:47:59 2006
From: tom at opengridcomputing.com (Tom Tucker)
Date: Tue, 29 Aug 2006 09:47:59 -0500
Subject: [Stgt-devel] uSpace Transport Patch
In-Reply-To: <200608291431.k7TEVSRv006660@r-dd.iij4u.or.jp>
References: <200608201903.k7KJ3cGT016589@r-dd.iij4u.or.jp>
	<1156195780.7484.16.camel@trinity.ogc.int>
	<20060822081129C.fujita.tomonori@lab.ntt.co.jp>
	<200608291431.k7TEVSRv006660@r-dd.iij4u.or.jp>
Message-ID: <A66B1215-13BB-4CC7-B090-FF8000039969@opengridcomputing.com>

Tomo:

At this point, I'm in thee middle of writing the kernel side of the  
iSER transport. It would be no big deal to switch to user mode.  
Should I do it?

We might want to look at the OpenFabric's stack to see how they  
implement kernel bypass. This code has been accepted by kernel.org  
and might provide a workable model or at least a starting point for  
the user-mode iSER target implementation. It supports a very high  
bandwidth, zero copy mechanism for exchanging data and events with  
the kernel.

On Aug 29, 2006, at 9:31 AM, FUJITA Tomonori wrote:

> From: FUJITA Tomonori <fujita.tomonori at lab.ntt.co.jp>
> Subject: Re: [Stgt-devel] uSpace Transport Patch
> Date: Tue, 22 Aug 2006 08:11:29 +0900
>
>> From: Tom Tucker <tom at opengridcomputing.com>
>> Subject: [Stgt-devel] uSpace Transport Patch
>> Date: Mon, 21 Aug 2006 16:29:40 -0500
>>
>>> Tomo:
>>>
>>> Enclosed is a patch that allows you to plug in multiple  
>>> transports. It
>>> has a few benefits over the last approach:
>>
>> Thanks.
>>
>>
>>> 1. The TCP side can remain exactly the same. i.e. user-mode  
>>> connection
>>> management and login send/recv.
>>>
>>> 2. The stgtd implementation still uses pollfd to receive I/O  
>>> events. The
>>>    iser side will provide an fd that can be polled.
>>>
>>>
>>> I have built and run this patch with the current code and  
>>> connected with
>>> a iscsi initiator over TCP. I did encounter problems, however,  
>>> trying to
>>> do disk i/o.
>>
>> The write path code is broken. I will fix it if the kernel-mode
>> approach would likely be accepted into mainline.
>
> Mike posted the kernel-mode iSCSI target patch to scsi-ml several days
> ago.
>
> http://marc.theaimsgroup.com/?l=linux-scsi&m=115639258024577&w=2
>
> We've got any responses so far. It means that we might get a refusal
> later on after some effort on the kernel-mode approach. That inclines
> me to go with the user-space approach...
> _______________________________________________
> Stgt-devel mailing list
> Stgt-devel at lists.berlios.de
> https://lists.berlios.de/mailman/listinfo/stgt-devel



From fujita.tomonori at lab.ntt.co.jp  Wed Aug 30 00:23:15 2006
From: fujita.tomonori at lab.ntt.co.jp (FUJITA Tomonori)
Date: Wed, 30 Aug 2006 07:23:15 +0900 (JST)
Subject: [Stgt-devel] uSpace Transport Patch
In-Reply-To: <A66B1215-13BB-4CC7-B090-FF8000039969@opengridcomputing.com>
References: <20060822081129C.fujita.tomonori@lab.ntt.co.jp>
	<200608291431.k7TEVSRv006660@r-dd.iij4u.or.jp>
	<A66B1215-13BB-4CC7-B090-FF8000039969@opengridcomputing.com>
Message-ID: <20060831072542K.fujita.tomonori@lab.ntt.co.jp>

From: Tom Tucker <tom at opengridcomputing.com>
Subject: Re: [Stgt-devel] uSpace Transport Patch
Date: Tue, 29 Aug 2006 09:47:59 -0500

> Tomo:
> 
> At this point, I'm in thee middle of writing the kernel side of the  
> iSER transport. It would be no big deal to switch to user mode.  
> Should I do it?

I like to go with the user-space approach if it provides reasonable
performance. I cannot risk getting a refusal after a serious effort.
I don't like to duplicate open-iscsi kernel-space code in user-space,
however, it's much better than the future refusal.

The perfromance should be fine for iSER. For tcp, we would see small
drop, however, it should be fine. I've been working on the user-space
approach to see the performance. I replaced poll with epoll and added
AIO support. I'm making the out-of-date user-space code work with the
latest code. That sould be finished shortly.

I guess that I can merge the basic transport part of your latest
patch.


> We might want to look at the OpenFabric's stack to see how they  
> implement kernel bypass. This code has been accepted by kernel.org  
> and might provide a workable model or at least a starting point for  
> the user-mode iSER target implementation. It supports a very high  
> bandwidth, zero copy mechanism for exchanging data and events with  
> the kernel.

Sounds nice. I guess that you mean that user-space processes can
access to hardware without kernel intervention. Are documents about
the APIs available? I have some questions about event notifications,
etc.



From tom at opengridcomputing.com  Wed Aug 30 03:42:29 2006
From: tom at opengridcomputing.com (Tom Tucker)
Date: Tue, 29 Aug 2006 20:42:29 -0500
Subject: [Stgt-devel] uSpace Transport Patch
In-Reply-To: <20060830093620V.fujita.tomonori@lab.ntt.co.jp>
References: <A66B1215-13BB-4CC7-B090-FF8000039969@opengridcomputing.com>
	<20060831072542K.fujita.tomonori@lab.ntt.co.jp>
	<D1F4BAC9-36FA-4537-83EC-1CDF8F23D6B6@opengridcomputing.com>
	<20060830093620V.fujita.tomonori@lab.ntt.co.jp>
Message-ID: <4A1CC24C-CDE0-489E-B0BA-4BFB5AC1284F@opengridcomputing.com>


On Aug 29, 2006, at 7:36 PM, FUJITA Tomonori wrote:

> From: Tom Tucker <tom at opengridcomputing.com>
> Subject: Re: [Stgt-devel] uSpace Transport Patch
> Date: Tue, 29 Aug 2006 19:17:09 -0500
>
>> On Aug 29, 2006, at 5:23 PM, FUJITA Tomonori wrote:
>>
>>> From: Tom Tucker <tom at opengridcomputing.com>
>>> Subject: Re: [Stgt-devel] uSpace Transport Patch
>>> Date: Tue, 29 Aug 2006 09:47:59 -0500
>>>
>>>> Tomo:
>>>>
>>>> At this point, I'm in thee middle of writing the kernel side of the
>>>> iSER transport. It would be no big deal to switch to user mode.
>>>> Should I do it?
>>>
>>> I like to go with the user-space approach if it provides reasonable
>>> performance. I cannot risk getting a refusal after a serious effort.
>>> I don't like to duplicate open-iscsi kernel-space code in user- 
>>> space,
>>> however, it's much better than the future refusal.
>>>
>>> The perfromance should be fine for iSER. For tcp, we would see small
>>> drop, however, it should be fine. I've been working on the user- 
>>> space
>>> approach to see the performance. I replaced poll with epoll and  
>>> added
>>> AIO support. I'm making the out-of-date user-space code work with  
>>> the
>>> latest code. That sould be finished shortly.
>>>
>>> I guess that I can merge the basic transport part of your latest
>>> patch.
>>>
>>
>> That would be great.
>>
>>>
>>>> We might want to look at the OpenFabric's stack to see how they
>>>> implement kernel bypass. This code has been accepted by kernel.org
>>>> and might provide a workable model or at least a starting point for
>>>> the user-mode iSER target implementation. It supports a very high
>>>> bandwidth, zero copy mechanism for exchanging data and events with
>>>> the kernel.
>>>
>>> Sounds nice. I guess that you mean that user-space processes can
>>> access to hardware without kernel intervention. Are documents about
>>> the APIs available? I have some questions about event notifications,
>>> etc.
>>>
>>
>> Sorry, the bulk of the documentation is all written in C.
>
> No problem.
>
>
>> There is some some documentation in a WiKi at
>> http://openfabrics.org. The source can be obtained via svn from
>> svn://openfabrics.org/svn/gen2/ trunk. It's big though. The user
>> space stuff is in ./src/userspace.  See the files in librdmacm and
>> libibverbs for how fd's are used for events.
>
> OK. I will. I guess that event handling (how to know the readable data
> is ready and the completion of transmit, etc) is only tricky stuff.
>
>
> Seems that you dropped the mailing list address (I don't know it's
> intentional or not),

Oops...no it wasn't.

> so I like to ask one more question, RNIC support
> in mainline. After the big discussion last month, what's the current
> state?

The iWARP stuff has been submitted to Roland for review and  
subsequent inclusion in 2.6.19. At this point, things look very  
positive since the bulk of the code has already been seen and the  
core changes are relatively minor and there is only a single device  
driver (AMSO1100).

The one other change we needed (netevents) has already been submitted  
to netdev and has been accepted by Dave Miller. So things are looking  
good there too.

In the meantime, I have a set of git patches to 2.6.17.y that I  
maintain. We also maintain this code as the iWARP branch in the  
OpenFabric's SVN repository.  I would recommend that we use stacked  
git on a git tree hosted by kernel.org for the kernel components. I  
can provide and maintain iWARP patches against this tree until iWARP  
support is mainline in 2.6.19. I guess we could continue to use svn  
for the user-mode components, but I don't have a strong opinion there.

Thoughts?

Tom


From fujita.tomonori at lab.ntt.co.jp  Thu Aug 31 16:42:07 2006
From: fujita.tomonori at lab.ntt.co.jp (FUJITA Tomonori)
Date: Thu, 31 Aug 2006 23:42:07 +0900
Subject: [Stgt-devel] uSpace Transport Patch
In-Reply-To: <4A1CC24C-CDE0-489E-B0BA-4BFB5AC1284F@opengridcomputing.com>
References: <D1F4BAC9-36FA-4537-83EC-1CDF8F23D6B6@opengridcomputing.com>
	<20060830093620V.fujita.tomonori@lab.ntt.co.jp>
	<4A1CC24C-CDE0-489E-B0BA-4BFB5AC1284F@opengridcomputing.com>
Message-ID: <200608311442.k7VEg7Tj001842@r-dd.iij4u.or.jp>

From: Tom Tucker <tom at opengridcomputing.com>
Subject: Re: [Stgt-devel] uSpace Transport Patch
Date: Tue, 29 Aug 2006 20:42:29 -0500

> > so I like to ask one more question, RNIC support
> > in mainline. After the big discussion last month, what's the current
> > state?
> 
> The iWARP stuff has been submitted to Roland for review and  
> subsequent inclusion in 2.6.19. At this point, things look very  
> positive since the bulk of the code has already been seen and the  
> core changes are relatively minor and there is only a single device  
> driver (AMSO1100).
> 
> The one other change we needed (netevents) has already been submitted  
> to netdev and has been accepted by Dave Miller. So things are looking  
> good there too.

Great!


> In the meantime, I have a set of git patches to 2.6.17.y that I  
> maintain. We also maintain this code as the iWARP branch in the  
> OpenFabric's SVN repository.  I would recommend that we use stacked  
> git on a git tree hosted by kernel.org for the kernel components. I  
> can provide and maintain iWARP patches against this tree until iWARP  
> support is mainline in 2.6.19. I guess we could continue to use svn  
> for the user-mode components, but I don't have a strong opinion there.

I like to move user-space code to a git tree too, however, I need to
mature it a bit before that. I don't want to use git, svn, and hg (for
Xen) everyday. ;)

By the way, now the main trunk includes the user-space iSCSI target
driver (the old kernel-mode code was moved under the branches
directory).

svn://svn.berlios.de/stgt/trunk

I've just done only read performance tests with open-iscsi's default
params and disktest. There is no performance difference between IET
and the new user-mode driver. It's far from completion. However,
surely AIO enables tgt to provide the comparable performance.


